<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Luhui&#39;s Personal Website</title>
    <link>https://blog.liluhui.cn/</link>
    
    <image>
      <url>https://blog.liluhui.cn/asset/img/logo-green.ico</url>
      <title>Luhui&#39;s Personal Website</title>
      <link>https://blog.liluhui.cn/</link>
    </image>
    
    <atom:link href="https://blog.liluhui.cn/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>关于生活、学习、工作 feedId:66855595489698816+userId:55886336755964928</description>
    <pubDate>Fri, 24 Oct 2025 08:41:50 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Agent Memory 评估测试方案：从指标体系到开源基准</title>
      <link>https://blog.liluhui.cn/2025/10/24/Agent-Memory-Evaluation-Framework-From-Metrics-to-Open-Benchmarks/</link>
      <guid>https://blog.liluhui.cn/2025/10/24/Agent-Memory-Evaluation-Framework-From-Metrics-to-Open-Benchmarks/</guid>
      <pubDate>Fri, 24 Oct 2025 08:38:29 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;给那些正在构建智能体的开发者的一份记忆体检指南&lt;/em&gt;&lt;/p&gt;
&lt;br/&gt;
&lt;br/&gt;


&lt;p&gt;前段时间，我在调试一个几何 Agent。&lt;/p&gt;
&lt;p&gt;这个 Agent 能自动分析几何题、推理定理、调用绘图工具，看上去颇有点“自主学习”的影子。&lt;/p&gt;
&lt;br/</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>给那些正在构建智能体的开发者的一份记忆体检指南</em></p><br/><br/><p>前段时间，我在调试一个几何 Agent。</p><p>这个 Agent 能自动分析几何题、推理定理、调用绘图工具，看上去颇有点“自主学习”的影子。</p><br/><p>但问题也随之而来——它太健忘了。</p><p>有时候明明刚在上文证明过某个结论，下一步又开始怀疑它自己。</p><p>我给它接上了向量数据库、加了摘要器、甚至写了个小型索引器，但效果依旧不稳定。</p><br/><p>那时候我开始意识到：</p><p><strong>我们都在拼命强化 Agent 的“行动力”，却很少认真测量它的“记忆力”。</strong></p><br/><p>于是我决定系统地研究一下，怎么评估一个 Agent 的 Memory 模块。</p><p>今天这篇文章，写给所有已经或准备构建 Agent 工程的人。</p><p>希望帮你找到一套可落地、可复现的记忆评测方案。</p><br/><br/><h2 id="为什么要测记忆？"><a href="#为什么要测记忆？" class="headerlink" title="为什么要测记忆？"></a>为什么要测记忆？</h2><p>如果说大模型是 Agent 的大脑，那 Memory 就是它的长期神经系统。</p><p>没有记忆，再聪明的模型也只能“现想”而无法“积累”。</p><br/><p>在工程实践里，这会表现为：</p><ul><li>对话几轮后开始失忆</li><li>任务中重复提问</li><li>自相矛盾的人设</li><li>一旦上下文超过 10K，就变成另一位陌生 AI</li></ul><p>在我构建数学 Agent 的过程中，这种现象尤其明显。</p><p>模型在第一轮中记得“点 A 在圆上”，到了第五轮，它却开始假设“点 A 在圆外”。</p><p>一开始我以为问题在于 prompt 太短，后来才发现，真正的原因是<strong>缺乏系统的 Memory 测试</strong>。</p><p>没有量化，就无法优化。</p><p>于是，记忆评测成了我“修 Agent 心智”的重要一步。</p><br/><br/><h2 id="我们到底要测什么？"><a href="#我们到底要测什么？" class="headerlink" title="我们到底要测什么？"></a>我们到底要测什么？</h2><p>衡量 Agent 的记忆，其实可以借鉴人类心理学：</p><p>人类记忆分为短时、长时、情节、语义……</p><p>在工程里，我们可以把测试拆成几个核心问题：</p><ul><li><p><strong>能不能想起来？（Recall）</strong></p><p>例如：“用户之前提到的定理叫什么？”</p><p>对应指标 Recall@K。</p></li><li><p><strong>说得一致吗？（Consistency）</strong></p><p>“你昨天说角 A 等于 60°，今天怎么变 45° 了？”</p></li><li><p><strong>更新正确吗？（Update）</strong></p><p>“如果条件改变，旧记忆是否被覆盖？”</p></li><li><p><strong>能承认不知道吗？（Calibration）</strong></p><p>当没见过的信息出现，模型是否会拒答而不是胡编。</p></li><li><p><strong>记忆会不会膨胀？（Forgetting）</strong></p><p>随着交互增多，Agent 是否会被冗余记忆拖慢。</p></li><li><p><strong>多模态下是否还记得？（Multimodal Memory）</strong></p><p>看过的图、听过的指令，在下次提问时还能匹配回来吗？</p></li></ul><p>这六个维度几乎涵盖了所有常见的 Memory 问题。</p><p>我自己在调试几何 Agent 时，最常暴露的是前两个：</p><p>模型常常能“记得关键词”，却丢失了几何关系；</p><p>它能复述公式，但忘了变量的含义。</p><br/><p>这时候如果没有 Recall 或 Consistency 的量化指标，根本无法判断是哪一环在失灵。</p><br/><br/><h2 id="市面上能用的评测基准"><a href="#市面上能用的评测基准" class="headerlink" title="市面上能用的评测基准"></a>市面上能用的评测基准</h2><p>我查阅了近两年的研究，发现业界其实已经有了几套相当成熟的 Memory 评测基准。</p><p>只是大部分人没注意到它们可以直接上手。</p><br/><p>第一个是 <strong>LoCoMo</strong> —— Snap Research 的长对话评测。</p><p>它用上百轮对话测试模型的“长期记忆力”，</p><p>问题涵盖事实回忆、时间因果、甚至多模态对话。</p><p>在官方结果里，GPT-4 的 F1 分数只有 32，而人类平均是 88。</p><p>也就是说，我们距离真正的长期记忆，还差一整个物种的距离。</p><br/><p>第二个是 <strong>LongMemEval</strong> —— UCLA 团队的系统性基准。</p><p>它更像一个“记忆体检表”，从信息提取、跨会话推理、知识更新到拒答未知，一共五项指标。</p><p>如果你的 Agent 是任务型（比如客服、知识问答），</p><p>LongMemEval 是最值得尝试的那套测试。</p><br/><p>第三类是 <strong>多会话记忆集</strong>，如 Facebook 的 MSC 和百度的 Persona-Long。</p><p>它们主要考察“角色一致性”，模型是否能记住用户和自己的设定。</p><p>这对陪伴型、教育型 Agent 尤其重要。</p><p>这类基准就能帮你精确量化这种人格断层。</p><br/><br/><h2 id="评测指标背后的逻辑"><a href="#评测指标背后的逻辑" class="headerlink" title="评测指标背后的逻辑"></a>评测指标背后的逻辑</h2><p>这些基准的数据再多，也离不开几个核心指标：</p><ul><li><strong>Recall@K</strong> —— 检索召回率。衡量从记忆库中找到正确信息的能力。</li><li><strong>QA Accuracy &#x2F; F1</strong> —— 回答是否正确。最终看的是能否“说对话”。</li><li><strong>Consistency Score</strong> —— 是否前后矛盾。可以人工或自动打分。</li><li><strong>Rejection Rate</strong> —— 面对未知是否拒答，防止“假记忆”。</li><li><strong>ROUGE &#x2F; BLEU &#x2F; FactScore</strong> —— 用于生成式摘要或事件回忆任务。</li></ul><p>在工程里我发现，<strong>指标越细，越能暴露 Memory 模块的真实问题</strong>。</p><p>比如我的几何 Agent 在 Recall 很高时，QA 准确率却低；</p><p>这说明它能检索出正确片段，但推理时用错了。</p><p>有时候优化 Memory，不是改数据库，而是改检索策略。</p><br/><br/><h2 id="如何在自己的工程中测试记忆"><a href="#如何在自己的工程中测试记忆" class="headerlink" title="如何在自己的工程中测试记忆"></a>如何在自己的工程中测试记忆</h2><p>如果你已经有一个可运行的 Agent，不妨这样操作：</p><p><strong>第一步：准备测试集。</strong></p><p>可以直接使用 LoCoMo 或 LongMemEval 的公开数据，也可以用自己系统中的聊天日志，人工标几个“记忆点”。</p><p><strong>第二步：定义 Memory 模块接口。</strong></p><p>无论你用的是 LangChain 的 <code>ConversationBufferMemory</code>，还是自研的像 MemGPT 那样的分页机制，确保你能随时 dump 出它“记住了什么”。</p><p><strong>第三步：运行评测脚本。</strong></p><p>LoCoMo 官方仓库里有 <code>evaluate_qa.py</code>，只需改一下模型接口，就能测你的 Agent 的 QA F1。</p><p>LongMemEval 也有现成脚本，可以测 Recall、拒答率等。</p><p><strong>第四步：观察与反思。</strong></p><p>别只看准确率，更要看错误类型。</p><p>有些错误是检索不到，有些是检索到但没用。</p><p>如果可能，把指标接入 CI 流程，每次更新记忆逻辑时自动跑一轮。</p><p>当你第一次看到自己的 Agent 在 LoCoMo 上得分只有二十几，那种“原来它根本没记住我”的感觉，会比任何 bug 都真实。</p><br/><br/><h2 id="可直接上手的评测-Demo"><a href="#可直接上手的评测-Demo" class="headerlink" title="可直接上手的评测 Demo"></a>可直接上手的评测 Demo</h2><p>如果你不想从零开始，可以直接试这几个项目：</p><ul><li><p><strong>LoCoMo 官方评测工具</strong>：<br><a href="https://github.com/snap-research/locomo">https://github.com/snap-research/locomo</a></p><p>包含超长对话数据和 QA 评测脚本。</p></li><li><p><strong>LongMemEval 基准</strong>：<br><a href="https://github.com/xiaowu0162/LongMemEval">https://github.com/xiaowu0162/LongMemEval</a></p><p>五维记忆测试模板，支持 HuggingFace 模型。</p></li><li><p><strong>MemoryBank &#x2F; SiliconFriend</strong>：<br><a href="https://github.com/zhongwanjun/MemoryBank-SiliconFriend">https://github.com/zhongwanjun/MemoryBank-SiliconFriend</a></p><p>内置遗忘机制，可在本地启动一个有“长期记忆”的中文聊天机器人。</p></li><li><p><strong>Reflexion Agent</strong>：<br><a href="https://github.com/noahshinn/reflexion">https://github.com/noahshinn/reflexion</a></p><p>教你如何让 Agent 自己反思并记录经验。</p></li></ul><p>我个人推荐先跑 LongMemEval。</p><p>它轻量、指标明确、结果易解释。</p><p>如果你的 Agent 通过了它，再挑战 LoCoMo。</p><p>后者是真正的“长对话炼狱”，我第一次跑完时 GPU 都快烤化了。</p><br/><br/><h2 id="评测之外的坑与反思"><a href="#评测之外的坑与反思" class="headerlink" title="评测之外的坑与反思"></a>评测之外的坑与反思</h2><p>我最深的感触是：<strong>记忆问题不是硬件问题，是认知问题。</strong></p><br/><p>我曾花一周时间优化索引算法，却忽略了最根本的逻辑——Agent 根本不知道“什么时候该想起某件事”。</p><p>它拥有庞大的向量库，却缺乏触发机制。</p><p>那一刻我突然明白：真正需要评测的，不仅是“记得多少”，更是“何时想起”。</p><br/><p>另外一个坑是“假记忆”。</p><p>我曾让模型复盘教师一天的教学日志，它开始一本正经地编造“我今天教了学生三角函数”。</p><p>这时拒答率指标就很关键。</p><p>一个 Agent 不该无所不答，<strong>能承认不知道，本身就是记忆成熟的表现。</strong></p><br/><br/><h2 id="未来的方向"><a href="#未来的方向" class="headerlink" title="未来的方向"></a>未来的方向</h2><p>目前的基准都还停留在文本和问答层面。</p><p>未来的评测一定会走向更真实的多模态场景——让 Agent 看图、听音、记住空间位置，甚至在几天后的任务中回忆它曾经画过的图。</p><br/><p>我相信未来的开发工具里，会出现一种新的概念：<strong>MemoryOps</strong>。</p><p>就像今天的 DevOps 管理部署一样，MemoryOps 将监控和测试 Agent 的记忆健康。</p><p>到那时候，我们或许可以做到：“每次模型上线前，都跑一份记忆体检报告。”</p><br/><br/><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>写这篇文章时，我想到一个比喻：</p><p>训练模型像造大脑，但让它拥有记忆，才是赋予它灵魂。</p><p>所以，在你下一次调试 Agent 时，<br>别只盯着推理精度和响应速度，<br>也问问它一句：</p><blockquote><p>“你还记得我们第一次对话吗？”</p></blockquote><p><strong>没有被测过的记忆，终将变成幻觉。</strong></p><br/><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/24/Agent-Memory-Evaluation-Framework-From-Metrics-to-Open-Benchmarks/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Agent 如何避免记忆漂移：三大策略与工程实践</title>
      <link>https://blog.liluhui.cn/2025/10/17/Preventing-Memory-Drift-in-Agent-Systems-Three-Core-Techniques-and-Engineering-Implementations/</link>
      <guid>https://blog.liluhui.cn/2025/10/17/Preventing-Memory-Drift-in-Agent-Systems-Three-Core-Techniques-and-Engineering-Implementations/</guid>
      <pubDate>Fri, 17 Oct 2025 08:17:39 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;TL-DR&quot;&gt;&lt;a href=&quot;#TL-DR&quot; class=&quot;headerlink&quot; title=&quot;TL;DR&quot;&gt;&lt;/a&gt;TL;DR&lt;/h2&gt;&lt;p&gt;长期运行的 Agent 容易出现「记忆漂移」：随着时间推移，其记忆内容被反复重写、压缩、整合，逐渐偏离原始语义，进而</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2><p>长期运行的 Agent 容易出现「记忆漂移」：随着时间推移，其记忆内容被反复重写、压缩、整合，逐渐偏离原始语义，进而导致自相矛盾、逻辑错乱或行为失常。</p><p>本篇文章总结了三种抵御记忆漂移的核心策略：</p><ul><li><p><strong>定期总结</strong>：定时摘要长对话内容，减少信息积压，保持上下文可控</p></li><li><p><strong>批处理蒸馏</strong>：从多轮对话中提炼出用户偏好与抽象知识，提升记忆质量</p></li><li><p><strong>冲突合并</strong>：发现重复或冲突内容，统一更新或标记失效，维持一致性</p></li></ul><p>结合实际系统如 MemGPT、AWS AgentCore、LangChain 等，下文提供了对应的工程实现与开源项目指引，适合构建具备长期稳定记忆的 Agent 架构。</p><br/><br/><h2 id="引言：智能体的「记忆漂移」现象"><a href="#引言：智能体的「记忆漂移」现象" class="headerlink" title="引言：智能体的「记忆漂移」现象"></a>引言：智能体的「记忆漂移」现象</h2><p>在构建具备长期行为一致性与任务连贯性的智能体（Agent）时，「记忆」机制成为不可或缺的一环。</p><p>与静态函数调用或短程上下文不同，Agent 的长期记忆的目标是支持跨轮次对话、持续学习与经验积累。</p><p>然而，随着记忆体量增长，「记忆漂移」问题逐渐显现：<strong>原始信息在多次重写、压缩、提取过程中偏离原意，导致 Agent 出现自相矛盾、事实错乱或行为不一致等现象</strong>。</p><p>这一问题本质上源自智能体在长期运行中所面临的信息冗余、表达歧义与语义演化挑战。</p><p>就像我们日常使用电脑，当桌面文件堆积如山、不及时分类整理，搜索效率降低、重复文件泛滥，最终反过来干扰工作。</p><br/><p>本文将深入探讨三种关键的抗记忆漂移策略：定期总结、批处理蒸馏、冲突合并。</p><p>结合最新的开源实践与研究进展，为构建稳定可靠的 Agent Memory 系统提供参考路径。</p><br/><br/><h2 id="策略一：定期总结-——-让记忆不过载"><a href="#策略一：定期总结-——-让记忆不过载" class="headerlink" title="策略一：定期总结 —— 让记忆不过载"></a>策略一：定期总结 —— 让记忆不过载</h2><p>如果你曾被对话窗口滚动到看不见开头、或者某个 Agent 总是健忘你提过的偏好，那大概率它缺了一套靠谱的定期总结机制。</p><p><strong>定期总结（Periodic Summarization）</strong> 是让智能体隔一段时间就回头看看：我刚刚都经历了什么？有哪些是值得留下的？</p><p>就像人写日记，不可能每句话都记，而是总结当日要点。</p><br/><p>工程实现示例：</p><ul><li><strong>LangChain SummaryBufferMemory</strong>：在上下文快要塞不下之前，自动将早期内容打包为摘要，留出空间给后续对话。</li><li><strong>MemGPT 滚动摘要</strong>：采用分层内存结构，短期记忆用完就「递归摘要」进中期记忆，就像桌面上的临时文件转存进资料夹。</li></ul><br/><p>一些提醒：</p><ul><li>连续多次摘要容易信息腐蚀，逐层失真。建议保留关键原句作为锚点。</li><li>可引入 pin memory 机制，确保核心事实始终原样保留。</li></ul><br/><br/><h2 id="策略二：批处理蒸馏-——-从日志中提炼稳定认知"><a href="#策略二：批处理蒸馏-——-从日志中提炼稳定认知" class="headerlink" title="策略二：批处理蒸馏 —— 从日志中提炼稳定认知"></a>策略二：批处理蒸馏 —— 从日志中提炼稳定认知</h2><p>有没有遇到过这种情况：你和 AI 聊了十几次后，TA还是不了解你？</p><p>这时，问题可能不在对话内容，而在于没有把那些碎片化记忆凝练为稳定认知。</p><p><strong>批处理蒸馏（Batched Distillation）</strong> 就像是回顾一整个项目后，总结出规律、套路、偏好，存档到知识库中。</p><br/><p>工程实现示例</p><ul><li><strong>Generative Agents（Stanford）</strong>：每个模拟人每天睡觉前会进行反思，总结一天所学所感。</li><li><strong>AWS AgentCore Memory</strong>：让新事件与历史记忆对话，LLM负责融合成一条高层认知。</li><li><strong>Letta MemGPT 的睡眠代理</strong>：利用主线程空闲时间悄悄整理旧资料，像我们周末清理相册一样。</li></ul><br/><p>提示模版示例</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">请阅读以下 N 段日志，总结出关于用户的稳定特征、目标与情绪倾向。</span><br></pre></td></tr></table></figure><br/><br/><h2 id="策略三：冲突合并-——-去重与知识更新"><a href="#策略三：冲突合并-——-去重与知识更新" class="headerlink" title="策略三：冲突合并 —— 去重与知识更新"></a>策略三：冲突合并 —— 去重与知识更新</h2><p>Agent 说你喜欢喝美式，过一会儿又说你最讨厌咖啡？这不是它耍你，而是记忆没合并好的情况。</p><p>长期运行的智能体一定会遇到记忆冲突：用户今天说“我吃素”，下个月说“这家烧烤真香”。</p><br/><p><strong>不消解这些冲突，Agent 就会陷入人格分裂式输出。</strong></p><p>合并策略</p><ul><li><strong>语义合并</strong>：让 LLM判断两个说法是重复、矛盾还是递进。</li><li><strong>失效机制</strong>：标记旧记忆为「历史版本」，不参与默认推理。</li><li><strong>仲裁代理</strong>：在多智能体系统中，用专职 Agent 仲裁歧义事实。</li></ul><br/><p>工程落地示例</p><ul><li><strong>AWS AgentCore Memory</strong>：每条新记忆自动触发冲突检测与合并逻辑。</li><li><strong>Memori Memory Engine</strong>：具备版本控制与自动协调机制，适合长生命周期记忆管理。</li></ul><br/><br/><h2 id="拿来即用，策略对比与实践参考"><a href="#拿来即用，策略对比与实践参考" class="headerlink" title="拿来即用，策略对比与实践参考"></a>拿来即用，策略对比与实践参考</h2><table><thead><tr><th>策略名称</th><th>作用重点</th><th>典型触发时机</th><th>工程实现代表</th><th>风险点</th></tr></thead><tbody><tr><td>定期总结</td><td>控制体积，保存语境</td><td>消息超过阈值</td><td>LangChain、MemGPT</td><td>摘要失真</td></tr><tr><td>批量蒸馏</td><td>抽象提炼，积累知识</td><td>阶段归档或反思时刻</td><td>AWS AgentCore、Generative Agents</td><td>抽象过度</td></tr><tr><td>冲突合并</td><td>保持一致性，去重纠错</td><td>新旧冲突产生时</td><td>Memori、Letta、仲裁代理机制</td><td>决策不透明</td></tr></tbody></table><p><strong>组合建议</strong>：构建分层内存结构 + 批次反思 + 定期摘要 + 合并管道，能形成防漂移的“记忆治理闭环”。</p><br/><p>可用工具与开源实现一览：</p><table><thead><tr><th>名称</th><th>类型</th><th>地址</th><th>支持策略</th></tr></thead><tbody><tr><td>LangChain SummaryMemory</td><td>工具库</td><td><a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a></td><td>定期总结</td></tr><tr><td>MemGPT &#x2F; Letta</td><td>代理框架</td><td><a href="https://github.com/letta-ai/letta">https://github.com/letta-ai/letta</a></td><td>三者兼具</td></tr><tr><td>AgentCore Memory</td><td>云平台模块</td><td><a href="https://aws.amazon.com/bedrock/agents">https://aws.amazon.com/bedrock/agents</a></td><td>蒸馏 + 合并</td></tr><tr><td>Memori</td><td>记忆服务</td><td><a href="https://github.com/GibsonAI/memori">https://github.com/GibsonAI/memori</a></td><td>冲突合并</td></tr><tr><td>generative_agents</td><td>模拟研究框架</td><td><a href="https://github.com/joonspk-research/generative_agents">https://github.com/joonspk-research/generative_agents</a></td><td>批量蒸馏</td></tr></tbody></table><br/><br/><h2 id="写在最后：从记忆治理到认知形成"><a href="#写在最后：从记忆治理到认知形成" class="headerlink" title="写在最后：从记忆治理到认知形成"></a>写在最后：从记忆治理到认知形成</h2><p>智能体的记忆，终究不是日志数据库，而是它认知世界、理解人类、规划行动的基础。过去我们关注的是它记不记得；而现在，我们必须关心它记得对不对、准不准、合不合理。</p><p>三类策略分别作用于记忆系统的不同阶段：<strong>定期总结</strong> 帮它活在有限当下，<strong>批量蒸馏</strong> 帮它形成抽象理解，<strong>冲突合并</strong> 让它在真伪之间保持清醒。</p><p>三者结合，才可能走向真正可持续的 Agent 思维。</p><br/><p>我的观点是，未来 Agent 开发，不该再把 Memory 当附属功能，而应当作为核心设计范式来思考。</p><p>就像我们在产品中设计信息架构一样，我们也应该设计 Agent 的认知架构。</p><p>构建一个能学、能忘、能修的 Agent，不只是技术挑战，更是认知工程。</p><p>根基不稳，智能难远。</p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/17/Preventing-Memory-Drift-in-Agent-Systems-Three-Core-Techniques-and-Engineering-Implementations/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>什么是多 Agent 系统？从单体模型到协作智能的进化</title>
      <link>https://blog.liluhui.cn/2025/10/15/What-Is-a-Multi-Agent-System-From-a-Single-LLM-to-Collaborative-Intelligence/</link>
      <guid>https://blog.liluhui.cn/2025/10/15/What-Is-a-Multi-Agent-System-From-a-Single-LLM-to-Collaborative-Intelligence/</guid>
      <pubDate>Wed, 15 Oct 2025 08:11:28 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;过去一年，我们见证了无数“大模型”带来的奇迹。&lt;br&gt;它们能写代码、能画图、能写策划书，甚至能帮你找 bug。  &lt;/p&gt;
&lt;p&gt;于是一个问题出现了：  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;既然大模型已经这么强了，&lt;strong&gt;为什么还要搞那么复杂的「多 Agent</description>
        
      
      
      
      <content:encoded><![CDATA[<p>过去一年，我们见证了无数“大模型”带来的奇迹。<br>它们能写代码、能画图、能写策划书，甚至能帮你找 bug。  </p><p>于是一个问题出现了：  </p><blockquote><p>既然大模型已经这么强了，<strong>为什么还要搞那么复杂的「多 Agent 系统」</strong>？ </p><p>是不是就是多开几个大模型？  </p></blockquote><p>其实，多 Agent 不是“堆模型”，而是一次<strong>智能结构的转变</strong>。  </p><p>它让我们开始用「团队」的方式去理解 AI，让语言模型从“单人作坊”变成“协作组织”。  </p><br/><br/><h2 id="一个-Agent-不够用吗？"><a href="#一个-Agent-不够用吗？" class="headerlink" title="一个 Agent 不够用吗？"></a>一个 Agent 不够用吗？</h2><p>想象你让 GPT 帮你开发一个网站：它能写前端，也能设计数据库，还能生成测试代码。 </p><p>但很快你会发现一个问题，它在写完后<strong>自测永远都通过</strong>，逻辑错误自己也检查不出来。  </p><br/><p>于是人们开始尝试：<br>让一个 GPT 写，另一个 GPT 审；<br>让一个负责规划，另一个负责执行；<br>甚至让两个 GPT 吵一架，看谁的结论更靠谱。  </p><p>这就是最早的 “<strong>multi-agent</strong>” 思想萌芽。<br>不是因为模型不行，而是因为<strong>智能需要结构</strong>。<br>单个 Agent 再强，也无法同时兼顾规划、执行、评估、反思这些不同心智功能。  </p><br/><br/><h2 id="为什么要多个-Agent：从「个体智能」到「集体智能」"><a href="#为什么要多个-Agent：从「个体智能」到「集体智能」" class="headerlink" title="为什么要多个 Agent：从「个体智能」到「集体智能」"></a>为什么要多个 Agent：从「个体智能」到「集体智能」</h2><h3 id="1️⃣-分工让思考更高效"><a href="#1️⃣-分工让思考更高效" class="headerlink" title="1️⃣ 分工让思考更高效"></a>1️⃣ 分工让思考更高效</h3><p>就像人类社会的分工一样，AI 也有“认知负荷”。<br>一个 Agent 的上下文再长，也无法同时规划和执行。  </p><br/><p>于是多 Agent 系统会把任务拆解：  </p><ul><li><strong>Planner</strong> 规划任务  </li><li><strong>Executor</strong> 调用工具或编写代码  </li><li><strong>Critic</strong> 检查结果、给出反馈</li></ul><br/><p>论文参考：</p><ul><li>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework (Hong et al., 2023)  </li><li>Reflexion: Verbal Reinforcement Learning with LLMs (Shinn et al., 2023)</li></ul><h3 id="2️⃣-不同视角，减少偏差"><a href="#2️⃣-不同视角，减少偏差" class="headerlink" title="2️⃣ 不同视角，减少偏差"></a>2️⃣ 不同视角，减少偏差</h3><p>当多个 Agent 相互讨论、辩论、复核时，错误就更难溜走。<br>这就是所谓的 “<strong>social critique</strong>” —— AI 用社会互动的方式，来弥补单模型思维的盲点。 </p><br/><p>例如 <em>CAMEL (2023)</em> 中，两个 LLM 扮演不同角色，通过角色扮演协作完成任务，结果准确率显著高于单模型执行。  </p><h3 id="3️⃣-群体记忆与长期任务"><a href="#3️⃣-群体记忆与长期任务" class="headerlink" title="3️⃣ 群体记忆与长期任务"></a>3️⃣ 群体记忆与长期任务</h3><p>一个模型记不住太久的上下文，而多 Agent 系统可以共享外部记忆。  </p><p><strong>LangGraph</strong> 就用图状结构记录各 Agent 的状态与结果，<br><strong>AutoGen</strong> 则通过消息路由实现多轮协作。  </p><p>这让智能系统第一次能像组织一样 <strong>有状态、有记忆、有分工</strong>。  </p><br/><br/><h2 id="「Agent」vs-「Multi-Agents」：什么时候该用哪种？"><a href="#「Agent」vs-「Multi-Agents」：什么时候该用哪种？" class="headerlink" title="「Agent」vs 「Multi Agents」：什么时候该用哪种？"></a>「Agent」vs 「Multi Agents」：什么时候该用哪种？</h2><p>不是所有任务都需要多 Agent，整理了下面这张表，帮你快速判断：  </p><table><thead><tr><th>场景类型</th><th>适合单 Agent</th><th>适合多 Agent</th></tr></thead><tbody><tr><td>简单问答、摘要、翻译</td><td>✅</td><td>❌</td></tr><tr><td>多步骤推理（数学、逻辑）</td><td>⚠️</td><td>✅</td></tr><tr><td>代码生成与测试</td><td>❌</td><td>✅</td></tr><tr><td>长期运营任务（游戏、规划）</td><td>❌</td><td>✅</td></tr><tr><td>决策 &#x2F; 研究讨论类任务</td><td>⚠️</td><td>✅</td></tr></tbody></table><p>👉 简单说：  </p><ul><li><strong>单 Agent</strong>：快、轻、直接。  </li><li><strong>多 Agent</strong>：稳、复杂、可解释。</li></ul><p>它更像是“团队思维”，适用于有阶段、有反馈、有评估的任务。  </p><br/><br/><h2 id="协作机制不是「堆模型」，而是「编排心智」"><a href="#协作机制不是「堆模型」，而是「编排心智」" class="headerlink" title="协作机制不是「堆模型」，而是「编排心智」"></a>协作机制不是「堆模型」，而是「编排心智」</h2><p>多 Agent 的价值在于协作机制，而不是数量。  </p><p>常见机制包括：  </p><ol><li><strong>角色定义</strong>：每个 Agent 有独立 Prompt 与目标（Planner &#x2F; Coder &#x2F; Tester）  </li><li><strong>通信协议</strong>：消息路由、对话规则（AutoGen 异步消息机制）  </li><li><strong>状态共享</strong>：外部记忆、数据库或上下文图（LangGraph）  </li><li><strong>自我审查</strong>：互评或辩论结构（CAMEL、Reflexion）  </li><li><strong>任务编排</strong>：从自然语言生成完整工作流（MetaGPT、CrewAI）</li></ol><p>工程参考：</p><ul><li>Microsoft AutoGen</li><li>LangChain LangGraph  </li><li>MetaGPT  </li><li>CAMEL-AI  </li><li>CrewAI</li></ul><br/><br/><h2 id="争议：多-Agent-是过渡，还是未来？"><a href="#争议：多-Agent-是过渡，还是未来？" class="headerlink" title="争议：多 Agent 是过渡，还是未来？"></a>争议：多 Agent 是过渡，还是未来？</h2><p>目前学术界有两种声音：  </p><p>1️⃣ <strong>单体强化派</strong><br>认为随着大模型上下文与记忆增强（如 GPT-o3、Gemini 2.5），<br>未来单模型内部就能模拟多角色思维，不再需要外部 Agent。  </p><p>2️⃣ <strong>协作网络派</strong><br>认为未来智能系统会像社会那样，通过标准协议（如 MCP、A2A）让不同 Agent 协作，<br>形成一个“分布式智能生态”。  </p><p>无论是哪种，multi-agent 都是一个重要的中间态：它让 AI 学会如何组织智能、引导协作，为真正的“社会化 AI”打下基础。  </p><br/><br/><h2 id="结语：AI，也需要同事"><a href="#结语：AI，也需要同事" class="headerlink" title="结语：AI，也需要同事"></a>结语：AI，也需要同事</h2><p>多 Agent 的出现，不是因为模型不够强，而是因为<strong>智能本身就不是单线程的</strong>。  </p><p>人类的思考依靠分工协作——感知、记忆、计划、执行、反思。  </p><p>AI 也在重走这条路，只不过是以 Agent 的形式。  </p><br/><p>当我们不再把智能看作一个「模型」，  </p><p>而是一群「协作的心智」时，  </p><p>也许我们就更接近真正的智能社会。  </p><br/><br/><br/><br/><br/><h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><p><strong>学术论文：</strong>  </p><ul><li><a href="https://arxiv.org/abs/2303.17760">Li et al. (2023) — <em>CAMEL: Communicative Agents for “Mind” Exploration of LLM Society</em></a></li><li><a href="https://arxiv.org/abs/2308.00352">Hong et al. (2023) — <em>MetaGPT: Meta Programming for Multi-Agent Collaborative Framework</em></a></li><li><a href="https://arxiv.org/html/2303.11366">Shinn et al. (2023) — <em>Reflexion: Verbal Reinforcement Learning for LLMs</em></a></li><li><a href="https://arxiv.org/abs/2304.03442">Park et al. (2023, Stanford) — <em>Generative Agents: Interactive Simulacra of Human Behavior</em></a></li><li><a href="https://arxiv.org/abs/2503.13657">Cemri et al. (2024) — <em>MAST: Multi-Agent System Taxonomy of Failures</em></a></li><li><a href="https://arxiv.org/abs/2503.05473">Mamie et al. (2025) - <em>The Society of HiveMind: Multi-Agent Optimization of Foundation Model Swarms</em></a></li></ul><p><strong>开源工程：</strong>  </p><ul><li><a href="https://github.com/microsoft/autogen">Microsoft AutoGen</a>  </li><li><a href="https://github.com/langchain-ai/langgraph">LangChain LangGraph</a>  </li><li><a href="https://github.com/FoundationAgents/MetaGPT">MetaGPT</a>  </li><li><a href="https://github.com/camel-ai/camel">CAMEL-AI</a>  </li><li><a href="https://github.com/crewAIInc/crewAI">CrewAI</a>  </li><li><a href="https://github.com/openai/swarm">OpenAI Swarm</a> (实验性)</li></ul>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/15/What-Is-a-Multi-Agent-System-From-a-Single-LLM-to-Collaborative-Intelligence/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>什么是 Agent Memory？探索 AI 如何理解并记住你的话</title>
      <link>https://blog.liluhui.cn/2025/10/10/Understanding_Agent_Memory_The_Mechanisms_Behind_AI%E2%80%99s_Ability_to_Remember/</link>
      <guid>https://blog.liluhui.cn/2025/10/10/Understanding_Agent_Memory_The_Mechanisms_Behind_AI%E2%80%99s_Ability_to_Remember/</guid>
      <pubDate>Fri, 10 Oct 2025 08:18:47 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;记忆并非理所当然，理解-AI-时代的记忆&quot;&gt;&lt;a href=&quot;#记忆并非理所当然，理解-AI-时代的记忆&quot; class=&quot;headerlink&quot; title=&quot;记忆并非理所当然，理解 AI 时代的记忆&quot;&gt;&lt;/a&gt;记忆并非理所当然，理解 AI 时代的记忆&lt;/h2&gt;&lt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="记忆并非理所当然，理解-AI-时代的记忆"><a href="#记忆并非理所当然，理解-AI-时代的记忆" class="headerlink" title="记忆并非理所当然，理解 AI 时代的记忆"></a>记忆并非理所当然，理解 AI 时代的记忆</h2><p>记忆是我们日常生活中不可或缺的一部分。<br>从小到大，我们积累的经验和知识形成了对世界的认知框架。<br>人类的记忆帮助我们在面对未知时作出反应，记住重要的事情，避免重复犯错。<br>但是，<strong>如果我们只将 记忆 理解为人类自然存在的生理过程，那么在面对人工智能（AI）时代的 Agent Memory 时，可能会产生误解</strong>。</p><p>在 AI 的世界里，记忆并不像人类那样自然而然地存在。<br>这也是为什么我们需要从一个全新的角度，去理解和探索 Agent Memory —— 它不仅仅是记住过去的互动，而是让机器能够像人类一样，通过记忆优化每次决策的能力。</p><p>通过这篇文章，我将带你走进 Agent Memory 的世界，解答这个关键问题： <strong>Agent Memory 是什么？为什么它对智能代理至关重要？</strong></p><br/><br/><h2 id="什么是-Agent-Memory？"><a href="#什么是-Agent-Memory？" class="headerlink" title="什么是 Agent Memory？"></a>什么是 Agent Memory？</h2><p><strong>Agent Memory 是人工智能代理（AI Agent）中的“记忆系统”，它是人类设计的存储、更新&#x2F;遗忘和检索机制。</strong><br>它使得 AI 能够在与用户互动时，不仅记住和利用历史信息，还能根据任务的需要进行更新、遗忘和优化，以提供更加智能、个性化的服务。</p><p><strong>可以将 Agent Memory 理解为一套“存储-更新-检索”的策略。</strong><br>不同的实现路径和技术方案使得这一系统的具体应用形式多种多样。无论是短期记忆、长期记忆，还是对信息的筛选和检索方式，它都帮助 AI 在每次与用户的互动中，保持一致性、理解上下文，并从过去的经验中不断学习和调整。</p><p>举个例子，当你与智能语音助手对话时，它不仅记得你昨天询问过身体不舒服的症状，还会根据历史信息优化后续的建议。<strong>这不仅是记忆的简单存储，而是通过精心设计的策略，让 Agent Memory 具备了学习和适应的能力</strong>。</p><p>需要特别注意的是，在 Agent Memory 的设计中，<strong>上下文 和 记忆 是两个不同的概念</strong>。</p><ul><li><strong>上下文</strong>: 只存在于当前的交互中，它帮助 AI 理解当前对话或任务的背景。例如，用户正在询问今天的天气，AI 就会利用这个即时上下文来生成回答，但当对话结束时，这些上下文信息将不再保存。</li><li><strong>记忆</strong>：则是长期存储的信息，能够跨会话、跨任务持续保持，并帮助 AI 在未来的交互中做出更加个性化和高效的响应。</li></ul><p>这与人类的思维过程相似：我们在对话中可能暂时记住某些信息（上下文），但“记忆”则是指我们从过去的经历中提取经验，以便做出更明智的决策，而不仅仅局限于当前的对话。</p><br/><br/><h2 id="Agent-Memory-的类型"><a href="#Agent-Memory-的类型" class="headerlink" title="Agent Memory 的类型"></a>Agent Memory 的类型</h2><p>Agent Memory 并不是单一的记忆体，而是由多个层次和类型组成，旨在应对不同的应用场景。<br>这些记忆类型就像人类不同的记忆系统，分别负责即时的工作任务和长期的知识储备。<br>以下是 <strong>Agent Memory 的五种基本类型</strong>，详细区别可看同系列文章<a href="https://blog.liluhui.cn/2025/09/19/Agent-Memory-Five-Layer-Model-and-Engineering-Implementation/">《Agent 记忆五层模型与工程落地》</a>：</p><ul><li><strong>工作记忆（Working Memory）</strong><br> 工作记忆负责存储和处理当前任务或对话中的即时信息。它类似于人类的短期记忆，帮助 AI 在与用户的互动中保持上下文，处理即时的需求。工作记忆通常在会话结束后被清除，以便为新的任务腾出空间。</li><li><strong>情景记忆（Episodic Memory）</strong><br> 情景记忆负责记录和存储与特定事件相关的信息。这类记忆帮助 AI 记住特定的事件、用户的行为和相关的交互情境，从而提供更具上下文关联性的反馈。</li><li><strong>语义记忆（Semantic Memory）</strong><br> 语义记忆包含了广泛的通用知识和事实，例如世界常识、数学公式、日期等。这类记忆不依赖于个体的经历，而是基于普遍接受的事实和信息。</li><li><strong>程序性记忆（Procedural Memory）</strong><br> 程序性记忆用于存储如何执行特定任务或操作的知识。这些知识是 Agent 在反复执行某项技能时积累的，类似于人类如何记住特定技能的操作步骤。</li><li><strong>外部持久记忆（External Persistent Memory）</strong><br> 外部持久记忆负责记录并归档用户的长期历史和行为数据。这类记忆帮助 AI 在多个会话、任务和平台之间保持一致性，便于长期个性化和精准反馈。</li></ul><br/><br/><h2 id="Agent-Memory-如何工作？"><a href="#Agent-Memory-如何工作？" class="headerlink" title="Agent Memory 如何工作？"></a>Agent Memory 如何工作？</h2><p><strong>Agent Memory 的核心工作流是存储、更新和检索信息。</strong><br>AI 通过以下几个步骤有效管理记忆，使得每次与用户的互动都更加精准和高效：</p><ul><li><strong>信息存储</strong><br> AI 会根据一定的策略存储重要的交互信息，这些信息可能来自用户输入的对话内容、历史数据或任务需求。为了实现高效存储，信息通常通过数据库或嵌入式向量存储（如 FAISS）来实现。</li><li><strong>信息更新</strong><br> 信息并非一成不变，随着新的交互发生，AI 会更新其记忆。例如，用户的偏好、常见问题或新的任务需求都可以被记录下来，并反映在长期记忆中。信息的更新使得 AI 能够不断优化其响应。</li><li><strong>信息检索</strong><br> AI 必须能够根据当前需求，迅速从记忆中提取相关信息。这一过程类似于检索，通过技术手段（如向量数据库和嵌入检索），AI 可以从大量存储的数据中找到最匹配的内容，从而提供更加智能和精准的回应。</li></ul><br/><br/><h2 id="Agent-Memory-在实际应用中的作用"><a href="#Agent-Memory-在实际应用中的作用" class="headerlink" title="Agent Memory 在实际应用中的作用"></a>Agent Memory 在实际应用中的作用</h2><ol><li><strong>个性化体验</strong><br>Agent Memory 使得 AI 能够记住并理解用户的偏好和需求，从而提供更加个性化的服务。例如，智能推荐系统能根据用户的历史行为推荐商品或服务。</li><li><strong>多轮对话与一致性</strong><br> 在多轮对话中，Agent Memory 使得 AI 能够保持对话的上下文和连贯性，不会重复提问或对话断裂。AI 可以更好地理解用户的意图，从而提供更智能的回应。</li><li><strong>提高效率</strong><br> 通过有效的记忆管理，AI 能够减少用户重复输入信息的需求，提升交互效率。例如，智能助手记住用户的常见问题，能快速提供相关回答，而无需每次重新输入。</li></ol><br/><br/><h2 id="Agent-Memory-的技术实现"><a href="#Agent-Memory-的技术实现" class="headerlink" title="Agent Memory 的技术实现"></a>Agent Memory 的技术实现</h2><p><strong>Agent Memory 的实现依赖于多种技术策略和组件，目的是让 AI 代理在与用户的交互中保持智能化的记忆能力。</strong><br>它的核心机制包括 存储、更新、遗忘和检索，并通过不断优化这些环节来提供个性化和高效的服务。关键技术要素包括：</p><ol><li><p><strong>存储机制</strong>，将用户交互转化为长期可访问的格式：</p><ul><li>向量数据库：如 <strong>FAISS</strong>、<strong>Pinecone</strong>，通过 <strong>embedding</strong> 向量存储，支持高效相似度检索。</li><li>知识库：存储通用知识，如语法、历史事实等，增强记忆能力。</li></ul></li><li><p><strong>信息更新与遗忘策略</strong>，根据新的交互进行动态更新和优化：</p><ul><li>增量更新：将新信息有针对性地加入，而非覆盖已有记忆。</li><li>遗忘机制：删除过时或无用数据，避免记忆膨胀。</li><li>信息压缩：整理和压缩冗余信息，提高存储效率。</li></ul></li><li><p><strong>信息检索机制</strong>，高效检索存储数据：</p><ul><li>向量检索：通过 <strong>FAISS</strong> 等工具，根据相似度快速检索相关信息。</li><li>查询优化：结合 <strong>contextual embeddings</strong> 精确理解用户意图，提升检索精度。</li></ul></li><li><p><strong>多模态信息整合</strong>，结合图像、语音、文本等多种数据形式，提升 AI 的综合响应能力。</p><ul><li>例如，<strong>多模态图像识别系统</strong>，同时处理文本与图像信息，提供精准反馈。</li></ul></li><li><p><strong>外部持久记忆与分布式存储</strong><br>随着数据量的增加，部分记忆会存储到外部系统（如云数据库），保证跨设备、跨平台的持续更新与访问。</p></li></ol><br/><br/><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过合理的 Agent Memory 管理，人工智能可以从单纯的工具进化为智能的交互伙伴，能够理解用户需求、提供个性化的反馈并实现更高效的互动。<br>未来，随着技术的不断进步，Agent Memory 将会在个性化服务、智能化交互以及多代理协作中发挥越来越重要的作用。<br>毕竟，<strong>让“智能”真的成为智能是需要经验积累的，那个“经验”正是在记忆之上的思考。</strong><br>当然现在 Agent Memory 在提升智能代理的能力和用户体验方面仍然面临一些挑战：比如记忆膨胀问题。随着时间推移，AI 可能会积累大量信息，这可能导致记忆库膨胀，影响性能。</p><br/><br/><br/><br/><br/><h2 id="延申阅读"><a href="#延申阅读" class="headerlink" title="延申阅读"></a>延申阅读</h2><ul><li><a href="https://arxiv.org/abs/2504.19413">Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory</a></li><li><a href="https://arxiv.org/abs/2502.12110">A-MEM: Agentic Memory for LLM Agents</a></li><li><a href="https://www.researchgate.net/publication/388144017_Memory_Architectures_in_Long-Term_AI_Agents_Beyond_Simple_State_Representation">Memory Architectures in Long-Term AI Agents</a></li><li><a href="https://mem0.ai/blog/memory-in-agents-what-why-and-how">AI Agent Memory: What, Why and How It Works</a></li><li><a href="https://www.ibm.com/think/topics/ai-agent-memory">What Is AI Agent Memory? | IBM</a></li><li><a href="https://medium.com/@nirdiamant21/building-an-ai-agent-with-memory-and-adaptability-cdbc428bc36c">Building an AI Agent with Memory and Adaptability</a></li></ul>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/10/Understanding_Agent_Memory_The_Mechanisms_Behind_AI%E2%80%99s_Ability_to_Remember/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Agent 记忆检索策略：怎样学会想起？</title>
      <link>https://blog.liluhui.cn/2025/10/08/Memory-as-Thinking-How-Agents-Retrieve-What-Matters/</link>
      <guid>https://blog.liluhui.cn/2025/10/08/Memory-as-Thinking-How-Agents-Retrieve-What-Matters/</guid>
      <pubDate>Wed, 08 Oct 2025 09:32:32 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;TL-DR&quot;&gt;&lt;a href=&quot;#TL-DR&quot; class=&quot;headerlink&quot; title=&quot;TL;DR&quot;&gt;&lt;/a&gt;TL;DR&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;LLM Agent 的记忆系统关键不在“能记多少”，而在“能否精准想起”。&lt;/strong&gt;&lt;br&gt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2><p><strong>LLM Agent 的记忆系统关键不在“能记多少”，而在“能否精准想起”。</strong><br>本文总结了 <strong>三类触发机制</strong> 与 <strong>六种检索策略</strong>，构成了一个从“何时想起”到“如何检索”的完整框架：</p><p>🧠 触发机制（When to Recall）</p><ol><li>规则触发 —— 窗口容量不足时检索历史</li><li>反思触发 —— 模型自觉遗忘时主动检索</li><li>事件触发 —— 特定情境或失败日志触发回忆</li></ol><p>🔍 检索策略（How to Retrieve）</p><ol><li>语义相似检索</li><li>混合检索</li><li>图式检索</li><li>元数据过滤</li><li>重排</li><li>反思式检索</li></ol><p>这些策略共同构成了 RAG（Retrieval-Augmented Generation） 的多种实现形态，从简单的语义召回到带有反思与路由能力的自适应检索。<br>记忆不是仓库，而是过滤器——检索策略定义了 Agent 的注意力边界，也塑造了它的“思考深度”。</p><br/><br/><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>LLM Agent 记忆系统的挑战不在“能存多少”，而在“<strong>能否精准想起</strong>”。<br>AutoGPT 曾经尝试将所有任务摘要向量化存入 Pinecone，但检索常常召回“语义相似但任务无关”的记录。<br>Voyager 在 Minecraft 中的“技能库”检索则恰好相反：每次仅召回可执行的技能模块，显著提升学习效率。</p><br/><p><strong>检索的关键不是容量，而是相关性。</strong><br><br/></p><p> 一个好的记忆检索系统，应该能回答三件事：</p><ol><li>什么时候需要想起？</li><li>想起哪些内容？</li><li>想起后如何用？</li></ol><br/><br/><h2 id="触发机制：Agent-何时“想起”"><a href="#触发机制：Agent-何时“想起”" class="headerlink" title="触发机制：Agent 何时“想起”"></a>触发机制：Agent 何时“想起”</h2><p>一个有记忆的 Agent，并不会在每次对话都去翻遍自己的“记忆仓库”。<br>真正聪明的系统，知道<strong>什么时候该想起</strong>。<br>触发检索的时机，其实构成了 Agent 的“意识边界”。<br>我们可以把它想象成人类的三种“回忆瞬间”：</p><h3 id="1-规则触发：因为“容量不够”"><a href="#1-规则触发：因为“容量不够”" class="headerlink" title="1. 规则触发：因为“容量不够”"></a>1. 规则触发：因为“容量不够”</h3><p>最常见的情况，是模型的上下文窗口装不下了。<br>当对话历史变长、任务链变复杂时，旧的信息被挤出窗口，模型开始遗忘。<br>于是我们让 Agent 在这种情况下主动去检索——像是人类“翻笔记”的瞬间。<br>在工程上，这通常由一个简单的规则触发：</p><blockquote><p>当上下文长度接近阈值（比如 80% 的窗口容量）时，调用检索模块，把最相关的历史片段重新召回。</p></blockquote><p>这是一种<strong>节制型的记忆唤醒</strong>。<br>它让 Agent 在不增加计算负担的前提下，维持对过去的最小感知。</p><br/><h3 id="2-反思触发：当-Agent-自觉“忘了什么”"><a href="#2-反思触发：当-Agent-自觉“忘了什么”" class="headerlink" title="2. 反思触发：当 Agent 自觉“忘了什么”"></a>2. 反思触发：当 Agent 自觉“忘了什么”</h3><p>更有意思的情况是 Agent 自己意识到记忆的缺口。<br>比如模型在生成中评估到不确定性上升、连续几步推理逻辑断裂，或自己产生了矛盾。<br>这时，它可能会触发一次“反思式检索”（Reflective Retrieval）：<br>让大模型生成一句类似</p><blockquote><p>“我好像需要回忆一下之前用户提过的限制条件。”</p></blockquote><p>然后根据这句话，再去检索相关记忆。<br>这种机制不靠固定阈值，而靠<strong>自我监控（self-monitoring）</strong>。<br>它更接近人类思维里的那种模糊直觉——“等等，好像哪儿不太对”。<br>在实现上，我们会给模型一个简单的函数调用接口，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> model.confidence &lt; <span class="number">0.5</span>:</span><br><span class="line">    memories = retrieve(query)</span><br></pre></td></tr></table></figure><p>让反思和检索之间形成闭环。<br>这正是 Self-RAG、A-Mem 这类系统的核心思想：<strong>Agent 主动决定何时“想起”</strong>。</p><br/><h3 id="3-事件触发：因为“当下需要”"><a href="#3-事件触发：因为“当下需要”" class="headerlink" title="3. 事件触发：因为“当下需要”"></a>3. 事件触发：因为“当下需要”</h3><p>最后一种触发是情境性的。<br>有些记忆并不是因为遗忘才被召回，而是<strong>因为情境再次出现</strong>。<br>比如，当一个任务执行失败、某个工具调用报错，Agent 会去搜索之前的失败记录：</p><blockquote><p>“上次这个 API 报 403 错时，我是怎么修的？”</p></blockquote><p>又或者，当用户在不同会话中再次提到某个主题，Agent 会识别关键词，自动检索该主题下的历史交互。<br>这类触发往往和<strong>事件监听</strong>或<strong>日志回放机制</strong>相关。<br>它让 Agent 的记忆像一个条件反射系统： “相同的信号 → 激活相似的记忆 → 快速反应。”</p><br/><br/><h2 id="检索策略：从“找得到”到“找得准”"><a href="#检索策略：从“找得到”到“找得准”" class="headerlink" title="检索策略：从“找得到”到“找得准”"></a>检索策略：从“找得到”到“找得准”</h2><p>以下策略可按复杂度逐级叠加：</p><h3 id="1-语义相似检索（Dense-Retrieval）"><a href="#1-语义相似检索（Dense-Retrieval）" class="headerlink" title="1. 语义相似检索（Dense Retrieval）"></a>1. 语义相似检索（Dense Retrieval）</h3><p>最基础的做法：将每条记忆文本编码为向量，通过余弦相似度召回前 K 条。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 工程核心代码</span></span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line"><span class="keyword">import</span> faiss, numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型和索引</span></span><br><span class="line">embedder = SentenceTransformer(<span class="string">&quot;all-MiniLM-L6-v2&quot;</span>)</span><br><span class="line">index = faiss.IndexFlatIP(<span class="number">384</span>)  <span class="comment"># 内积相似度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入记忆</span></span><br><span class="line">docs = [<span class="string">&quot;用户喜欢猫&quot;</span>, <span class="string">&quot;昨天搜索了寿司餐厅&quot;</span>, <span class="string">&quot;会议纪要：讨论新功能&quot;</span>]</span><br><span class="line">embeddings = embedder.encode(docs, normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">index.add(np.array(embeddings))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询检索</span></span><br><span class="line">query = <span class="string">&quot;找一家日本料理店&quot;</span></span><br><span class="line">q_emb = embedder.encode([query], normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">scores, idx = index.search(q_emb, k=<span class="number">2</span>)</span><br><span class="line">retrieved = [docs[i] <span class="keyword">for</span> i <span class="keyword">in</span> idx[<span class="number">0</span>]]</span><br><span class="line"><span class="built_in">print</span>(retrieved)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 改进方向：加上时间/任务过滤，形成 Hybrid 检索。</span></span><br></pre></td></tr></table></figure><p>✅ 优点：语义泛化强，易实现<br>⚠️ 缺点：可能召回“看似相关”的错误记忆（例如“猫”与“寿司”都和“喜欢”同义）</p><br/><h3 id="2-稀疏检索与混合检索（Sparse-Dense-Hybrid）"><a href="#2-稀疏检索与混合检索（Sparse-Dense-Hybrid）" class="headerlink" title="2. 稀疏检索与混合检索（Sparse + Dense Hybrid）"></a>2. 稀疏检索与混合检索（Sparse + Dense Hybrid）</h3><p>BM25 等稀疏方法对关键词精确匹配更可靠，可与向量检索融合：<br>最终得分 &#x3D; α * dense_score + (1 - α) * bm25_score</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hybrid 检索</span></span><br><span class="line"><span class="keyword">from</span> rank_bm25 <span class="keyword">import</span> BM25Okapi</span><br><span class="line"></span><br><span class="line">corpus = [doc.split() <span class="keyword">for</span> doc <span class="keyword">in</span> docs]</span><br><span class="line">bm25 = BM25Okapi(corpus)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hybrid_search</span>(<span class="params">query, topk=<span class="number">3</span>, alpha=<span class="number">0.6</span></span>):</span><br><span class="line">    q_emb = embedder.encode([query], normalize_embeddings=<span class="literal">True</span>)</span><br><span class="line">    dense_scores, idx = index.search(q_emb, k=<span class="built_in">len</span>(docs))</span><br><span class="line">    bm25_scores = bm25.get_scores(query.split())</span><br><span class="line"></span><br><span class="line">    combined = []</span><br><span class="line">    <span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs):</span><br><span class="line">        dense = <span class="built_in">float</span>(np.dot(q_emb, embedder.encode([doc], normalize_embeddings=<span class="literal">True</span>).T))</span><br><span class="line">        score = alpha * dense + (<span class="number">1</span> - alpha) * bm25_scores[i]</span><br><span class="line">        combined.append((score, doc))</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(combined, key=<span class="keyword">lambda</span> x: -x[<span class="number">0</span>])[:topk]</span><br></pre></td></tr></table></figure><p>✅ 优点：平衡语义与精确匹配，适合问答与代码检索<br>⚠️ 缺点：参数 α 需按语料调节，否则会失衡</p><br/><h3 id="3-图式检索（Graph-Retrieval）"><a href="#3-图式检索（Graph-Retrieval）" class="headerlink" title="3. 图式检索（Graph Retrieval）"></a>3. 图式检索（Graph Retrieval）</h3><p>将记忆组织为事件或知识图谱，更适合任务型 Agent（如工具调用日志、人物关系、因果事件）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">G = nx.Graph()</span><br><span class="line">G.add_edge(<span class="string">&quot;任务A&quot;</span>, <span class="string">&quot;任务B&quot;</span>, relation=<span class="string">&quot;前置&quot;</span>)</span><br><span class="line">G.add_edge(<span class="string">&quot;用户A&quot;</span>, <span class="string">&quot;任务B&quot;</span>, relation=<span class="string">&quot;触发&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">graph_retrieve</span>(<span class="params">node, relation=<span class="literal">None</span></span>):</span><br><span class="line">    neighbors = []</span><br><span class="line">    <span class="keyword">for</span> n, attr <span class="keyword">in</span> G[node].items():</span><br><span class="line">        <span class="keyword">if</span> relation <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> attr[<span class="string">&quot;relation&quot;</span>] == relation:</span><br><span class="line">            neighbors.append(n)</span><br><span class="line">    <span class="keyword">return</span> neighbors</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(graph_retrieve(<span class="string">&quot;任务A&quot;</span>))  <span class="comment"># -&gt; [&#x27;任务B&#x27;]</span></span><br></pre></td></tr></table></figure><p>✅ 优点：可解释、支持多跳推理<br>⚠️ 缺点：构建与维护成本高，适合结构化日志&#x2F;工具链场景</p><br/><h3 id="4-元数据过滤与上下文路由"><a href="#4-元数据过滤与上下文路由" class="headerlink" title="4. 元数据过滤与上下文路由"></a>4. 元数据过滤与上下文路由</h3><p>在语义检索前，先用元信息过滤搜索空间：<br>如「同会话」「同用户」「近7天」「主题&#x3D;工具调用」等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">metadata_filter</span>(<span class="params">memory, user=<span class="literal">None</span>, topic=<span class="literal">None</span>, since=<span class="literal">None</span></span>):</span><br><span class="line">    results = memory</span><br><span class="line">    <span class="keyword">if</span> user:</span><br><span class="line">        results = [m <span class="keyword">for</span> m <span class="keyword">in</span> results <span class="keyword">if</span> m[<span class="string">&quot;user&quot;</span>] == user]</span><br><span class="line">    <span class="keyword">if</span> topic:</span><br><span class="line">        results = [m <span class="keyword">for</span> m <span class="keyword">in</span> results <span class="keyword">if</span> topic <span class="keyword">in</span> m[<span class="string">&quot;tags&quot;</span>]]</span><br><span class="line">    <span class="keyword">if</span> since:</span><br><span class="line">        results = [m <span class="keyword">for</span> m <span class="keyword">in</span> results <span class="keyword">if</span> m[<span class="string">&quot;timestamp&quot;</span>] &gt;= since]</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><p>✅ 优点：降低搜索噪声、提升召回精度<br>⚠️ 缺点：依赖高质量标注（tagging&#x2F;日志结构）</p><br/><h3 id="5-重排（Reranking）"><a href="#5-重排（Reranking）" class="headerlink" title="5. 重排（Reranking）"></a>5. 重排（Reranking）</h3><p>使用一个额外模型（Cross-Encoder 或 LLM）重新打分前 K 条结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;cross-encoder/ms-marco-MiniLM-L-6-v2&quot;</span>)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;cross-encoder/ms-marco-MiniLM-L-6-v2&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rerank</span>(<span class="params">query, candidates</span>):</span><br><span class="line">    inputs = tokenizer([[query, c] <span class="keyword">for</span> c <span class="keyword">in</span> candidates], padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">    scores = model(**inputs).logits.squeeze().detach().numpy()</span><br><span class="line">    ranked = [c <span class="keyword">for</span> _, c <span class="keyword">in</span> <span class="built_in">sorted</span>(<span class="built_in">zip</span>(scores, candidates), reverse=<span class="literal">True</span>)]</span><br><span class="line">    <span class="keyword">return</span> ranked</span><br></pre></td></tr></table></figure><p>✅ 优点：提升最终 Top-1 准确度<br>⚠️ 缺点：增加计算成本；通常仅用于检索后的 re-ranking</p><br/><h3 id="6-反思式检索（Self-RAG-x2F-Agentic-Retrieval）"><a href="#6-反思式检索（Self-RAG-x2F-Agentic-Retrieval）" class="headerlink" title="6. 反思式检索（Self-RAG &#x2F; Agentic Retrieval）"></a>6. 反思式检索（Self-RAG &#x2F; Agentic Retrieval）</h3><p>让 Agent 先自我评估检索结果是否足够，再决定是否“再搜一次”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">reflective_retrieve</span>(<span class="params">query</span>):</span><br><span class="line">    results = hybrid_search(query)</span><br><span class="line">    <span class="comment"># Step 1: 让 LLM 评估是否充分</span></span><br><span class="line">    assessment = llm(<span class="string">f&quot;是否足够回答此问题？结果如下：<span class="subst">&#123;results&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;不足&quot;</span> <span class="keyword">in</span> assessment:</span><br><span class="line">        new_query = llm(<span class="string">f&quot;请改写更精确的查询：<span class="subst">&#123;query&#125;</span>&quot;</span>)</span><br><span class="line">        results = hybrid_search(new_query)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><p>✅ 优点：适合复杂任务或模糊查询<br>⚠️ 缺点：多次调用 LLM，延迟较高；但往往带来最自然的“记忆感”</p><br/><h3 id="7-六大检索策略选型"><a href="#7-六大检索策略选型" class="headerlink" title="7. 六大检索策略选型"></a>7. 六大检索策略选型</h3><table><thead><tr><th>场景</th><th>推荐策略</th><th>说明</th></tr></thead><tbody><tr><td>对话类 Agent</td><td>Dense + Metadata Filter</td><td>快速、足够准确</td></tr><tr><td>企业知识问答</td><td>Hybrid + Rerank</td><td>平衡精度与覆盖</td></tr><tr><td>工具日志分析</td><td>Graph + 时间过滤</td><td>可解释、结构化</td></tr><tr><td>自反式 Agent</td><td>Self-RAG + Hybrid</td><td>智能自修正</td></tr></tbody></table><br/><br/><h2 id="六种策略，正是-RAG-的六种变体"><a href="#六种策略，正是-RAG-的六种变体" class="headerlink" title="六种策略，正是 RAG 的六种变体"></a>六种策略，正是 RAG 的六种变体</h2><p>到这里我们已经看完六种检索策略。<br>它们从语义相似、混合检索，到图式、重排、反思式检索——构成了一个完整的“找回记忆”的谱系。<br>那这些策略，与我们常说的 <strong>RAG（Retrieval-Augmented Generation）</strong> 又是什么关系？</p><br/><p>RAG 的核心逻辑其实很简单：<strong>先检索，再生成</strong>。<br>也就是说，当模型面对一个问题时，先到外部知识库中“查资料”，把相关文本取回来，再把这些资料和问题一起交给语言模型，生成最终回答。<br>这是一个流程定义，而不是具体算法。<br>换句话说，RAG 规定了“查资料”的框架，但没有规定“怎么查”。于是你看到的那些检索策略——Dense、Hybrid、Graph、Rerank、Self-RAG——其实都是在实现这个“查”的部分。它们是 RAG 框架的不同实现形态。</p><table><thead><tr><th>策略</th><th>对应的 RAG 阶段</th><th>说明</th></tr></thead><tbody><tr><td>语义相似检索</td><td>基础 RAG 检索</td><td>最标准、也是最常见的实现</td></tr><tr><td>稀疏&#x2F;混合检索</td><td>Hybrid RAG</td><td>融合语义与关键词得分，适合精准问答</td></tr><tr><td>图式检索</td><td>Graph RAG &#x2F; Knowledge RAG</td><td>以关系为索引的多跳检索</td></tr><tr><td>元数据过滤</td><td>Query Routing &#x2F; Filtered RAG</td><td>检索前预筛选，减少噪声</td></tr><tr><td>重排</td><td>RAG 后处理阶段（Reranker）</td><td>让模型重新打分、排序结果</td></tr><tr><td>反思式检索</td><td>Self-RAG &#x2F; Agentic Retrieval</td><td>让模型主动决定是否检索与改写查询</td></tr></tbody></table><br/><br/><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>记忆不是仓库，而是过滤器。<br>检索策略的设计，其实是在定义 Agent 的“注意力”模式，它决定 Agent 记忆的边界，也定义了它的思考深度。</p><br/><br/><p>❤ 下一篇，我会分享 Agent Memory 如何避免记忆漂移，让零散的信息变成稳定的知识。</p><br/><br/><br/><br/><br/><h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul><li><strong>Self-RAG：自反式检索</strong><br>Asai et al., Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection（2023）—提出在推理时自判是否需要检索，并对检索结果与生成进行自我评估&#x2F;再检索的闭环。可直接启发“反思触发+多轮检索”设计。</li><li><strong>A-MEM：Agentic Memory</strong><br>Xu et al., A-MEM: Agentic Memory for LLM Agents（2025）—借鉴 Zettelkasten，把记忆组织成相互链接的卡片网络，新记忆写入会触发历史记忆的动态更新与重连，增强检索与演化。适合做“结构化记忆+链接检索”。代码与评测开源。</li><li><strong>Generative Agents（经典）</strong><br>Park et al., Generative Agents（2023）—首次系统展示观察→记忆→反思→检索→计划的完整闭环，强调“反思生成更高层摘要记忆”。适合作为代理记忆系统的总体架构参考。</li><li><strong>Voyager（技能库检索）</strong><br>Wang et al., Voyager: An Open-Ended Embodied Agent（2023）—在 Minecraft 中用技能库（代码+描述Embedding）语义检索以复用行为。适合“可执行技能记忆”的检索范式对照。</li></ul>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/08/Memory-as-Thinking-How-Agents-Retrieve-What-Matters/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>把 MCP 放回它该在的位置</title>
      <link>https://blog.liluhui.cn/2025/10/03/Quick-Clarity-The-Key-Difference-Between-Agent-and-MCP/</link>
      <guid>https://blog.liluhui.cn/2025/10/03/Quick-Clarity-The-Key-Difference-Between-Agent-and-MCP/</guid>
      <pubDate>Fri, 03 Oct 2025 12:08:10 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;前阵子有朋友问我：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Agent 和 MCP 到底有什么区别啊？”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我当时愣了一下。&lt;/p&gt;
&lt;p&gt;这问题乍听很简单，甚至让人觉得是不是在“混淆概念”。&lt;/p&gt;
&lt;p&gt;但转念一想，没错啊。对于</description>
        
      
      
      
      <content:encoded><![CDATA[<p>前阵子有朋友问我：</p><blockquote><p>“Agent 和 MCP 到底有什么区别啊？”</p></blockquote><p>我当时愣了一下。</p><p>这问题乍听很简单，甚至让人觉得是不是在“混淆概念”。</p><p>但转念一想，没错啊。对于刚入行的人来说，<strong>各种 buzzword 像弹幕一样飞来</strong>，Agent、MCP、RAG、LangChain……乍一看都差不多，背后却完全不是一回事。</p><p>我决定写下这篇文章。</p><p>不是为了定义概念，而是想<strong>把它们放回该在的位置</strong>。这样以后遇到选择，就不会懵逼。</p><br/><br/><h2 id="Agent-是人，MCP-是语言"><a href="#Agent-是人，MCP-是语言" class="headerlink" title="Agent 是人，MCP 是语言"></a>Agent 是人，MCP 是语言</h2><p>如果把 Agent 比作一个人：</p><ul><li>眼睛耳朵是 <strong>感知</strong>（输入）</li><li>大脑是 <strong>认知与推理</strong>（记忆、判断）</li><li>决定去做什么是 <strong>决策</strong></li><li>动手去做是 <strong>执行</strong></li><li>事后总结经验是 <strong>反馈</strong></li></ul><p>而 <strong>MCP</strong> 呢？</p><p><strong>它不是另一个“大脑”，而是这人和外部世界说话时，用的通用语言。</strong></p><p>Agent 想用锤子、笔记本、数据库……如果没有通用语言，就只能每次“手舞足蹈”解释一遍。但有了 MCP，像插 USB 一样——对接标准统一了，沟通就不再痛苦。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/10/3/08_56_48%20PM.png" class="left" width="500"><br/><br/> <h2 id="三种方式接工具"><a href="#三种方式接工具" class="headerlink" title="三种方式接工具"></a>三种方式接工具</h2><p>作为开发者，我自己踩过的坑大概分三种：</p><ul><li><strong>直连 API</strong>：最省事，写几行代码就能跑。但工具一多，就像每个家电都要单独插线，很快乱成一团。</li><li><strong>自建网关</strong>：给工具统一写一层包装，好一点，但维护起来累。</li><li><strong>MCP 协议</strong>：就像买了插排，谁来都能插，但前提是大家都认这个标准。</li></ul><p>所以 MCP 解决的不是“有没有 Agent”，而是“工具怎么接得更省心”。</p><br/><br/><h2 id="什么时候该用-MCP？"><a href="#什么时候该用-MCP？" class="headerlink" title="什么时候该用 MCP？"></a>什么时候该用 MCP？</h2><p>我很喜欢把问题拆成“要不要现在就做”。</p><p><strong>推荐用 MCP 的场景：</strong></p><ul><li>你要接的工具特别多、特别杂。</li><li>你想做一个“插件市场”，别人开发的工具也能接进来。</li><li>你的团队很大，需要统一接口和权限。</li></ul><p><strong>不急着用 MCP 的场景：</strong></p><ul><li>你只有 1-2 个工具，跑起来最重要。</li><li>原型阶段，时间比优雅更关键。</li><li>场景完全内网，不需要和别人兼容。</li></ul><p>说白了：<strong>MCP 是标准，不是魔法</strong>。 如果你的产品还在“验证能不能跑”，先别急着上。</p><br/><br/><h2 id="渐进路线（我自己走过的）"><a href="#渐进路线（我自己走过的）" class="headerlink" title="渐进路线（我自己走过的）"></a>渐进路线（我自己走过的）</h2><p>做产品的时候，我的演进路线大概是：</p><ol><li><strong>先直连 API</strong>：把东西跑起来，先看到结果。</li><li><strong>工具变多了</strong>：抽象一层接口，否则维护起来要崩溃。</li><li><strong>产品要规模化</strong>：再考虑 MCP，把“工具接入”完全标准化。</li></ol><p>我不是一开始就追 MCP，而是把它当作未来的一步。<br>有点像盖房子：先把砖垒起来，等真的要接水电气，再考虑用不用品质更好的插座系统。</p><br/><br/><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>所以，Agent 和 MCP 不是一回事：</p><ul><li><strong>Agent 是大脑+身体，去做事。</strong></li><li><strong>MCP 是语言+插口，帮它对接外部世界。</strong></li></ul><br/><p>理解这一点，你就不会再问“Agent 和 MCP 是不是一个东西”，而会问：</p><p><strong>“我的产品阶段，需不需要 MCP？”</strong></p><p>我觉得这才是更有价值的问题。</p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/03/Quick-Clarity-The-Key-Difference-Between-Agent-and-MCP/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/09 Review</title>
      <link>https://blog.liluhui.cn/2025/10/02/202509/</link>
      <guid>https://blog.liluhui.cn/2025/10/02/202509/</guid>
      <pubDate>Thu, 02 Oct 2025 07:47:22 GMT</pubDate>
      
      <description>鸟站在枝头宁静安详，不是因为它知道树枝不会断，而是因为它知道自己有翅膀。</description>
      
      
      
      <content:encoded><![CDATA[<p><em>鸟站在枝头 宁静安详<br>不是因为它知道树枝不会断<br>而是因为它知道自己有翅膀</em></p><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br><strong>绝大部分小企业从未被吃掉，大鱼想吃的是其它大鱼。</strong></p><p>在开始一滩事情之前就害怕被各路资本抄袭没什么好处，不如期待做大了就共舞，做不大就守护好自己的先进奶牛，先把事情跑起来再说。<br>今天，我想赚小而美的90%，而不是大而全的0.1%。</p><br/><p>02<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/10/2/002.png" alt="image"></p><p>最近的自媒体数据非常稳定的增长中，再次见证复利的力量，第一个月积累100粉，第二月达成500粉，即将完成第三个月1000粉。看着自己的产品有人使用，还是蛮开心的。也加入了科技薯的创作者社区，和前辈们交流取经。<br>目前内容方面精力有限，优先还是产品侧投入，内容主要是 数学几何画板的功能宣传 和 Agent构建相关知识科普，Q4 再继续探索探索。</p><br/><p>03<br>不舒服，让自己动起来。<br>舒服了，也让自己动起来。<br>经历过就会感谢 <strong>“体验-创造-分享-爱”</strong> 这个循环，在此之前，第一步是行动起来。</p><br/><p>04<br><strong>会买才会卖。</strong></p><p>当你真真正正能辨析自己的消费背后的需求和投射的情绪和认知，一个是会降低很多莫名其妙的消费，第二个是你也能在业务中间去创建一个理解用户需求的过程，同时你还学会了不去评价这些事情 。</p><p><strong>精分十年不出门，占星三年打死人。</strong></p><p>很嘲讽是吧，学精神分析十年都没把自己搞明白，学星盘三年就能出来干收费1500的咨询，为什么？</p><p>这是两个产品，一个要求自己被精神分析的人，是希望通过把理性照入自己的潜意识里，深度看到自己人性的善与恶后，通过自己的意志力来改变。而星盘解决的是，我有好多想法，甚至是有确定的想法，我需要一个人给我答案。<br><br/><br><br/></p><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>把最近Agent工程实践中学习和落地的知识进行梳理，这个月写了四篇文章，同步更新到博客、公众号、小红书了，这个方向随着书写越挖越深，可以写的东西也从最开始的框架选择、架构思路越来越细越拓越宽，这就是 Learn In Public 的魔力吧。</p><ul><li><a href="https://blog.liluhui.cn/2025/09/05/6-Design-Principles-I-Learned-from-Claude-Code/">从 Claude Code 学的 6 个设计铁律（含 prompts&#x2F;tool 清单）</a></li><li><a href="https://mp.weixin.qq.com/s/dy2q4omQ_GzT9alPyLJB5w">22 个顶级 Agent 工作流框架整理</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzU2NTg1ODk2Mg==&mid=2247483810&idx=1&sn=1a7e92a0a2d875e17b531a618e8b632c&chksm=fcb4065fcbc38f4996d86bff572567f7125f8ab5963014098c10f078d7411e9a1ffb72cbb2a5&cur_album_id=4172082496760184844&scene=189#wechat_redirect">Agent 记忆的五层模型</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzU2NTg1ODk2Mg==&mid=2247483835&idx=1&sn=acd4c7440435a8f721ea3cb9d8609126&chksm=fcb40646cbc38f50d7449907372c9e00ec7ebdd958f46c376f64a06657761695ff269eb5699a&cur_album_id=4172082496760184844&scene=189#wechat_redirect">Agent 记忆写入三大策略，决定“记什么”的工程学</a></li></ul><br/><p>02<br>大角几何画板9月份重点都放在了构建全新的 Agent workflow 流程以及各种 Bad Case 的优化，也已经进入积累用户反馈的问题&#x2F;需求池，逐步解决的情况中了，目前属于有很多可以做的也缺很多对标功能，但在优势上依然没有放大到验证有效的阶段。<br>截止9月底产品已经有3000+有效用户了，其中1000+认为是有效激活的，用户画像也开始更丰富，从基本是教师和数学从业者，增加了一些爱好者、学生和家长。<br>目前产品算是持续有进展，但还没到阶段性里程碑的程度，小团队内部的分歧也导致发力方向的混乱，这些都是客观存在的问题，希望产品发展越来越好。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/10/2/003.png" alt="image"><br><br/><br><br/></p><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br>加入了霖子的瑜伽工作室，开始加强训练，这个月取得了蛮不错的进步。轮式的耐力明显增长了很多个呼吸；尝试了很多从没做过的进阶动作，以前不敢的鹤蝉式转头倒立也不害怕了；倒立的跳跃也明显少了些恐惧，虽然也很难一步到位就不害怕了，但我清晰充分感受到自己的变化 … 这就是瑜伽提示练习带来的增加勇气吧！<br>要夸夸自己本月取得的阶段成就：肘倒立能独立定住3秒、三点头倒立髋腿能自己立起了、不规则头倒立稳定可以起来、骆驼转轮从力量控不住起不来到能独立完成、站立上下轮完成、鸽王从非常紧张到能自己去深入的感觉。虽然有非常多可以继续努力的力量和伸展，也有很多不完美，总之感激本月取得的进步！</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/10/2/004.png" alt="image"><br><br/></p><p>02<br>吃到了好爽的战斧牛排 ！ （太腻了，下次不吃了）</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/10/2/005.png" alt="image"></p><br/><p>03<br>团建去海边吃了海鲜、放了烟花 ~（其实很想回家干活）</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/10/2/006.jpg" alt="image"></p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/02/202509/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Agent 记忆写入策略：如何决定“记什么”？</title>
      <link>https://blog.liluhui.cn/2025/10/01/What-Should-an-Agent-Remember-Writing-Strategies-Inspired-by-Human-Memory/</link>
      <guid>https://blog.liluhui.cn/2025/10/01/What-Should-an-Agent-Remember-Writing-Strategies-Inspired-by-Human-Memory/</guid>
      <pubDate>Wed, 01 Oct 2025 09:27:33 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;在&lt;a href=&quot;https://blog.liluhui.cn/2025/09/19/Agent-Memory-Five-Layer-Model-and-Engineering-Implementation/&quot;&gt;上一篇文章&lt;/a&gt;里，我聊过 &lt;strong&gt;Agent </description>
        
      
      
      
      <content:encoded><![CDATA[<p>在<a href="https://blog.liluhui.cn/2025/09/19/Agent-Memory-Five-Layer-Model-and-Engineering-Implementation/">上一篇文章</a>里，我聊过 <strong>Agent 记忆的五层模型</strong>。那篇文章更多是框架视角：我们需要区分短期记忆、长期记忆、情景记忆、语义记忆、技能记忆等等。<br>但是，当真正开始在工程里落地的时候，很多人会遇到一个更具体的问题：</p><blockquote><p>Agent 每天都在接收大量输入，但不可能把所有内容都存下来。那，究竟应该“记什么”？</p></blockquote><p>这个问题听起来简单，背后却很关键。因为一旦写入策略没设计好，要么记忆库很快“垃圾堆积”，要么遗漏了用户真正关心的事实。今天就来聊聊 <strong>记忆写入策略</strong>。</p><br/><h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2><p>多轮对话 Agent 不可能“什么都记”，关键是设计写入策略。<br>本文总结了三种常用方法，并给出 LangGraph + 向量库的代码示例：</p><ul><li><strong>LLM 打分（重要性）</strong>：让大模型自己评估一条信息对未来是否重要，重要才写入。</li><li><strong>相似度检测（新颖性）</strong>：用 embedding 检查新信息是否与已有记忆相似，避免重复存储。</li><li><strong>计数与蒸馏（高频性）</strong>：对重复出现的信息进行计数，达到阈值后用 LLM 总结为一条稳定事实。</li></ul><p>这三种策略往往要<strong>混合使用</strong>，才能既不遗漏关键信息，也避免记忆库膨胀。</p><br/><h2 id="策略一：LLM-打分（重要性）"><a href="#策略一：LLM-打分（重要性）" class="headerlink" title="策略一：LLM 打分（重要性）"></a>策略一：LLM 打分（重要性）</h2><p>第一种策略很直接：<strong>让模型自己判断</strong>。<br>做法是：在对话后，把新信息丢给一个 LLM，让它用自然语言理解的能力打一个 “重要性分数”。比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">请根据以下事件对未来是否重要打分（1-10）：</span><br><span class="line">“用户告诉你她最喜欢喝黑咖啡。”</span><br></pre></td></tr></table></figure><p>测试设定一个合适的阈值，分数高于这个阈值 → 写入长期记忆，分数低于这个阈值 → 丢掉或只保留在短期上下文。<br>这种方法在 Generative Agents 论文里就被用过。研究发现，模型给出的打分，和人类直觉其实挺接近的。</p><p>优点：</p><ul><li>能理解上下文的语义，不只是关键词匹配。</li><li>灵活，可以针对不同任务改写 prompt。</li></ul><p>缺点：</p><ul><li>每次都要额外调用 LLM，成本较高。</li><li>打分可能不稳定（受 prompt 影响）。</li></ul><p>但即便如此，作为第一道“筛子”，它仍然很实用。</p><br/><h2 id="策略二：相似度检测（新颖性）"><a href="#策略二：相似度检测（新颖性）" class="headerlink" title="策略二：相似度检测（新颖性）"></a>策略二：相似度检测（新颖性）</h2><p>第二种方法是<strong>避免重复</strong>。<br>我们可以把每条候选记忆编码成向量，存入一个向量数据库（比如 FAISS、Chroma、Weaviate）。<br>当新内容出现时，先检索一下：如果相似度很高，说明这东西之前就存过。→ 不新建，只更新一下计数或时间戳。如果相似度很低，说明这是全新的信息。→ 写入为新记忆。<br>例如：第一次用户说“我喜欢咖啡” → 存下来。后来又说“我很爱喝黑咖啡” → 与已有记忆相似度很高 → 不新建，而是给原记忆增加一个“+1 出现次数”。</p><p>优点：</p><ul><li>避免记忆冗余。</li><li>让记忆库保持精炼。</li></ul><p>缺点：</p><ul><li>阈值难调。过高会漏掉细微差别，过低又容易写入重复。</li></ul><br/><h2 id="策略三：计数与蒸馏（高频性）"><a href="#策略三：计数与蒸馏（高频性）" class="headerlink" title="策略三：计数与蒸馏（高频性）"></a>策略三：计数与蒸馏（高频性）</h2><p>第三种思路是<strong>重复即重要</strong>。<br>人类也是这样：别人随口说一次的话我们可能忘记，但如果一再强调，我们会牢牢记住。<br>在 Agent 中，可以通过“计数器”实现：每次遇到类似的事实，就给计数 +1。当 count ≥ 阈值（比如 3），触发一次总结：用 LLM 把这几次重复的信息，合并成一条稳定的长期记忆。</p><p>比如： “我喜欢咖啡” 出现了 3 次 → 总结为一条稳定记忆：“用户偏好：咖啡”。</p><p>这样做的好处是：</p><ul><li>记忆越来越浓缩，避免无限膨胀。</li><li>高频事实得到强化，和人类习惯接近。</li></ul><br/><h2 id="实战示例：LangGraph-向量库"><a href="#实战示例：LangGraph-向量库" class="headerlink" title="实战示例：LangGraph + 向量库"></a>实战示例：LangGraph + 向量库</h2><p>下面是我写的一个简化的 demo，展示如何把三种策略放到一个 写入节点 里。这里我用 LangGraph 来组织流程，用 FAISS 来做相似度搜索。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 LLM 和向量库</span></span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>)</span><br><span class="line">vectorstore = FAISS.load_local(<span class="string">&quot;memory_index&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_writer</span>(<span class="params">state</span>):</span><br><span class="line">    text = state[<span class="string">&quot;observation&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 重要性打分</span></span><br><span class="line">    score = llm.predict(<span class="string">f&quot;请对以下内容打分（1-10）重要性：<span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">int</span>(score) &lt; <span class="number">6</span>:</span><br><span class="line">        <span class="keyword">return</span> state  <span class="comment"># 分数太低，不写入</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 相似度检测</span></span><br><span class="line">    docs = vectorstore.similarity_search(text, k=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> docs <span class="keyword">and</span> docs[<span class="number">0</span>].score &gt; <span class="number">0.9</span>:</span><br><span class="line">        <span class="comment"># 已存在 → 更新计数</span></span><br><span class="line">        docs[<span class="number">0</span>].metadata[<span class="string">&quot;count&quot;</span>] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> docs[<span class="number">0</span>].metadata[<span class="string">&quot;count&quot;</span>] &gt;= <span class="number">3</span>:</span><br><span class="line">            summary = llm.predict(<span class="string">f&quot;总结以下信息为一条稳定事实：<span class="subst">&#123;docs[<span class="number">0</span>].page_content&#125;</span>&quot;</span>)</span><br><span class="line">            vectorstore.update(docs[<span class="number">0</span>].<span class="built_in">id</span>, summary)</span><br><span class="line">        <span class="keyword">return</span> state</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 新建记忆</span></span><br><span class="line">    vectorstore.add_texts([text], metadatas=[&#123;<span class="string">&quot;count&quot;</span>: <span class="number">1</span>&#125;])</span><br><span class="line">    <span class="keyword">return</span> state</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 LangGraph 中注册节点</span></span><br><span class="line">graph = StateGraph()</span><br><span class="line">graph.add_node(<span class="string">&quot;memory_writer&quot;</span>, memory_writer)</span><br></pre></td></tr></table></figure><p>这只是最简版骨架，真正的系统里可以扩展：</p><ul><li>importance_score 和 similarity_score 可以做加权平均。</li><li>高频性总结可以用更复杂的聚类 + LLM 总结。</li><li>遗忘机制（衰减 &#x2F; FIFO 替换）也可以接上。</li></ul><br/><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>大语言模型的上下文长度是有限的。就算用上 100k、甚至百万级上下文，你也不会想把所有历史对话原样塞进去。<br>写入策略决定了 Agent 的“人格”——它记什么，忘什么，直接影响了用户体验。<br>写入必须有一个“门槛”，类似人脑的选择性记忆。我们往往只会保留：</p><ul><li><strong>重要的</strong>：影响未来决策的事情 → 避免噪音。</li><li><strong>新鲜的</strong>以前没出现过的事实 → 避免冗余</li><li><strong>高频的</strong>：多次重复强调的偏好 → 提炼知识</li></ul><p>工程上，三种策略往往是混合使用。<br>我的建议是：</p><ul><li>从最简单的相似度检测开始，先解决重复存储问题。</li><li>再加上 LLM 打分和高频总结，让记忆越来越“聪明”。</li></ul><p>下一篇，我会聊 <strong>记忆的检索与遗忘</strong> ——如何从一大堆记忆里找回最相关的那几条，以及如何避免记忆库无限膨胀。</p><br/><h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul><li><a href="https://arxiv.org/abs/2304.03442">Generative Agents (Park et al. 2023)</a> —— 引入重要性打分与反思机制  </li><li><a href="https://arxiv.org/abs/2404.13501">A Survey on Memory Mechanism of LLM-based Agents (Zhang et al. 2024)</a> —— 全景综述  </li><li><a href="https://github.com/ALucek/agentic-memory">AgenticMemory (GitHub)</a> —— 动态记忆库的开源实现  </li><li><a href="https://github.com/letta-ai/letta">Letta&#x2F;MemGPT (GitHub)</a> —— 带长期记忆的 Agent 框架</li></ul><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/10/01/What-Should-an-Agent-Remember-Writing-Strategies-Inspired-by-Human-Memory/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Agent 记忆五层模型与工程落地</title>
      <link>https://blog.liluhui.cn/2025/09/19/Agent-Memory-Five-Layer-Model-and-Engineering-Implementation/</link>
      <guid>https://blog.liluhui.cn/2025/09/19/Agent-Memory-Five-Layer-Model-and-Engineering-Implementation/</guid>
      <pubDate>Fri, 19 Sep 2025 03:27:20 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;对话式大模型 Agent 的「记忆」问题，本质就是：&lt;strong&gt;如何让机器像人一样，不只是即时回答，而是能记住过去、理解现在、影响未来。&lt;/strong&gt;&lt;br&gt;过去两年，学术界和工业界已经逐渐形成一个共识：记忆需要分层，不同层次解决不同问题。下面我用一个五层模型，带你</description>
        
      
      
      
      <content:encoded><![CDATA[<p>对话式大模型 Agent 的「记忆」问题，本质就是：<strong>如何让机器像人一样，不只是即时回答，而是能记住过去、理解现在、影响未来。</strong><br>过去两年，学术界和工业界已经逐渐形成一个共识：记忆需要分层，不同层次解决不同问题。下面我用一个五层模型，带你快速建立完整认知。</p><br/><h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2><p>Agent Memory 的五层模型，就像人类大脑的结构化记忆系统。</p><ul><li><strong>工作记忆负责即时</strong></li><li><strong>情景记忆负责事件</strong></li><li><strong>语义记忆负责知识</strong></li><li><strong>程序性记忆负责技能</strong></li><li><strong>外部持久记忆负责归档</strong></li></ul><p>业界工程实践已经逐步达成共识：<strong>分层 + 策略化 + 可控</strong>。这是未来对话式 Agent 真正“有记忆力”的基础。</p><br/><h2 id="1-工作记忆（Working-Memory）"><a href="#1-工作记忆（Working-Memory）" class="headerlink" title="1. 工作记忆（Working Memory）"></a>1. 工作记忆（Working Memory）</h2><ul><li><strong>定义</strong>：Agent 当前正在处理的上下文，类似人类的「短时记忆」。</li><li><strong>特点</strong>：存活时间短、容量有限，常常就是一段对话上下文窗口。</li><li><strong>类比</strong>：你在和朋友聊天时，能记住刚才说的两三句话。</li><li><strong>实现方式</strong>：<ul><li>LLM prompt 窗口（context window）</li><li>Scratchpad 技巧（中间步骤写出来）</li></ul></li><li><strong>代表案例</strong>：LangChain 的 <code>ConversationBuffer</code>、ChatGPT 的当前对话历史。</li></ul><br/><h2 id="2-情景记忆（Episodic-Memory）"><a href="#2-情景记忆（Episodic-Memory）" class="headerlink" title="2. 情景记忆（Episodic Memory）"></a>2. 情景记忆（Episodic Memory）</h2><ul><li><strong>定义</strong>：记录「事件」和「经历」，带时间线，能追溯发生了什么。</li><li><strong>特点</strong>：和具体时刻挂钩，经常包含“失败&#x2F;成功的经验”与“反思日志”。</li><li><strong>类比</strong>：你记得昨天在咖啡馆聊过天，记得过程和情绪。</li><li><strong>实现方式</strong>：<ul><li>把对话片段存档，并打上时间戳</li><li>提炼重要片段（反思）作为索引</li></ul></li><li><strong>代表论文</strong>：<ul><li><a href="https://arxiv.org/abs/2304.03442"><em>Generative Agents</em>（2023）</a>：Agent 在虚拟小镇中记忆、反思、规划。</li><li><a href="https://arxiv.org/abs/2303.11366"><em>Reflexion</em>（2023）</a>：让 Agent 自己“写日志”，从错误中学习。</li></ul></li></ul><br/><h2 id="3-语义记忆（Semantic-Memory）"><a href="#3-语义记忆（Semantic-Memory）" class="headerlink" title="3. 语义记忆（Semantic Memory）"></a>3. 语义记忆（Semantic Memory）</h2><ul><li><strong>定义</strong>：长期积累的「事实、知识、用户画像」。</li><li><strong>特点</strong>：和时间无关，更像百科或人物设定。</li><li><strong>类比</strong>：你记得朋友喜欢喝拿铁，这是稳定的知识。</li><li><strong>实现方式</strong>：<ul><li>向量数据库（Qdrant、Weaviate、FAISS）存储事实与偏好</li><li>知识图谱记录“人-事-关系”</li></ul></li><li><strong>代表论文&#x2F;项目</strong>：<ul><li><a href="https://arxiv.org/abs/2305.10250"><em>MemoryBank</em>（2023）</a>：持续对话中生成用户画像</li><li><a href="https://docs.mem0.ai/open-source/graph_memory/overview"><em>Mem0 Graph Memory</em>（2024）</a>：结构化保存人物与事件关系</li></ul></li></ul><br/><h2 id="4-程序性记忆（Procedural-Memory）"><a href="#4-程序性记忆（Procedural-Memory）" class="headerlink" title="4. 程序性记忆（Procedural Memory）"></a>4. 程序性记忆（Procedural Memory）</h2><ul><li><strong>定义</strong>：Agent 学到的「技能」或「操作套路」。</li><li><strong>特点</strong>：不是单纯事实，而是“知道如何做”。</li><li><strong>类比</strong>：你不用思考就能骑自行车、写一封邮件。</li><li><strong>实现方式</strong>：<ul><li>把常见操作总结成工具调用范式</li><li>动态 Few-Shot 示例库（常用推理模板）</li></ul></li><li><strong>工程案例</strong>：<ul><li><a href="https://www.langchain.com/langgraph">LangGraph</a> 中，Agent 会学习常用任务的状态流转</li><li><a href="https://github.com/microsoft/autogen">Copilot&#x2F;AutoGen</a> 把编辑-执行-调试形成可复用的模式</li></ul></li></ul><br/><h2 id="5-外部持久记忆（External-x2F-Persistent-Memory）"><a href="#5-外部持久记忆（External-x2F-Persistent-Memory）" class="headerlink" title="5. 外部持久记忆（External&#x2F;Persistent Memory）"></a>5. 外部持久记忆（External&#x2F;Persistent Memory）</h2><ul><li><strong>定义</strong>：超越上下文的长期存储，像“硬盘”。</li><li><strong>特点</strong>：支持无限扩展，必须解决检索与整理问题。</li><li><strong>类比</strong>：你写日记、建笔记本，未来可以随时翻查。</li><li><strong>实现方式</strong>：<ul><li>向量库 + 图数据库 + 文档存储</li><li>分层存储（高频缓存 vs. 历史归档）</li></ul></li><li><strong>代表论文&#x2F;工程</strong>：<ul><li><a href="https://arxiv.org/abs/2310.08560"><em>MemGPT</em>（2023）</a>：提出“内存分页&#x2F;中断”机制，像操作系统一样管理记忆</li><li>LangGraph × MongoDB（2024）：提供标准化的 <a href="https://www.mongodb.com/company/blog/product-release-announcements/powering-long-term-memory-for-agents-langgraph">Memory Store</a></li></ul></li></ul><br/><h2 id="工程落地的常见共识"><a href="#工程落地的常见共识" class="headerlink" title="工程落地的常见共识"></a>工程落地的常见共识</h2><h3 id="1-分层设计"><a href="#1-分层设计" class="headerlink" title="1. 分层设计"></a>1. 分层设计</h3><p>人类的记忆本来就是分层的：我们能在几秒钟里复述一串电话号码，却会在多年后仍然记得一次重要的旅行。工程上的 Agent 也是这样。短期的、随时会遗忘的“工作记忆”，与长期的、可以反复翻阅的“档案室”，需要用不同的方式去保存与检索。于是，分层设计成为共识：即时信息放在快取里，长期知识则交给更稳定的存储系统。就像书桌上的便签和书架上的厚厚档案，功能完全不同，却缺一不可。</p><p><strong>短期记忆 vs 长期记忆，采用不同存储与检索策略。</strong><br><br/></p><h3 id="2-写入策略"><a href="#2-写入策略" class="headerlink" title="2. 写入策略"></a>2. 写入策略</h3><p>想象一下，如果我们把每一句废话都写进日记，很快就会被无穷无尽的记录淹没。Agent 也是如此，它不能也不应该记住一切。于是，工程师们给它设定了选择标准：只有重要的（关系到目标或用户画像）、新颖的（之前未曾出现）、高频的（重复多次的事实）才会进入长期记忆。换句话说，Agent 的记忆更像是一本精选集，而不是毫无筛选的逐字稿。</p><p><strong>写入策略不是所有内容都要保存，只记“重要&#x2F;新颖&#x2F;高频”的。</strong><br><br/></p><h3 id="3-检索策略"><a href="#3-检索策略" class="headerlink" title="3. 检索策略"></a>3. 检索策略</h3><p>当记忆被写入，另一个问题随之而来：如何在需要时找到它？最初的做法往往依赖语义相似度，把提问和记忆做 embedding 比较。但很快，人们发现这还不够。因为有些信息不仅要“像”，还要“新”——时间因素不可或缺；有些信息要靠“重要性”来区分，避免被琐碎淹没。所以今天的检索策略更像是一场多维度的评分：语义相关、时间新鲜、重要程度，三者一起决定结果。</p><p><strong>检索策略不仅仅靠语义相似度，还要结合时间性和重要性。</strong><br><br/></p><h3 id="4-整理与巩固"><a href="#4-整理与巩固" class="headerlink" title="4. 整理与巩固"></a>4. 整理与巩固</h3><p>长久使用下来，任何系统都会遇到“记忆漂移”的问题：重复、矛盾、甚至遗忘关键信息。解决办法和人类差不多——定期整理。工程实践里，这意味着定时运行批处理，把零散的对话压缩成主题摘要，把重复的事实合并为一个清晰的条目。就像我们清理电脑文件夹，把散落各处的文档归档成整洁的文件夹，方便未来的自己。</p><p><strong>定期把零散内容压缩为摘要，避免“记忆漂移”</strong><br><br/></p><h3 id="5-透明与可控"><a href="#5-透明与可控" class="headerlink" title="5. 透明与可控"></a>5. 透明与可控</h3><p>最后，还有一个关乎信任的问题。人们普遍认为，Agent 的记忆不能是“黑箱”，用户必须能看见并掌控。用户应该知道系统记住了什么，也能在必要时删除、修改或屏蔽。ChatGPT、Claude 等主流产品已经在这一点上给出实践：用户可以进入设置界面，看到自己的“记忆”，甚至要求系统“忘掉”某些事实。这种透明和可控，不仅是工程最佳实践，更是赢得用户信赖的关键。</p><p><strong>产品化下用户能看到、编辑甚至删除 Agent 的记忆。</strong></p><br/><h2 id="延伸阅读与资料"><a href="#延伸阅读与资料" class="headerlink" title="延伸阅读与资料"></a>延伸阅读与资料</h2><ul><li><strong>论文</strong>：<ul><li><a href="https://arxiv.org/abs/2304.03442"><em>Generative Agents</em> (2023)</a></li><li><a href="https://arxiv.org/abs/2303.11366"><em>Reflexion</em> (2023)</a></li><li><a href="https://arxiv.org/abs/2310.08560"><em>MemGPT</em> (2023)</a></li><li><a href="https://arxiv.org/abs/2305.10250"><em>MemoryBank</em> (2023)</a></li><li><a href="https://arxiv.org/abs/2402.17753"><em>LoCoMo</em> (2024, 长对话记忆评测基准)</a></li></ul></li><li><strong>框架文档</strong>：<ul><li><a href="https://langchain-ai.github.io/langgraph/concepts/memory/">LangGraph Memory</a></li><li><a href="https://developers.llamaindex.ai/python/framework/module_guides/deploying/agents/memory/">LlamaIndex Memory</a></li><li><a href="https://microsoft.github.io/autogen/0.2/docs/ecosystem/agent-memory-with-zep/">AutoGen Memory &amp; Zep</a></li><li><a href="https://docs.crewai.com/en/concepts/memory">CrewAI Long-term Memory</a></li></ul></li></ul><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/09/19/Agent-Memory-Five-Layer-Model-and-Engineering-Implementation/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>🌅 22 个顶级 Agent 工作流框架整理</title>
      <link>https://blog.liluhui.cn/2025/09/12/22-top-level-Agent-workflow-frameworks-organized/</link>
      <guid>https://blog.liluhui.cn/2025/09/12/22-top-level-Agent-workflow-frameworks-organized/</guid>
      <pubDate>Fri, 12 Sep 2025 01:56:16 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;最近在做一个新的独立开发产品，核心功能里涉及到 多智能体协作。&lt;br&gt;在调研阶段，我发现相关框架和工具特别多：有的强调团队角色分工，有的走可视化无代码路线，还有的专注研究“涌现行为”。&lt;br&gt;于是我干脆整理了一份 Agent 框架全景图，按时间和特点做了分类。&lt;br&gt;如果要</description>
        
      
      
      
      <content:encoded><![CDATA[<p>最近在做一个新的独立开发产品，核心功能里涉及到 多智能体协作。<br>在调研阶段，我发现相关框架和工具特别多：有的强调团队角色分工，有的走可视化无代码路线，还有的专注研究“涌现行为”。<br>于是我干脆整理了一份 Agent 框架全景图，按时间和特点做了分类。<br>如果要做 B2B&#x2F;B2C 的 Agent 产品，可以判断该走 可视化无代码（Flowise、n8n）、多角色分工（Meta-GPT、ChatDev）、还是 通用框架（AutoGen、Agno、CrewAI）路线。<br>结合框架生态热度（Star 数、厂商背景）做市场判断，避免选型踩坑。</p><br/><p><a href="https://github.com/agentuniverse-ai/agentUniverse">AgentUniverse</a>（2023，开源 1.6k⭐）：支持多智能体协作，具备完整的规划、工具使用和内存管理能力，部署以本地为主，角色定义包括 PEER、DOE 等。<br><a href="https://github.com/OpenBMB/AgentVerse">Agentverse</a>（2023，开源 4.7k⭐）：聚焦多智能体协同与涌现行为，角色涵盖专家、决策者等，采用基于阶段的控制流架构，支持跨平台部署。<br><a href="https://github.com/agno-agi/agno">Agno</a>（2024，开源 32.5k⭐）：轻量级多模态智能体框架，支持 “团队模式” 的多智能体协作，采用混合流（数据 + 控制）架构，基于 Python 实现工具调用。<br><a href="https://github.com/microsoft/autogen">AutoGen</a>（2023，开源 49.2k⭐）：以多智能体对话为核心，角色包括指挥官、工作者、评论家等，采用控制流架构和 DAG（有向无环图）表示，支持代码执行和人机协作。<br><a href="https://github.com/camel-ai/camel">CAMEL</a>（2023，开源 14.2⭐）：专注于智能体间 “心智探索” 的协作，角色分为规划者、执行者等，基于 MCP 协议通信，支持模块化任务分解。<br><a href="https://github.com/OpenBMB/ChatDev">ChatDev</a>（2023，开源 27.4k⭐）：模拟软件开发团队协作，角色包括 CEO、CTO、程序员等，采用类 DAG 的控制流，侧重代码生成与调试。<br><a href="https://github.com/coze-dev/coze-studio">Coze</a>（2024，开源 16.7k⭐）：支持对话式智能体工作流，角色以会话型为主，采用节点式表示和 API 协议，可部署于 Web、移动端等多平台。<br><a href="https://github.com/crewAIInc/crewAI">CrewAI</a>（2024，开源 38k⭐）：强调角色化协作（规划者、团队成员），基于 Python DSL 定义流程，采用控制流架构和任务规划图，支持多 LLM 集成。<br><a href="https://openai.com/index/introducing-deep-research/">DeepResearch</a>（2025，闭源）：聚焦协作推理任务，角色包括搜索者、分析者等，依赖 OpenAI 生态，支持部分自我反思能力。<br><a href="https://github.com/langgenius/dify">Dify</a>（2023，开源 114k⭐）：以提示链为核心的单智能体框架，采用控制流和 JSON 配置，支持函数调用，部署方式包括 SaaS 和本地。<br><a href="https://github.com/stanfordnlp/dspy">DSPy</a>（2023，开源 28.1k⭐）：通过声明式语言定义工作流，角色涵盖规划者、检索者等，采用混合流架构，支持模块化图表示。<br><a href="https://github.com/PaddlePaddle/ERNIE-SDK">ERNIE-SDK</a>（2024，开源 370⭐）：百度推出的智能体框架，角色设计较隐式，采用流程图表示，支持多模态交互和本地部署。<br><a href="https://github.com/FlowiseAI/Flowise">Flowise</a>（2023，开源 43.5k⭐）：基于 LangChain 的可视化工具，以数据流为核心，采用 DAG 表示，适合无代码构建工作流。<br><a href="https://github.com/langchain-ai/langgraph">LangGraph</a>（2023，开源 18.5k⭐）：LangChain 生态的扩展，以节点为单位定义智能体角色，采用 DAG 和状态共享机制，支持复杂循环与条件路由。<br><a href="https://github.com/microsoft/autogen/tree/main/python/packages/autogen-magentic-one">Magnetic-One</a>（2024，开源 49.7k⭐）：多智能体通用框架，角色包括编排者、编码者等，基于 AutoGen 对话协议，采用 DAG 架构。<br><a href="https://github.com/FoundationAgents/MetaGPT">Meta-GPT</a>（2023，开源 58.4k⭐）：模拟软件开发的元编程框架，角色包括产品经理、工程师等，采用类定义的控制流，支持命令行部署。<br><a href="https://github.com/n8n-io/n8n">n8n</a>（2019，开源 137k⭐）：非 LLM 驱动的工作流自动化工具，按节点定义功能，支持 Webhook、REST 等协议，部署灵活（云、本地）。<br><a href="https://github.com/om-ai-lab/OmAgent">OmAgent</a>（2024，开源 2.5k⭐）：专注视频理解的多模态框架，角色包括规划者、检索者等，采用文本计划表示，适用于特定系统集成。<br><a href="https://github.com/openai/swarm">OpenAI Swarm</a>（2024，开源 20.4k⭐）：OpenAI 推出的多智能体框架，角色包括工作者、路由器，采用封装式表示，支持 Python&#x2F;YAML 配置。<br><a href="https://github.com/QwenLM/Qwen-Agent">Qwen-agent</a>（2024，开源 11.4k⭐）：阿里推出的智能体框架，支持自定义角色，基于 MCP 协议，采用代码驱动的控制流，部署灵活。<br><a href="https://github.com/facebook/react">ReAct</a>（2022，开源 239k⭐）：早期提示框架，无明确角色划分，以 “推理 - 行动” 循环为核心，是现代智能体工作流的基础。<br><a href="https://github.com/microsoft/semantic-kernel">Semantic Kernel</a>（2023，开源 26.1k⭐）：微软推出的 SDK，角色设计隐式，采用 DAG 表示和函数调用协议，支持多语言与跨平台部署。</p><br/><p>🤔 如果让你来选，你更倾向哪一类路线？</p><ul><li>无代码可视化</li><li>多角色团队协作</li><li>通用框架</li><li>厂商生态</li></ul><p>👇评论留言 </p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/09/12/22-top-level-Agent-workflow-frameworks-organized/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>从 Claude Code 学的 6 个设计铁律（含 prompts/tool 清单）</title>
      <link>https://blog.liluhui.cn/2025/09/05/6-Design-Principles-I-Learned-from-Claude-Code/</link>
      <guid>https://blog.liluhui.cn/2025/09/05/6-Design-Principles-I-Learned-from-Claude-Code/</guid>
      <pubDate>Fri, 05 Sep 2025 10:28:12 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;TL-DR&quot;&gt;&lt;a href=&quot;#TL-DR&quot; class=&quot;headerlink&quot; title=&quot;TL;DR&quot;&gt;&lt;/a&gt;TL;DR&lt;/h2&gt;&lt;p&gt;Claude Code 之所以“顺滑”，核心不是模型，而是架构和设计哲学。&lt;br&gt; 6 条可以直接迁移到你自己 Ag</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="TL-DR"><a href="#TL-DR" class="headerlink" title="TL;DR"></a>TL;DR</h2><p>Claude Code 之所以“顺滑”，核心不是模型，而是架构和设计哲学。<br> 6 条可以直接迁移到你自己 Agent 的铁律：</p><ol><li><strong>保持单一主循环</strong> —— 一条主 loop，最多一条分支，调试优先。</li><li><strong>小模型，大闭环</strong> —— 80% 的读&#x2F;扫&#x2F;总结都交给小模型，关键时刻才用大模型。</li><li><strong>上下文文件（claude.md）</strong> —— 用一个 context 文件固化团队约定与偏好。</li><li><strong>LLM Search 胜于 RAG</strong> —— 用 ripgrep&#x2F;jq&#x2F;find + LLM，而不是复杂的向量检索。</li><li><strong>分层工具设计</strong> —— 高频动作单独做工具，低频留给 Bash，高层工具保证 determinism。</li><li><strong>显式 To-Do 清单</strong> —— 让模型自己维护待办，防止长会话跑偏。</li></ol><br/><h2 id="一、保持单一主循环"><a href="#一、保持单一主循环" class="headerlink" title="一、保持单一主循环"></a>一、保持单一主循环</h2><p>我看到很多人做 Agent 时，喜欢搞多智能体、复杂 orchestrator。结果是：看 demo 很炫，真要调试时一团糟。Claude Code 完全反其道而行之：<strong>一条主循环，最多一条分支</strong>。</p><p>它的策略是：如果遇到复杂任务，就 spawn 一个“子自己”，<strong>最多一层</strong>，跑完再把结果写回消息历史。好处是整个控制流一目了然，出错时能很快定位。</p><p><strong>经验教训</strong>：debuggability &gt; 架构炫技。</p><br/><h2 id="二、小模型，大闭环"><a href="#二、小模型，大闭环" class="headerlink" title="二、小模型，大闭环"></a>二、小模型，大闭环</h2><p>Claude Code 超过一半的调用走的都是 Haiku（小模型），用来读文件、parse JSON、总结 git 历史。只有关键生成（比如复杂编辑）才用大模型。<br> 这有两个好处：</p><ul><li>成本能降 70–80%。</li><li>反馈速度快，闭环很短，用户觉得“爽”。<br> 对我来说，这其实是个很实用的模式：<strong>别浪费大模型去干小活。</strong></li></ul><br/><h2 id="三、上下文文件：claude-md-模式"><a href="#三、上下文文件：claude-md-模式" class="headerlink" title="三、上下文文件：claude.md 模式"></a>三、上下文文件：claude.md 模式</h2><p>Claude Code 的另一个 killer feature 是 claude.md。它是一个上下文文件，写清楚所有人类无法从代码直接推断出的规则：</p><ul><li>哪些目录要忽略</li><li>用哪些库</li><li>代码风格&#x2F;注释习惯<br> 每次请求都会把 claude.md 附上。效果非常明显：有和没有，差距是天与地。<br> 如果你做自己的 Agent，可以试着加个 agent.md，让它成为团队偏好的“单一真相源”。</li></ul><br/><h2 id="四、LLM-Search-胜于-RAG"><a href="#四、LLM-Search-胜于-RAG" class="headerlink" title="四、LLM Search 胜于 RAG"></a>四、LLM Search 胜于 RAG</h2><p>Claude Code 在搜索上做了一个非常“逆潮流”的选择：不用 RAG。<br>它直接让模型写 <code>ripgrep/jq/find</code>，就像你在终端里手敲一样。模型理解代码和正则，足以定位绝大多数问题。</p><p>为什么这样更好？因为 RAG 有很多隐形失效点（相似度函数、chunk 粒度、reranker…），而 LLM Search 可见、可调试。</p><p>我现在越来越相信：<strong>别急着上 RAG，先让模型像人一样搜索。</strong></p><br/><h2 id="五、分层工具设计"><a href="#五、分层工具设计" class="headerlink" title="五、分层工具设计"></a>五、分层工具设计</h2><p>Claude Code 的工具集很讲究层次感：</p><ul><li>低层：Bash、Read、Write</li><li>中层：Edit、Grep、Glob</li><li>高层：Task、WebFetch、diagnostics<br> 原则是：<strong>高频动作 → 独立工具</strong>（比如 Grep），这样更准确；低频场景交给 Bash 即可。</li></ul><p> 这点给我的启发是：设计工具时不要贪心，<strong>把 agent 最容易用错&#x2F;用频繁的动作，做成独立工具。</strong></p><br/><h2 id="六、显式-To-Do-清单"><a href="#六、显式-To-Do-清单" class="headerlink" title="六、显式 To-Do 清单"></a>六、显式 To-Do 清单</h2><p>长会话的一个大坑是“上下文腐烂”。Claude Code 的解法是：<strong>让模型自己维护 To-Do list</strong>。<br>它会频繁检查和更新 To-Do，这样就能保持方向一致，还能在中途插入&#x2F;删除子任务。<br>相比多 agent 接力，这种方式简单、直观，而且能充分利用 LLM 的“边想边写”能力。</p><br/><h2 id="附录：Prompts-amp-Tools-清单"><a href="#附录：Prompts-amp-Tools-清单" class="headerlink" title="附录：Prompts &amp; Tools 清单"></a>附录：Prompts &amp; Tools 清单</h2><p>Claude Code 的核心提示：太长评论留下邮箱，我会定期回复</p><p>Claude Code 的核心 Tools 提示：太长评论留下邮箱，我会定期回复</p><p>Claude Code 的 prompt 工程很值得参考：</p><ul><li><code>&lt;system-reminder&gt;</code>：定期提醒模型某些状态（但不暴露给用户）。</li><li><code>&lt;good-example&gt;/&lt;bad-example&gt;</code>：用示例来 steer 模型选择。</li></ul><p>工具方面，它的必备集包括：</p><ul><li>低层：Bash、Read、Write</li><li>中层：Edit、Grep、Glob</li><li>高层：Task、WebFetch、diagnostics</li></ul><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/09/05/6-Design-Principles-I-Learned-from-Claude-Code/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/08 Review</title>
      <link>https://blog.liluhui.cn/2025/09/02/202508/</link>
      <guid>https://blog.liluhui.cn/2025/09/02/202508/</guid>
      <pubDate>Tue, 02 Sep 2025 13:23:21 GMT</pubDate>
      
      <description>早早交付，经常交付</description>
      
      
      
      <content:encoded><![CDATA[<p><em>早早交付，经常交付</em></p><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br>更新目前在维护的几个公开媒体渠道</p><ul><li><a href="https://www.xiaohongshu.com/user/profile/5678ff4a50c4b4434936b793">小红书@Luhui Dev</a> 开发者视角的短平快内容</li><li><a href="https://x.com/LuhuiDev">推特@LuhuiDev</a> 海外看到有意思的东西发发</li><li><a href="https://mp.weixin.qq.com/s/4m0Vpj8-mvUrZtlHVh59PA">公众号@芦荟的自留地</a> 更新长文内容，部分同步博客这边的内容</li><li><a href="https://liluhui.cn/">个人博客 liluhui.cn</a> 不方便向外发的</li></ul><br/><p>02<br>好热的8月，明明入秋了天天逼近40℃的高温，一整个不是很想出门，但是竟然还跑了两趟上海，新找了5公里外的瑜伽工作室，生命果然不至于折腾。</p><br/><p>03<br>在互联网上，1%的人创作，9%的人贡献，90%的人消费。要想融入圈子和社区，就要去贡献和创作，不要吝啬任何微小的行为，每一个都是反馈和互动的种子。我现在的创业理念是：深入和圈子互动，服务好我的1000个核心商业价值用户。</p><br/><p>04<br>现在想找人深度聊天越来越难，很多人没有deepthinking，他就不可能deeptalk，最后就都去deepseek了。<br>很扎心吧 U•ェ•*U</p><br/><br/><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>这个月大部分时间都在疯狂迭代大角几何画板和做小红书内容上。交互上推进了工具、多画板、登录等能力，新上了重构版的几何绘图Agent，借助推理模式能力有突破式进展，希望能覆盖更多数学绘图群体的需求。截止8月底已经有400个登录用户，1000个访问用户了，3个月不到的时间就收到了很多用户反馈蛮惊喜的。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/Pasted%20image%2020250902202358.png" alt="image"></p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/mmexport1756299569887.png" alt="image"></p><br/><p>02<br>去参加了上海的 Google I&#x2F;O 2025 开发者大会，上午主要在工作坊学习了下整个谷歌生态AI能力的SDK，下午一整个在面基网友们，上海又多了一群在干事的新朋友。<br>这次还有个小插曲，大会前2天临时起意做了个大会日程APP，正常借此做内容，24小时转化了第一批30多个用户，详细的复盘可以看<a href="https://blog.liluhui.cn/2025/08/18/googleio/">这篇</a>。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250814_183840.jpg" alt="image"></p><br/><br/><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br>我的新头像系列 （感谢生图模型的迅速进展）</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/Weixin%20Image_2025-08-21_212357_7.png" alt="image"></p><br/><p>02<br>重启羽毛球，最近停药后疯狂长胖，加入有氧训练！<br>其实也想学网球，一直没找到合适的机会和老师 …<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250809_150254.jpg" alt="image"></p><br/><p>03<br>家里小植物们长得好好，每天看着桌上和阳台能感受到生命力就在这里。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250825_093257.jpg" alt="image"></p><br/><p>04<br>这个月看来《捕风追影》《浪浪山小妖怪》《戏台》《南京照相馆》，我的月度最佳是《南京照相馆》。哦对，还蹭了暑假孩子们的8k星空展览，带上设备在宇宙间看星系的感觉也非常棒哈哈哈。</p><p>一句话推荐：<br>《捕风追影》不要带脑子的爽片，拳拳到肉，成龙+鲜肉，反派超帅。<br>《浪浪山小妖怪》小孩子的快乐，成年人的悲伤，雅俗共赏的分层电影。以及，上海美术电影制片厂。<br>《戏台》陈佩斯，陈佩斯，陈佩斯！<br>《南京照相馆》不以视角切入沉重的历史，跟随小人物的沉浸，看宏观世界的规律，看走出影院后的太平盛世。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250823_162658.jpg" alt="image"></p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/09/02/202508/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>构建 Agent 中的方法论陷阱</title>
      <link>https://blog.liluhui.cn/2025/08/22/Traps-of-Methodology-in-Agent-Development/</link>
      <guid>https://blog.liluhui.cn/2025/08/22/Traps-of-Methodology-in-Agent-Development/</guid>
      <pubDate>Fri, 22 Aug 2025 03:49:54 GMT</pubDate>
      
      <description>看似聪明的 Agent 方法论，可能是陷阱。少即是多。</description>
      
      
      
      <content:encoded><![CDATA[<p><em>看似聪明的 Agent 方法论，可能是陷阱。少即是多。</em></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前几天在刷推的时候，看到了 cline 的开发者 Ara 提到的一段话。<br>他说，在构建 AI Agent 时，有三种听起来很聪明的想法，其实常常是「思维毒药」。</p><p>“思维毒药” 这个词总归怪怪的，我觉得“陷阱”这个比喻让我更有共鸣。因为这些思维确实很有吸引力，就像远远看去是一条捷径，但走进去才发现，里面布满了泥潭。</p><p>作为一个开发者，我一边读，一边在回想自己做 Agent 的过程——踩过的坑，走过的弯路，几乎都能在这里找到影子。</p><h2 id="一、关于多代理编排"><a href="#一、关于多代理编排" class="headerlink" title="一、关于多代理编排"></a>一、关于多代理编排</h2><p>想象一下这样的画面：<br>有一支虚拟团队，里面有“分析员 Agent”“执行员 Agent”“总调度 Agent”。它们像人类小组一样，分工协作、互相传递消息，最后汇总出完美的结果。</p><p>听上去是不是很酷？我当初也实践过。</p><p>可现实是：<strong>大多数真正有价值的 Agent 工作，本质上还是单线程的</strong>。</p><p>复杂的编排，不仅增加了技术上的不确定性，还让我们更难解释模型的行为。<br>换句话说，它让项目背上了两份负担：<strong>实现复杂度 + 解释复杂度</strong>。</p><p>曾经做过一个 Team Demo 来完成 AI Coding 这件事，尝试用多个 Agent 分工协作。结果没走几步，就被“状态同步”和“出错恢复”折腾得焦头烂额。调试的时候，根本不知道到底是哪个 Agent 在搞鬼。</p><p>到最后，我还是把逻辑简化掉，留给一个更强的单体 Agent 去完成。意外的是，效果比多代理方案还要稳定。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/22/2.png"></p><h2 id="二、关于-RAG-的补丁效应"><a href="#二、关于-RAG-的补丁效应" class="headerlink" title="二、关于 RAG 的补丁效应"></a>二、关于 RAG 的补丁效应</h2><p>过去两年，RAG（检索增强生成）几乎成了构建 Agent 的标配。好像不加上它，整个系统就“不完整”。</p><p>但真实的情况是：<strong>RAG 更像是一块补丁</strong>。<br>很多时候，一个简单的 grep 命令，或者一张设计良好的数据库表，就能解决问题。<br>如果你的数据和知识管理一团乱，RAG 只会把混乱放大，它不是万能钥匙。重要的数据，数据，还是 TMD 数据。</p><p>我刚开始用 RAG 的时候，觉得它是“救命稻草”。模型终于可以“记住”外部知识了。可随着项目复杂度增加，我发现问题并没有减少，反而多了新的麻烦：检索不准、上下文过载、延迟变高…… 慢慢我意识到：<strong>真正重要的，其实是信息组织方式</strong>。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/22/3.png"></p><h2 id="三、关于「更多指令-x3D-更好结果」"><a href="#三、关于「更多指令-x3D-更好结果」" class="headerlink" title="三、关于「更多指令 &#x3D; 更好结果」"></a>三、关于「更多指令 &#x3D; 更好结果」</h2><p>还有一个陷阱，是很多人都会踩的：<br>我们常常相信，只要写更长、更详细的 prompt，模型就会更聪明。</p><p>现实往往相反。<br>长 prompt 增加了 token 成本，响应速度更慢，结果也不一定更好。更糟糕的是，它掩盖了真正的问题：<strong>模型本身的能力边界</strong>。</p><p>我刚开始玩 LLM 的时候，我也写过像“说明书”一样长的 prompt，把能想到的规则全堆上去。<br>但最后发现，简洁、清晰的三句话，往往比十段废话更有效。</p><p>现在我更看重的是 <strong>任务建模和上下文管理</strong>。<br>比如明确拆分任务，合理设计输入输出，这些往往比写一个“超级提示词”来得靠谱。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/22/4.png"></p><h2 id="总结：少即是多"><a href="#总结：少即是多" class="headerlink" title="总结：少即是多"></a>总结：少即是多</h2><p>回顾这三点：</p><ul><li><strong>多代理编排</strong>：是幻觉，现实里常常多余。</li><li><strong>RAG</strong>：是补丁，价值有限，不该当成金科玉律。</li><li><strong>长 prompt</strong>：是迷思，解决不了模型的根本限制。</li></ul><p>别被“听起来聪明”的概念绑架，真正有效的，往往是简单、直接、可解释的方案。<br>作为开发者，我更愿意拥抱这种“少即是多”的原则。<br>因为时间和资源有限，每一行代码、每一个设计选择，都需要指向真正的核心价值。</p>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/08/22/Traps-of-Methodology-in-Agent-Development/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>48 小时小工具实录：我做了个大会助手</title>
      <link>https://blog.liluhui.cn/2025/08/18/googleio/</link>
      <guid>https://blog.liluhui.cn/2025/08/18/googleio/</guid>
      <pubDate>Mon, 18 Aug 2025 15:11:51 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;img src=&quot;https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/18/asdaweq.png&quot; alt=&quot;image&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;起心动念&quot;&gt;&lt;a href=&quot;#起心动念&quot;</description>
        
      
      
      
      <content:encoded><![CDATA[<p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/18/asdaweq.png" alt="image"></p><h3 id="起心动念"><a href="#起心动念" class="headerlink" title="起心动念"></a>起心动念</h3><p>周一晚上，本来想早点休息，结果脑子突然冒出个念头：</p><blockquote><p>“要是有个离线可用、免登录的大会日程助手就好了。”</p></blockquote><p>于是干脆一口气写了 5 个小时，把一个可用版本搞了出来。核心约束很明确：免登录、离线、轻交互。目标很单纯，就是现场能救急。</p><br/><h3 id="临时开工"><a href="#临时开工" class="headerlink" title="临时开工"></a>临时开工</h3><p>整个技术方案非常 indie：</p><ul><li>React + PWA + Vercel 一键部署</li><li>数据靠 GPT 整理的大会官网，然后导入 JSON</li><li>没有后台，没有账号，全在前端跑</li></ul><p>代码写得像夜宵拼盘，能跑就行。为什么选纯前端？为了离线和快速交付。上线第一天就接到 iOS 用户反馈打不开，着急忙慌修问题，才发现自己紧急开发没有充分测试设备的问题。那一晚边修边想：“这样上线真的有人用吗？”</p><h3 id="上线与运营"><a href="#上线与运营" class="headerlink" title="上线与运营"></a>上线与运营</h3><p>周二白天，我赶紧补了点运营内容。发到 v2ex，几乎没人理；同时小红书，反而慢慢起来了。陆陆续续有人私信问“怎么用”，我只好一边当客服一边补文案。没想到借着这件事，还面基了不少人。</p><p>这让我意识到：即便是独立开发的小工具，找到合适的分发渠道也比想象中重要。</p><h3 id="两天的数据"><a href="#两天的数据" class="headerlink" title="两天的数据"></a>两天的数据</h3><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/18/zxcqsa.png" alt="image"></p><p>结果出来后有点意外：</p><ul><li>76 位用户</li><li>841 次访问</li><li>平均使用时长 2 分 10 秒</li><li>主题页 438 次访问，详情页 93 次</li></ul><p>比我自己刷朋友圈的时长还长，说明不是点开就走人。尤其主题页访问量很高，说明用户确实想“逛全局”，不是只搜一场。</p><br/><h3 id="What-went-well"><a href="#What-went-well" class="headerlink" title="What went well"></a>What went well</h3><ul><li><strong>免登录 + 离线可用</strong>：如设想成了最大卖点。</li><li><strong>需求真实驱动</strong>：临时上线也有人用，证明确实解决了痛点。</li><li><strong>小红书意外带量</strong>：运营不是我擅长的，但确实帮我接住了用户。</li></ul><br/><h3 id="What-didn’t-go-well"><a href="#What-didn’t-go-well" class="headerlink" title="What didn’t go well"></a>What didn’t go well</h3><ul><li><strong>预热不足</strong>：要是提前一周发布，效果可能翻倍。</li><li><strong>数据采集缺失</strong>：只接了 GA4 页面浏览，没法更准确地知道预约行为。</li></ul><p>结果就是：复盘时我只能靠各个页面数据来猜激活。根因很简单：我当时的“成功定义”还停留在“能上线可用”，而不是“被看见、被采用”。</p><br/><h3 id="反思-amp-下一步"><a href="#反思-amp-下一步" class="headerlink" title="反思 &amp; 下一步"></a>反思 &amp; 下一步</h3><p>这次实验让我真正意识到，复盘在于两件事：<strong>如何更快挖掘真实需求</strong>，以及<strong>如何把运营节奏踩准</strong>。</p><ul><li><strong>需求发现</strong>：这次是自己用痛点驱动临时开发，下次应该提前去看不同社区、社交平台上用户在哪些地方吐槽过类似问题，尽早发现“隐形需求”，最好提前一周留出验证窗口。</li><li><strong>运营节奏</strong>：节奏感比功能更关键。T-72 小时就该放预热帖，T-24 小时要有“一图一文案”准备好，正式开幕当天要能推出“今日变更&#x2F;热门场次”的内容。</li><li><strong>分发优先级</strong>：这次 v2ex 没起量，小红书反而爆发，说明不同渠道效果差异巨大，下次要更明确主力渠道，少浪费子弹。</li></ul><p>下一步的方向：</p><ol><li><strong>继续验证不同类型大会</strong>：看看这个模式在学术会议、技术沙龙、大规模大会上效果是否一致。</li><li><strong>优化快速部署能力</strong>：缩短从临时起意到可上线的时间，把常用组件和脚手架打包好。</li><li><strong>打磨一套数据解析与生成工具</strong>：针对不同大会的日程结构，统一导入、解析和生成，避免重复劳动。</li></ol><br/><h3 id="收尾"><a href="#收尾" class="headerlink" title="收尾"></a>收尾</h3><p>说白了，这 76 个用户不是因为我运营厉害，而是需求实在强烈。上线前一晚还在修 bug，上线后疯狂回私信解释。典型 indie dev：<strong>边做边慌，边慌边学</strong>。</p><p>但这次让我明白了一件事：上线不等于成功。下次要把“被看见、被采用”写进 Definition of Done。</p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      
      
      <comments>https://blog.liluhui.cn/2025/08/18/googleio/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/07 Review</title>
      <link>https://blog.liluhui.cn/2025/08/02/202507/</link>
      <guid>https://blog.liluhui.cn/2025/08/02/202507/</guid>
      <pubDate>Sat, 02 Aug 2025 13:47:49 GMT</pubDate>
      
      <description>你不应先学习，再开始；而应先开始，再学习。</description>
      
      
      
      <content:encoded><![CDATA[<p><em>你不应先学习，再开始；而应先开始，再学习。</em></p><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br>毕业工作也有八个年头了，曾经以为自己是个蛮冒险的人，其实也并不是，公司一共两家，坐标一直在杭州，就行为上来说，是在安稳地积累。这些年累计的金融理财实践也让我有了蛮确定的安全感，有一两门手艺，有健康的身体，人生其实还是有蛮多拓展选项的。想学习想看看年轻人都在做什么，不想像那些老顽固已经不愿意相信了，总是自嘲“老了“，拿着一套老模式一直做下去。我觉得沉浸投入的时候就投入，到一定时候，就该抬头看看新世界了，等一个十年！</p><br/><p>01<br>和瑜伽的姐妹们约定，80 岁的人生也一起爬山！<br>在这里反而让人不畏老了，不出意外的话，我们都会一直一直练下去，每天活络我们的经脉。<br>越来越感受到健康的身体才是精气神的底气，同龄人已经天天腰疼肩颈疼了，我们这群人还在疯狂找事来动，不动就浑身难受。养神又养身的运动真好，总是能把我从烦躁的状态中释放出来。</p><br/><br/><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>在学习自媒体经营中，目前个人号<a href="https://x.com/LuhuiDev">推特@LuhuiDev</a> 和<a href="https://www.xiaohongshu.com/user/profile/5678ff4a50c4b4434936b793">小红书@Luhui Dev</a>，欢迎互动。<br>做这件事情的起源是在筹备个人的独立项目，未来除了公司的业务部分，想把个人的作品和产品都一步步建立起来。这一年学习使用 AI 下来很明显的感受是，自己的能力边界被大大拓宽了，时间效率也提供了，两三个人能很快合作交付出专业且完整的小项目。展望未来来说，我倾向于和不同的人合作更多的项目，我需要去碰撞和交流更多合得来的人。</p><br/><p>02<br>团队的<a href="https://www.xiaohongshu.com/discovery/item/686394740000000023004278?source=webshare&xhsshare=pc_web&xsec_token=ABK3VRE_HBxbzrWAqv93Rtnny__pUdBrObJFZgTCrYjrQ=&xsec_source=pc_share">大角几何画板项目</a>已经完整上线了，服务于数学内容创作者和数学教师的几何绘图需求。目前国内产品的几何画板已经是个非常老旧的产品了，在新的 AI 时代，大角几何画板算是重新思考交互方式，包括人与 AI、人与画板不同的协作方式。我在<a href="https://www.xiaohongshu.com/discovery/item/687e44730000000023005124?source=webshare&xhsshare=pc_web&xsec_token=ABLAPYNqJHWtb3YO-Sw9pXm47NwSXriyefHIly3SxRJio=&xsec_source=pc_share">开发日志系列</a>持续更新功能动态，另外不定时会发视频按理，有兴趣地来看看吧。</p><br/><p>03<br>接朋友的需求做了个硬核科技风的个人主页项目，灵感来源于 console 和 黑客帝国，整个项目的实现全靠 AI 干活我 review，整体完成度极好，<a href="https://x.com/LuhuiDev/status/1948016244788969519">效果看这 🔗</a>。</p><br/><p>04<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/Pasted%20image%2020250802212319.png" alt="image"><br>把我手头的运维工作进行了一次大重构优化，终于实现了线上小机器 10 秒以内的停机切换，非常满意。实现上主要是把 docker 构建流程进行了重构，实现一个 自动备份数据库 -&gt; 拉取代码 -&gt; 构建镜像 -&gt; 停止服务 -&gt; 启动服务 -&gt; 健康检查。然后和 AI 合作整了套管理脚本，方便我直接查看状态、回滚和更新。</p><br/><br/><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250719_200128.jpg" alt="image"></p><p>月中给超好的朋友过生日，难得的一大聚，想想也是蛮神奇的，认识二十多年，饭桌上的人变了许多，但总还有老面孔。生活也过得越来越丰富，探索新的美食、新的旅途、新的同路人。<br><br/></p><p>02<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250714_102813.jpg" alt="image"><br>搞到多儿的周边，很开心 XD<br>已经打卡 600 多天啦，每天都离不开的小绿鸟<br><br/></p><p>03<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/08/02/IMG_20250708_201225.jpg" alt="image"><br>陪朋友夜访了趟灵隐，晚上的灵隐人很少，近距离欣赏一尊尊高大的佛像和雄伟的大殿，这体验还是蛮推荐的。说起来在杭州十年还是第一次去，夏天的晚上除了蚊子多整个都很舒服，小路昏暗静谧，可以站在佛像前感受那种“压迫感”，或者说“保护感”，大家是认认真真在祈愿，这种精神氛围蛮有意思。<br><br/><br><br/><br><br/><br><br/><br><br/></p>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/08/02/202507/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/06 Review</title>
      <link>https://blog.liluhui.cn/2025/07/03/202506/</link>
      <guid>https://blog.liluhui.cn/2025/07/03/202506/</guid>
      <pubDate>Thu, 03 Jul 2025 14:02:47 GMT</pubDate>
      
      <description>自我实现是一个持续发生的过程。它意味着，每一次都在诚实与欺瞒、正义与偷懒之间做出选择；意味着让每一次选择，都成为成长的机会。</description>
      
      
      
      <content:encoded><![CDATA[<p><em>自我实现是一个持续发生的过程。它意味着，每一次都在诚实与欺瞒、正义与偷懒之间做出选择；意味着让每一次选择，都成为成长的机会。</em></p><h2 id="大声嚷嚷"><a href="#大声嚷嚷" class="headerlink" title="大声嚷嚷"></a>大声嚷嚷</h2><ul><li>正式开始运营技术向的 Twitter 账号 <a href="https://x.com/aloea_1">@aloea_1</a>，用于分享我的小产品进展，欢迎互粉互动～</li><li>筹备了小半年的轻养生香文化品牌 <a href="https://www.xiaohongshu.com/user/profile/66cc807b000000000b033c1b">@闻补</a>，终于在小红书开张，欢迎成为我们的创始支持官！</li></ul><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><h3 id="01"><a href="#01" class="headerlink" title="01"></a>01</h3><p>目前的生活状态：</p><p>少评论，少内耗。该战斗时就战斗，该行动时就行动。偶尔停下脚步，感受自然的风，指尖的温度，空气的味道，还有此刻的呼吸。<br>可以享受慵懒，但不沉溺其中。休息好就继续往前走。<br>警惕“连续作战”的兴奋感，每天留一点时间练瑜伽，觉察情绪的变化，少些理性地判断。<br>用理性兜底，让感性来引路。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/07/03/20250703172221.png" alt="image"><br><br/></p><h3 id="02"><a href="#02" class="headerlink" title="02"></a>02</h3><p>遇到许多厉害的人，看上去光鲜亮丽，能量满满，似乎总想要更多。</p><p>有人在硅谷扎根，全球飞行，体验各地文化；<br>有人带家人移居日本，过上高保障的生活；<br>有人在技术圈里游刃有余，轻松将人脉牵连起来，走到哪里都有朋友；<br>有人拥有自己的团队，身边拥有一群情绪价值拉满的伙伴；<br>有人开设了瑜伽馆，经常收到学员的反馈和感谢。</p><p>但我越来越清楚地知道：我当下的生活，其实已经很幸福了。我未必想要那样。</p><p>那些光鲜亮丽的苦楚与代价就在那里。<br>有人夜夜应酬，醉到天亮；<br>有人随时待命，时刻留意工作消息，精力被分割；<br>有人面对难缠的客户，遭遇无理甚至恶意；<br>有人在系统面前无能为力，财产归零；<br>有人迷失方向，不知去往何处；<br>有人拼命四五年，落下一身病痛。</p><p>这些让我明白：有些路要慢慢走，不需要着急奔向前线。作品细水长流，财富一点点积累。不追头部，不比速度，只要保持活着，时间就成了最强的护城河。<br><br/></p><h3 id="03"><a href="#03" class="headerlink" title="03"></a>03</h3><p>在瑜伽课堂里体验被声音包围的感觉太好了，不论是阿汤的唱诵还是简单的 OM，怪不得那么多文化都有诵经、吟唱。</p><p>那种感觉，真真切切我被包裹了，包裹在一片美好的秩序之中，这里我没有念头，他人也没有念头。我们共同唱诵着同一种声音，我的四面八方都是同我一样的声音。它们不厌恶我、不喜爱我、不评论我，它们都没有注视着我。我同它们一起平和安稳地感激此刻的存在。<br><br/><br><br/></p><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><h3 id="01-1"><a href="#01-1" class="headerlink" title="01"></a>01</h3><p>新项目【大角几何】正式上线！<br>这是一款结合自然语言绘图、逻辑验证、智能纠错的几何工具，既服务教育教学，也支持专业研究。<br>首版已上线，具备 AI 辅助构图、几何关系推理、图形实时反馈等功能，效果初显。我们正持续迭代，拓展更复杂的图形与代数定义支持。</p><p>相关动态我会持续更新在 <a href="https://x.com/aloea_1">Twitter</a>。<br><br/></p><h3 id="02-1"><a href="#02-1" class="headerlink" title="02"></a>02</h3><p>同时也在孵化另外两个项目。最近半年就是“超忙人”状态，也有中途放弃的方向。现实告诉我：脚踏实地去做事，到处都是细节。进度总是被各种预期外的事情打乱，每一步都想做好。</p><p>事情越做越多，见到的同行也越来越多，忙碌而充实。但也会因为时间紧张，挤压了瑜伽的练习，阅读也变少了。<br>自责时常出现——没时间沉下心来输入与整理。<br>所以我常提醒自己：每段旅程都有主线任务，精力有限，要学会取舍。<br><br/><br><br/></p><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><h3 id="01-2"><a href="#01-2" class="headerlink" title="01"></a>01</h3><p>书：没读。<br>电影：看了《还有明天》（民主政治这话题我们可不敢多说）。<br>惭愧中。<br>不过淘到了一本数独书，还有岸部真明的黑胶，开心！<br><br/></p><h3 id="02-2"><a href="#02-2" class="headerlink" title="02"></a>02</h3><p>最近去了一趟日本，在异国他乡聚会的感觉很特别。</p><p>感谢佳伦和 Anne 的组局，在东京湾边烤肉、吹风，体验了一场精致的晚风社交。也和姐妹们在迪士尼疯玩了一整天，累趴但超级满足。买了人生第一只琳娜贝儿，傻傻开心了一整天。</p><p>一个人在东京到处瞎逛，逛到很多稀奇古怪的东西，挑了些新玩意，到处拍拍照。初夏的日本，处处是绿色的生命力。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/07/03/20250703215855.png" alt="image"></p><p>小狗子在老家也玩得很开心，在好朋友家里每天蹦蹦跳跳。虽然被投喂得圆圆的，但看得我心动，想给它整个小院子了。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/07/03/20250703215904.png" alt="image"></p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/07/03/202506/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/05 Review</title>
      <link>https://blog.liluhui.cn/2025/06/02/202505/</link>
      <guid>https://blog.liluhui.cn/2025/06/02/202505/</guid>
      <pubDate>Sun, 01 Jun 2025 16:00:00 GMT</pubDate>
      
      <description>我不是一个乐观主义者，我只是一个非常严肃的可能主义者。</description>
      
      
      
      <content:encoded><![CDATA[<br/><p><em>我不是一个乐观主义者，我只是一个非常严肃的可能主义者。</em></p><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br>幸福在每天流淌着<br>床边的狗头<br>被窝的温暖<br>无理取闹<br>放下聪明</p><br/><p>02<br>个体的价值观不是头脑中的想法，不是静坐着头脑定义的价值观。<br>人必须按照某种方式行动，价值观正是在行动中动态发展出来的。<br>在行动中，人会发展出优势，优势会产出价值，在循环中人会不断加强和认可其优势与价值。</p><br/><p>03<br>和朋友相处要保持距离，有些人不可交流就不要硬交流，这样还能互相欣赏对方的可爱之处。</p><p>不可交流在于，有些人只是沉浸在自己观察到的世界，自己认为的真理，认定这些真理高高在上，捍卫其就是捍卫个人的意志，探讨变成了攻击，变成了不友好。这种抗拒某种意义上也是在保护这个世界的粉红泡泡，保护某种懒惰与不勇敢。</p><br/><p>04<br>离开了这段关系一段时间，再回过头看，我的身体也进入了某种需要安神和内收的阶段。那些别扭的感觉都消失了，思考也变顺畅不少，抛开了一些沉甸甸的约束，也少了习以为常的依赖，生活变得慵懒了一些，不需要承担什么，信任自己的直觉去全身投入建设这个世界。</p><p>习惯于某种忙碌是不好的，麻木的感觉是种信号，总该停下来重新整顿，照顾好内心的小火苗。</p><br/><br/><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>这个月重构了APP的产品逻辑，把数学教育这个场景下的子功能从 ALL IN Chat 拆到主入口，重新测试1.0版本提供的拍照解题、一卷批改等功能。目前的产品规划上重构安排的时间不太合理，1.1版本的规划有几个方向还在内部探讨纠结中，对教育领域目前的数据服务商进行了全面地调研，市场的已有数据都比较传统，云服务商场提供的能力准确性差异还蛮大的，这块可以做封装的可能行很多，希望团队能沉下心来做好一件事。</p><br/><p>02<br>开始构建自己的产品，6月顺利能全部备案完成就能上线了！<br>新的产品围绕生活数据的记录和分析，是从我自己的需求出发的，想做点小而美的好东西。<br>另外饰品品牌-闻补也正式上线了，初代的四款产品已经确定下来，是我和朋友跑了小三个月的市场调研选定的，目前设计和产研都是我们一手在把控，线上商场预计会在六月下旬到七月上旬启动。</p><br/><br/><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br>入手了圣手三代，奶酪绿真好看啊，敲击感很丝滑，工作都得劲了。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/06/02/RZ007507.jpg" alt="image"></p><br/><p>02<br>安静下来和茶人一起品味的过程蛮新奇的，心动了2025蜜兰单枞，想回味下武夷山的岩茶了。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/06/02/RZ007551.jpg" alt="image"></p><br/><p>03<br>国家地理摄影展，从洞穴、丛林、草原、雪山、冰川到无尽的天空，好看，更想去看看这些地方了，想更多支持3D拟世界美景产品的发展，这样我和朋友们都能更方便舒适地享受到。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/06/02/IMG_20250601_221722.jpg" alt="image"><br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/06/02/IMG_20250601_190814.jpg" alt="image"></p><br/><p>04<br>收到好多朋友的投喂来的新鲜水果和特产，好爱大家呀，一起躺着度过悠闲的周末。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/06/02/IMG_20250501_142755.jpg" alt="image"></p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/06/02/202505/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/04 Review</title>
      <link>https://blog.liluhui.cn/2025/05/03/202504/</link>
      <guid>https://blog.liluhui.cn/2025/05/03/202504/</guid>
      <pubDate>Sat, 03 May 2025 12:27:42 GMT</pubDate>
      
      <description>糊涂塌客虽然是只小鸟，但却有旺盛的斗志。(づ′▽`)づ</description>
      
      
      
      <content:encoded><![CDATA[<br/>_糊涂塌客虽然是只小鸟，但却有旺盛的斗志。(づ′▽`)づ_<br/><h2 id="这个月发生了什么？"><a href="#这个月发生了什么？" class="headerlink" title="这个月发生了什么？"></a>这个月发生了什么？</h2><ul><li>我们团队的大角讲题APP上线了1.0版本，重构了整个讲题对话模块，支持从AI出卷到AI批改到AI讲解的学习路径。</li><li>独立在尝试搞AI方向的自媒体账号，不去想太多，就是试验自己是否了解外部生态的玩法和自己运营的能力。</li><li>帮助朋友创建了合香文化品牌，两个月的时间从概念到货源及产品研发，线下售卖拿到结果，连续尝试根据不同的客源调整产品方向，算是一个还不错的起步。</li><li>年初搬家后开始养的植物们，一个个都发新芽&#x2F;新叶了，春雨、蓝花楹是我目前的最爱。</li><li>开始尝试健身房的力量训练，拓展运动类型+1。</li></ul><br/><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br>一些美好的想法记录：</p><ul><li><p>想要将梦境都记录下来，让梦境能够通过美学和沟通来显化其中的暗示与意义，想看到意识之下那个黑暗忧郁恐惧又胆小的小孩，可她总是躲起来，见不着，没有具象，都是小动作在隐隐不安。（寻感兴趣的朋友共创）</p></li><li><p>想要做自己的品牌，从中国古老的香方出发，结合适当的现代美学穿搭融入到年轻人之间。喜欢古香里草药的味道、木头的味道，安神静心，让属于新一代年轻人的香味审美包含中国传统的底蕴。喜欢在读书时闻着淡淡的纸张香味，喜欢在瑜伽时闻着清新的木香，喜欢在入睡时闻着安稳的檀香。（已经启动）</p></li></ul><p>一些需求：</p><ul><li><p>Heptabase 中 mention 功能无法快速引入卡片，用着不舒服，只能退而求其次用 @ 的超链接。</p></li><li><p>阿里云的域名证书定期自动更新部署。</p></li></ul><br/><p>02<br>一个朋友跟我感慨，在28岁的时候她已经确定了，非常喜欢gap那一年的nothing的状态。<br>我想，现在都市拼搏的年轻人真的都太累了，375承担了多少的自我压迫和束手无策，这里已经有太多的规矩和模式，匹配不上又改革不了，这样的困局让这么多人抑郁、焦虑。<br>大家需要更多的场合和机会去疗愈，也需要更多多样化的评价体系。</p><br/><p>03<br>不要没有力量的肌肉<br>不要没有信任的友谊<br>不要相信不承担责任的观点<br>不要缺乏美感的变化<br>不要没有价值观的阅历<br>不要未拼尽全力的人生<br>不要把资源和精力浪费在自己不渴望的事情上<br>不要吃没有营养的食物<br>不要没有逻辑的统计<br>不要没有证明的数学<br>不要没有实践经验的老师<br>不要冷若冰霜的礼貌<br>不要没有相互投入的友谊<br>不要忽略概率的遍历性<br>不要相信没有风险的财富机会<br>不要辞藻华丽却又言之无物<br>不要忽略决策的非对称性</p><p>摘自《《非对称风险》</p><br/><p>04<br>真的有世界一流的亲密关系吗？</p><p>个体独立，携手共进，互相照亮彼此，互相成长。</p><p>可是成长本就是个体的事情，如果不是缺失了什么，两个个体究竟如何牢牢在一起。</p><p>一流的亲密关系，本就是在说一段可以互相离开的关系。</p><p>可以离开，可以重新填补，可以看见对方，可以从对方的眼镜中看到自己。</p><p>最后还是自我的修行。</p><p>凉意，我被眼前的标题出触动。</p><br/><br/><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>尝试做一套企业内部用于项目编程和动画视频制作的“Manus”，框架整体完成，细枝末节的Agent缺得有点多，导致时不时都有点蠢。不管怎么说，先用起来了。<br>受大老板邀请，把技术圆桌交流组织起来，反馈问卷还不错，接下来就是争取福利拓展影响了。也是就着借此次组织活动的机会，我花了两天时间访谈了公司内不同部门的同事。整体给我的感觉是浸泡在前线的人确实少，工作机会缺失的情况下，自主学习的动力和效率是有明显差距的，这一波“革命”，上头的人必须先动起来。</p><br/><p>02<br>年后面试不断，复盘下25年上来这波面试者对比之前的情况：</p><ul><li>解决代码问题的思维反应明显偏慢</li><li>谦虚很多，或者说敬畏 or 小心翼翼？</li><li>在用&#x2F;用过 AI Coding 占比八成以上，其中一半口头表达使用付费版本</li></ul><br/><br/><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br>在朋友的推荐下开启健身，第一节课就把我拉爆了，臀腿酸痛了整整三天。 但是教练说，我要变强了！<br>上了5节私教课了，能明显感到和瑜伽的区别是，力量训练需要容错率更高，自重类的训练项目对于我这样能精准感知到肌肉伸展和收缩的人来说，能明显感觉到不稳定时的代偿，虽然这样的代偿存在很多运动之中，但自重式力量训练在这一点上更明显。还有对于气息的控制上，力量训练需要更多爆发力，而我的瑜伽训练中则更多的是耐力训练，很新奇这样的爆发式发力。</p><br/><p>02<br> 年初开始养的植物们都长出了新叶，春天的生机在每次雨水后炸开在我眼前，这就是中医讲的自然生发吗，对于植物的嫩芽、肥厚这些词有了更具体的认识。连冬天被狗子啃得干干净净的发财树都重新变得郁郁葱葱了，看来今年会有财运呀。</p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/05/03/202504/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/02 Review</title>
      <link>https://blog.liluhui.cn/2025/03/03/202502/</link>
      <guid>https://blog.liluhui.cn/2025/03/03/202502/</guid>
      <pubDate>Mon, 03 Mar 2025 12:27:42 GMT</pubDate>
      
      <description>凡是墙皆是门。</description>
      
      
      
      <content:encoded><![CDATA[<p>凡是墙皆是门。<br>所有不可能，恰恰是通往另一个新可能的大门。<br>我们需要积聚能量和能力去重构，<br>耐心，<br>静心，<br>平常心。</p><br/><br/><h2 id="这个月发生了什么？"><a href="#这个月发生了什么？" class="headerlink" title="这个月发生了什么？"></a>这个月发生了什么？</h2><ol><li>针对学生数学教学的AI+教育APP：大角讲题，接入DeepSeek 满血版上线了。</li><li>春天回暖了，开始回归加强运动安排了。</li><li>春节期间到处走走吃吃喝喝，养神，调整生活。</li></ol><br/><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br>解决自己受阻的地方，解决他人受阻的地方。前置关键的一环是，深入探索受阻的地方，不是遇到了就下意识地绕过去，不是难受了就不去看它。</p><p><strong>所有不可能，恰恰是通往另一个新可能的大门。</strong><br>有些路太难，就拆开一步步走。</p><br/><p>02<br>克尔凯郭尔老师说人生有三大绝望：不知道有自己，不能够有自己，不愿意有自己。我后来又看到一种说法，克老师所说的第一种绝望不是“不知道有自己”，而是“知道有自己”。天啊，只有三十多岁的人才知道，这两种说法都血淋淋的对。</p><br/><p>03<br>南海之帝为儵（音：叔）北海之帝为忽，中央之帝为浑沌。<br>儵与忽时相与遇于浑沌之地，浑沌待之甚善。<br>儵与忽谋报浑沌之德，曰：“人皆有七窍以视听食息此独无有，尝试凿之。”<br>日凿一窍，七日而浑沌死。</p><br/><p>04<br>人们想要捕捉美好的画面，只是就这一点，心意很美好。<br>多看多想美好的，世界就会美好起来。<br>一定会吧。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/03/03/20250303164057.png" alt="image"></p><br/><br/><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>DeepSeek 的火爆和出圈远超想象，年后上来的一周，各种抓紧测试，后面又因为要找到稳定可靠的服务供应商折腾了一周，等到2月底各家云厂商才稳定运行起来，我们产品端也第一时间接入了DS的思考模型和常规模型。问题还是有不少的，实测效果在我们的数学题目交流场景下，效果要明显好于 gpt4o，但在分类器和格式转化上却远不及 gpt4o。</p><p>本月技术关注关键词：DeepSeek、Deep Reasearch</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/03/03/20250303164606.png" alt="image"></p><br/><p>02<br>把远程向日葵迁移到 Tailsacles+ WIndow Remote Desktop，Windows专业版提供的系统级别的 RDP 远控协议真好用，丝滑，优雅，省了向日葵的会员费了 b(￣▽￣)d<br>其中 tailsacles 用 NAT 穿透技术把不同网络下的设备连接到一个局域网内。RDP则直接继承在 Windows 内核上，延迟低爽歪歪。</p><br/><p>03<br>推荐两个新发现的好用工具服务</p><ul><li>开源 Mac 应用及数据清理 ：<a href="https://github.com/alienator88/Pearcleaner">Pearcleaner</a></li><li>多端文件互传工具 Win&#x2F;Mac&#x2F;Linux&#x2F;IOS&#x2F;Android：<a href="https://github.com/localsend/localsend">LocalSend</a><ul><li>LTS1.3 加密协议</li><li>千兆网络局域网内 100MB&#x2F;s 传输</li></ul></li></ul><br/><br/><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br>尝试和朋友去跳舞，是没玩过的运动，连着跳了几天只感觉自己的不协调和潦草，身体不累，但要动脑子，记动作好陌生，大家甩头起来让我怕怕，但是蹦跶起来很快乐。</p><br/><p>02<br>一个春节假期过去，身体变得僵硬了，后弯不舒畅，倒立支楞不起来，是倦怠的身体，紧张、不安，不好掌控的身体的细节。对自身的不信任感下，每个动作都在求稳，放不开也绕不过去。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/03/03/mmexport1740535784238.jpg" alt="image"></p><br/><p>03<br>从朋友那学来的芝麻汤圆淋上浓缩咖啡液，咖啡的苦涩平衡了粘腻的芝麻还增加了醇厚的香气，好妙呀！<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/03/03/97be1561f5fd62c672e82c7a7deddf8.jpg" alt="image"></p><br/><p>04<br>月末的双休杭州忽然就30度了，春暖花开，去赏梅花！<br>人好多的，全城都复苏了。<br><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/03/03/retouch_2025030215193271.jpg" alt="image"></p><br/><p>05<br>家里的绿植们：<br>一号富贵籽，比冬天秃了但还绿绿葱葱地活着。<br>二号蓝花楹，天气回暖光秃的枝干上开始长小芽了。<br>三号常春藤，生长的非常好，一直在开出新叶片。<br>四号春雨，黄了几片叶子摘了，没啥变化。<br>五号石榴树，新来的冒名顶替来的。</p><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/03/03/02dca515da198211eb358c5aa727b54.jpg" alt="image"></p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/03/03/202502/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2025/01 Review</title>
      <link>https://blog.liluhui.cn/2025/02/02/202501/</link>
      <guid>https://blog.liluhui.cn/2025/02/02/202501/</guid>
      <pubDate>Sun, 02 Feb 2025 09:47:40 GMT</pubDate>
      
      <description>毋意，毋必，毋固，毋我</description>
      
      
      
      <content:encoded><![CDATA[<p>毋意，毋必，毋固，毋我</p><h2 id="这个月发生了什么？"><a href="#这个月发生了什么？" class="headerlink" title="这个月发生了什么？"></a>这个月发生了什么？</h2><ol><li>新一年的第一个月，好好思考和整理了下自己想要的，回归到初始的冲动上。</li><li>主业工作上这个月主要在搞数据分析，还有推进各种新模型的测试，「大角讲题」上线了语音功能还有试卷擦除。</li><li>小红书变得好欢乐因为tiktok这波封禁的难民，deepseek 在这个月也是不断发酵，真香。</li><li>天冷了，基本窝在家里看看书看看电影，春节附近走走溜溜狗，天气如此那就慵懒一些。</li><li>在杭州探索各种咖啡厅、茶室、书吧，换些地方待一待，西湖边的风景确实好啊。</li><li>学习养绿植中，不是想过老年人生活，就是有冲动想要一个充满生命力的屋子 😅。</li></ol><br/><br/><h2 id="所见与所想"><a href="#所见与所想" class="headerlink" title="所见与所想"></a>所见与所想</h2><p>01<br>喜欢迷宫饭中森西对于生态的尊重，认真的玩好游戏，胜利者满怀感激，失败者尊重接受，要么吃，要么被吃，无关地位的高低，只是因为进食是生者的权利。也喜欢莱欧斯好好吃饭、努力锻炼就为自己的存在而充分骄傲的心态。食物通过食道进了胃，再从小肠进入大肠，我们用身体的所有部分消化它，让它渗透到身体的每个角落，让它形成自己。<strong>吃饭，是认真活着的证明，是生命一切意义的起始。</strong></p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/20250202165043.png" class="left" width="500"><br/><br/><p>02<br>想要做好的是：<strong>静心 学习 服务他人</strong></p><p>正在经历波动和重整，静心做的少了，在疯狂忙碌和彻底放空两个极端横跳，少了打坐和书写。<br>想要持续投入学习，又总是因为探索太多东西而分散精力，想看的技术太多，想尝试的娱乐太多，想了解的瑜伽太多，结果沉淀下来的都不扎实。一年做好一件事这话没错，但是列列年度目标再怎么删还是有个五六件。<br>想对他人有帮助，但眼下更重要的是照顾好自己，让自己充分地可以舒展和表达，再去做更多的事情。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/mmexport1735816937274.jpg" class="left" width="500"><br/><br/><p>03<br>在过年假期期间每日抄写心经，感受指尖的不自觉的用力后刻意的松开一些，又在想要让字型更好的时候不自觉变得紧张。重了，中指上的老茧隐隐酸痛，轻了，字型飘渺，把握好这个度很难，这个难是对字型的不熟悉，是新手畏畏缩缩又想要把事做好的过分用力，是想让自己放宽心又因为没有能耐并不能真的放宽心的无力。</p><p>每一遍心经抄写完，看着整整齐齐的文字列于纸张之上，浅浅的开心和满足，细看哪里都是不完美，但没有遗憾，因为每一笔我都认真对待了，即使那些思绪飘散离去的文字，我也因为书写这个字型的过程看到了自己的想象，自己忍不住想去思考的事情，因为每一笔而能安住当下的感觉，很微妙。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250201_120204.jpg" class="left" width="500"><br/><br/><p>04<br>本月遇到的一些好内容推荐：</p><ul><li><a href="https://mp.weixin.qq.com/s/d9NiG92zhfBrBQ0ily7ggg">金融|文章|陆家嘴没有神话</a> 从各项数据和案例来看主动基金的时代已经过去，指数投资趋势已呈现。今年机构圈的跨年氛围弥漫着“没人在意自己是不是第一，都在努力不成为后二分之一”的活人微死感。</li><li><a href="https://user.qzone.qq.com/2634895847">健康|文章|李辛医师：现代人的压力与管理</a>2007年在上海交大的一场演讲，谈论了从中医视角下是如何认识疾病的，与现代医学定义病理名称这样的标签化面对病证的方是不同，中医从心理结构和身体运作出发认识“生病”，或者说精气神的不平衡。<br/><br/></li></ul><h2 id="学习与工作"><a href="#学习与工作" class="headerlink" title="学习与工作"></a>学习与工作</h2><p>01<br>DeepSeek 这个月可太风光了，1月21日开源推理模型DeepSeek-R1发布，完全开源训练细节全公开，效果几乎打平 openai-o1 ，api 调用价格只有二十七分之一。月底这波海外爆发，推上很坏了，但服务器这稳定性几乎没法用了，我暂时被劝退了…<br>DeepSeek-R1在大规模强化学习（RL）中自然涌现出了强大的推理能力和有趣的推理行为，并未进行有监督的微调（SFT）<br><a href="https://github.com/deepseek-ai/DeepSeek-R1">https://github.com/deepseek-ai/DeepSeek-R1</a></p><p>本月另外关注的两个大模型</p><ul><li>Google 发布 Gemini 2.0 Flash Thinking 推理模型</li><li>字节跳动发布 Doubao-1.5-pro 推理模型<br/><br/></li></ul><p>02<br>主业的教育产品「大角讲题」本月上线了 0.3.1-0.4.1，目前核心功能上了教学讲题和试卷擦除，运营上还没有打开通路，主要通过自媒体账号和应用商城的流量。现在教学讲题上还有很多可以做的空间，很多处于尝试阶段的方案，以及测试数据集和测试标准的建立的工作，一步步来吧。<br><br/><br><br/></p><h2 id="生活与社交"><a href="#生活与社交" class="headerlink" title="生活与社交"></a>生活与社交</h2><p>01<br>去上海的时候和朋友买了几个手办，喜欢labubu这个瑜伽系列 😆。 悦动青春抽中了两个聪介，可惜不是一对聪介美津未，喜欢美津未但是一个没中 😅。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250125_114702.jpg" class="left" width="500"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250125_120915.jpg" class="left" width="500"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250122_114812.jpg" class="left" width="500"><br/><br/><p>02<br>Cubox 礼盒的贴纸还怪好看的，给笔记本安排上了 😉。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250121_215447.jpg" class="left" width="500"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/ef6e0631395b9d6066d7cc795aef7b5.jpg" class="left" width="500"><br/><br/><p>03<br>西湖边叔叔阿姨们的生活，热热闹闹腾腾，坐在树下的老大爷跟着一起瞎唱，阳光照地我睁不开眼，明明风吹来挺冷，但那个环境下确实感觉，暖洋洋的人气。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250118_153343.jpg" class="left" width="500"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250118_153608.jpg" class="left" width="500"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250118_153828.jpg" class="left" width="500"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250118_153442.jpg" class="left" width="500"><br/><br/><p>04<br>我的快乐狗子和它的朋友们。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250129_113648.jpg" class="left" width="500"><p>玩累了就坐我不看上晒太阳</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250129_112707.jpg" class="left" width="500"><p>三师会晤</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250129_112706.jpg" class="left" width="500"><p>这表情太狗了😄</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250118_215130.jpg" class="left" width="500"><p>爱挂鼻涕的胖虎加菲猫</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250131_125111.jpg" class="left" width="500"><p>我在抄经，狗子呼呼大睡，白噪音呼声，频率稳定 😊<br><br/><br><br/></p><p>05<br>两个晚上完成拼图🧩，图益的质量很满意。 (๑￣▽￣)و✧</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/IMG_20250129_234308%201.jpg" class="left" width="500"><br/><br/><p>06<br>蹭朋友的车逛到南浔，遇到一对从上海来玩的古装小姐姐，聊的很投缘，还很热情地帮我们拍照，因为和老朋友留下了值得珍惜的照片而开心。咖啡不咋地，天气也不太好，不过偶尔闲散的感觉很好，偶遇热心的人很好，吃到老字号的面很好，想到下次还会见面更好。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/mmexport1737903135311.jpg" class="left" width="500"><br/><br/><p>07<br>养绿植，果然没那么容易，好想要一个充满绿色的屋子，试试看 🪴</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/047a4819c1bff583f1d9ce2b8ac8223.jpg" class="left" width="500"><p>春雨从刚来时倒伏的状态慢慢能立起来点了</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/d6207cf520498ce71116cceecdff286.jpg" class="left" width="500"><p>常春藤长出好多新的小叶子</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/80ff9216c2ffc2c730425c7885f5bc6.jpg" class="left" width="500"><p>发财树被狗啃没了，不知道还有没有机会..</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/84c9fc8d0eaee4ef7a984534df2db14.jpg" class="left" width="500"><p>苔藓球真好养，每天托盘里装上水长得一直好好。<br><br/><br><br/></p><p>08<br>新年第一拜瑜伽，随着太阳升起，和小伙伴们一起108遍拜日，舒畅，迎接新一年。</p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/02/01/retouch_2025010222011624.jpg" class="left" width="500"><br/><br/><p>09<br>一月看片简评<br>《我们一起摇太阳》（2024中国）：感人又好笑，爱情不爱情另说，面对疾病和死亡有人相伴很好。<br>《首尔之春》（2023韩国）：行，不愧是韩国政治，这剧情想都不敢想。<br>《蓦然回首》（2024日本）：很细腻的短片，人生很孤独啊，但，有种热血在其中诶。<br>《名侦探柯南：百万美元的五棱星》（2024日本）（非粉丝就别看了）：行，柯学。<br>《小小的我》（2024中国大陆）（非粉丝就别看了）：剧情冲突不够感觉在秀演技了..<br>《怪物》（2023日本）（别看）：这感情我看不懂，好粗糙，是在故意整悬疑。</p><br/><br/><br/><br/><br/>]]></content:encoded>
      
      
      <category domain="https://blog.liluhui.cn/categories/%E7%94%9F%E6%B4%BB/">生活</category>
      
      
      
      <comments>https://blog.liluhui.cn/2025/02/02/202501/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>