<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>从顶流开源 Kimi K2-Thinking 学习：什么是推理模型？ | Luhui's Personal Website</title><meta name="author" content="Luhui芦荟"><meta name="copyright" content="Luhui芦荟"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="引言：推理模型，为什么值得我们关注 在开源模型阵营中，大佬 Kimi K2 Thinking（以下简称“K2‑Thinking”）的崛起为推理模型带来了优秀学习样本。 “推理模型”到底是什么？它与我们熟悉的传统大型语言模型（LLM）有什么根本不同？ 在信息爆炸、任务越来越复杂的时代，仅靠“训练好一个大模型、输入–输出”已经难以满足：比如依赖多步逻辑、实时工具调用、环境反馈循环，这些场景里传统 LL">
<meta property="og:type" content="article">
<meta property="og:title" content="从顶流开源 Kimi K2-Thinking 学习：什么是推理模型？">
<meta property="og:url" content="https://blog.liluhui.cn/2025/11/21/Understanding-Reasoning-Models-Exploring-Kimi-K2-Thinking-and-Its-Breakthrough/index.html">
<meta property="og:site_name" content="Luhui&#39;s Personal Website">
<meta property="og:description" content="引言：推理模型，为什么值得我们关注 在开源模型阵营中，大佬 Kimi K2 Thinking（以下简称“K2‑Thinking”）的崛起为推理模型带来了优秀学习样本。 “推理模型”到底是什么？它与我们熟悉的传统大型语言模型（LLM）有什么根本不同？ 在信息爆炸、任务越来越复杂的时代，仅靠“训练好一个大模型、输入–输出”已经难以满足：比如依赖多步逻辑、实时工具调用、环境反馈循环，这些场景里传统 LL">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg">
<meta property="article:published_time" content="2025-11-21T00:00:20.000Z">
<meta property="article:modified_time" content="2025-11-21T12:53:34.321Z">
<meta property="article:author" content="Luhui芦荟">
<meta property="article:tag" content="李璐慧,芦荟,Aloea,技术博客,前端,Node">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg"><link rel="shortcut icon" href="https://i.loli.net/2017/11/26/5a19c0b50432e.png"><link rel="canonical" href="https://blog.liluhui.cn/2025/11/21/Understanding-Reasoning-Models-Exploring-Kimi-K2-Thinking-and-Its-Breakthrough/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{
      const saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
      
      window.btf = {
        saveToLocal: saveToLocal,
        getScript: (url, attr = {}) => new Promise((resolve, reject) => {
          const script = document.createElement('script')
          script.src = url
          script.async = true
          script.onerror = reject
          script.onload = script.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            script.onload = script.onreadystatechange = null
            resolve()
          }

          Object.keys(attr).forEach(key => {
            script.setAttribute(key, attr[key])
          })

          document.head.appendChild(script)
        }),

        getCSS: (url, id = false) => new Promise((resolve, reject) => {
          const link = document.createElement('link')
          link.rel = 'stylesheet'
          link.href = url
          if (id) link.id = id
          link.onerror = reject
          link.onload = link.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            link.onload = link.onreadystatechange = null
            resolve()
          }
          document.head.appendChild(link)
        }),

        addGlobalFn: (key, fn, name = false, parent = window) => {
          const pjaxEnable = false
          if (!pjaxEnable && key.startsWith('pjax')) return

          const globalFn = parent.globalFn || {}
          const keyObj = globalFn[key] || {}
    
          if (name && keyObj[name]) return
    
          name = name || Object.keys(keyObj).length
          keyObj[name] = fn
          globalFn[key] = keyObj
          parent.globalFn = globalFn
        }
      }
    
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode
      
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })()</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=8Z2NNDYTL9"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', '8Z2NNDYTL9')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', '8Z2NNDYTL9', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '从顶流开源 Kimi K2-Thinking 学习：什么是推理模型？',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-11-21 20:53:34'
}</script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/rss2.xml" title="Luhui's Personal Website" type="application/rss+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">117</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" href="/about"><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/process"><span> 建站历程</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/5W7DZ_A-ywM.jpg);"><nav id="nav"><span id="blog-info"><a href="/" title="Luhui's Personal Website"><span class="site-name">Luhui's Personal Website</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" href="/about"><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/process"><span> 建站历程</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">从顶流开源 Kimi K2-Thinking 学习：什么是推理模型？</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-21T00:00:20.000Z" title="发表于 2025-11-21 08:00:20">2025-11-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-21T12:53:34.321Z" title="更新于 2025-11-21 20:53:34">2025-11-21</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="从顶流开源 Kimi K2-Thinking 学习：什么是推理模型？"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="引言：推理模型，为什么值得我们关注"><a href="#引言：推理模型，为什么值得我们关注" class="headerlink" title="引言：推理模型，为什么值得我们关注"></a>引言：推理模型，为什么值得我们关注</h2><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/11/21/2025112103.png"></p>
<p>在开源模型阵营中，大佬 Kimi K2 Thinking（以下简称“K2‑Thinking”）的崛起为推理模型带来了优秀学习样本。</p>
<p><strong>“推理模型”到底是什么？它与我们熟悉的传统大型语言模型（LLM）有什么根本不同？</strong></p>
<p>在信息爆炸、任务越来越复杂的时代，仅靠“训练好一个大模型、输入–输出”已经难以满足：比如依赖多步逻辑、实时工具调用、环境反馈循环，这些场景里传统 LLM 往往容易漂移、跳步或卡顿。</p>
<p>而<strong>推理模型强调：从多个角度思考分析、多步推导、根据环境变化调整路径</strong>。</p>
<p>在这方面，K2‑Thinking 正是一个很典型的代表：它公开了技术路线，强调“思考 + 工具调用 +长流程”能力，这为我梳理“什么是推理模型”提供了一个很棒的资料。</p>
<br/>
<br/>

<h2 id="什么是推理模型？与传统-LLM-的关键区别"><a href="#什么是推理模型？与传统-LLM-的关键区别" class="headerlink" title="什么是推理模型？与传统 LLM 的关键区别"></a>什么是推理模型？与传统 LLM 的关键区别</h2><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/11/21/2025112102.png"></p>
<p>最重要的来了，推理模型到底具备哪些关键特性，能够让它在复杂任务中脱颖而出呢？</p>
<h3 id="1-链式推理（Chain-of-Thought）"><a href="#1-链式推理（Chain-of-Thought）" class="headerlink" title="1. 链式推理（Chain-of-Thought）"></a>1. <strong>链式推理（Chain-of-Thought）</strong></h3><p>链式推理是推理模型的核心特性之一，它指的是模型能够像人类一样<strong>逐步思考</strong>，而不是直接给出答案。</p>
<p>举个简单的例子，假设你在解决一个数学问题，推理模型不会只是直接计算出结果，而是会先拆解问题，逐步推导出解答过程，最后给出完整的答案。</p>
<p>这种方式能够有效避免传统模型“跳过步骤”导致的错误。</p>
<br/>

<h3 id="2-工具调用（Tool-Calling）"><a href="#2-工具调用（Tool-Calling）" class="headerlink" title="2. 工具调用（Tool Calling）"></a>2. <strong>工具调用（Tool Calling）</strong></h3><p>工具调用是推理模型的一项重要能力。</p>
<p>传统的大语言模型只依赖训练数据和内部知识库，而推理模型则能够<strong>主动调用外部工具</strong>来辅助完成任务。</p>
<p>比如，它不仅能进行搜索，还能执行代码，调取数据库中的信息，甚至访问最新的网络资源。</p>
<p>在解答一个问题时，推理模型不仅仅依赖“它知道的”，而是能够实时与世界互动，获取最新的有用信息。</p>
<br/>

<h3 id="3-自我反思（Self-Reflection）"><a href="#3-自我反思（Self-Reflection）" class="headerlink" title="3. 自我反思（Self-Reflection）"></a>3. <strong>自我反思（Self-Reflection）</strong></h3><p>在推理过程中，推理模型还具备<strong>自我反思</strong>的能力。</p>
<p>当它在执行任务时，它能够检查自己的推理过程，发现其中的漏洞并进行修正。</p>
<p>就像你在解数学题时，不仅仅是盯着结果，而是不断回顾每一步的推理过程，确保每个步骤都无误。</p>
<p>推理模型的这种能力，可以大大提高任务的准确性和可靠性。</p>
<br/>

<h3 id="4-长程推理（Long-Horizon-Reasoning）"><a href="#4-长程推理（Long-Horizon-Reasoning）" class="headerlink" title="4. 长程推理（Long-Horizon Reasoning）"></a>4. <strong>长程推理（Long-Horizon Reasoning）</strong></h3><p>长程推理指的是模型能够处理<strong>多轮推理</strong>，并且在整个推理过程中保持一致的思路。</p>
<p>它能够记住前面推理过程中发生的关键步骤，并且根据这些步骤来调整后续的决策。</p>
<p>比如，在长时间的决策过程中，推理模型能够从多个方面考虑，并一步步推进，直到问题得到完全解决。</p>
<br/>
<br/>

<h2 id="K2‑Thinking-的创新突破"><a href="#K2‑Thinking-的创新突破" class="headerlink" title="K2‑Thinking 的创新突破"></a>K2‑Thinking 的创新突破</h2><p><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2025/11/21/2025112101.png"></p>
<p>K2‑Thinking 作为开源推理模型的代表，为我们展示了推理能力在实际应用中的潜力。</p>
<h3 id="1-长时间自主推理（Long-Horizon-Agency）"><a href="#1-长时间自主推理（Long-Horizon-Agency）" class="headerlink" title="1. 长时间自主推理（Long-Horizon Agency）"></a><strong>1. 长时间自主推理（Long-Horizon Agency）</strong></h3><p>传统的大型语言模型（LLM）通常在面对多步骤任务时会“漂移”，在执行 30-50 步之后就容易失去逻辑连贯性。</p>
<p>而 K2‑Thinking 设计成一个能够持续进行 200-300 次连续工具调用且保持思路一致的“思考代理”。</p>
<p>这种能力让它能够完成复杂问题的推理，而不仅仅是简单的回答问题。</p>
<p>在一个演示中，K2‑Thinking 通过 23 次推理和工具调用，解决了一个博士级别的数学问题，展示了它在长时间、复杂任务中的自主推理能力。</p>
<br/>

<h3 id="2-测试时扩展（Test-Time-Scaling）"><a href="#2-测试时扩展（Test-Time-Scaling）" class="headerlink" title="2. 测试时扩展（Test-Time Scaling）"></a><strong>2. 测试时扩展（Test-Time Scaling）</strong></h3><p>K2‑Thinking 不像传统模型那样固定计算每个查询，而是采用 <strong>测试时扩展</strong> 的方式。</p>
<p>在遇到复杂任务时，它会“思考更多”，通过递归循环不断优化问题的解决路径：</p>
<ul>
<li>思考：分解问题。</li>
<li>行动：调用外部工具（如搜索引擎、代码解释器等）。</li>
<li>观察：获取工具输出。</li>
<li>重新评估：分析新信息并调整方案。</li>
</ul>
<p>这种递归式的推理过程使得 Kimi 可以在多轮的推理和工具调用中，始终保持清晰的思路和目标。</p>
<br/>

<h3 id="3-高效的-MoE（Mixture-of-Experts）架构"><a href="#3-高效的-MoE（Mixture-of-Experts）架构" class="headerlink" title="3. 高效的 MoE（Mixture-of-Experts）架构"></a><strong>3. 高效的 MoE（Mixture-of-Experts）架构</strong></h3><p>虽然 K2‑Thinking 拥有 1 万亿参数，但它采用了高效的 Mixture-of-Experts (MoE) 架构，在每次推理时只激活其中的 32 亿参数。</p>
<p>这样的“稀疏”设计让模型在拥有大量知识的同时，保持低成本的推理效率。</p>
<p>由于其高效设计，K2‑Thinking 可以在较为普通的硬件上运行，例如两台 M3 Ultra Mac Studios，极大地降低了运行成本和对硬件的依赖。</p>
<br/>

<h3 id="4-原生-INT4-量化加速"><a href="#4-原生-INT4-量化加速" class="headerlink" title="4. 原生 INT4 量化加速"></a><strong>4. 原生 INT4 量化加速</strong></h3><p>K2‑Thinking 采用 <strong>原生 INT4 量化</strong> 技术，将模型的权重压缩到 4 位，带来 <strong>2 倍的推理速度</strong> 提升和大幅度的内存减少。</p>
<p>这使得它能够在性能和成本之间实现最佳平衡，适合更多的应用场景。</p>
<br/>

<h3 id="5-优异的多步骤推理表现"><a href="#5-优异的多步骤推理表现" class="headerlink" title="5. 优异的多步骤推理表现"></a><strong>5. 优异的多步骤推理表现</strong></h3><p>在 <strong>Humanity’s Last Exam (HLE)</strong> 和 <strong>BrowseComp</strong> 等基准测试中，K2‑Thinking 超越了 GPT-5 和 Claude，展示了它在 <strong>工具调用</strong> 和 <strong>多步骤推理</strong> 任务中的卓越表现。</p>
<p>例如，Kimi 在 HLE 测试中获得 44.9%，优于 GPT-5 的 41.7%。在网页搜索任务 BrowseComp 中，Kimi 获得了 60.2%，大幅领先于 GPT-5 的 54.9%。</p>
<br/>

<h3 id="6-低成本训练和高效计算"><a href="#6-低成本训练和高效计算" class="headerlink" title="6. 低成本训练和高效计算"></a><strong>6. 低成本训练和高效计算</strong></h3><p>K2‑Thinking 的训练成本仅为 <strong>460 万美元</strong>，远低于 GPT-4（~7800 万美元）和 Gemini Ultra（1.91 亿美元）。</p>
<p>这使得 Kimi 的成本效益成为行业的颠覆性力量，证明了通过高效算法优化可以挑战资本密集型的 AI 计算模式。</p>
<p>Moonshot 通过创新的 <strong>Muon 优化器</strong> 和 <strong>多头潜在注意力（MLA）</strong> 进一步提升了计算效率，使得每一美元的计算支出都能获得更多的智能输出。</p>
<br/>

<h3 id="7-开源与商业模式创新"><a href="#7-开源与商业模式创新" class="headerlink" title="7. 开源与商业模式创新"></a><strong>7. 开源与商业模式创新</strong></h3><p>K2‑Thinking 采用了 <strong>修改版 MIT 许可协议</strong>，这一许可不仅允许研究人员、初创公司和企业进行商业化使用，还通过 <strong>要求商业产品显示 Kimi K2</strong> 来确保对该技术的认知和贡献。</p>
<p>与大部分限制性商业许可不同，Kimi 通过开放权重和宽松的许可协议，推动了 AI 技术的社区创新。</p>
<p>这种开放的方式挑战了现有的高 API 收费模式，给开发者带来了 <strong>低成本、开源竞争力的替代品</strong>。</p>
<p>相较于依赖高收费 API 的传统 AI 模型，Kimi 提供了一个几乎免费的高性能替代方案。</p>
<br/>

<h3 id="8-打破“计算壁垒”：算法为先，资本为后"><a href="#8-打破“计算壁垒”：算法为先，资本为后" class="headerlink" title="8. 打破“计算壁垒”：算法为先，资本为后"></a><strong>8. 打破“计算壁垒”：算法为先，资本为后</strong></h3><p>K2‑Thinking 打破了 <strong>“计算壁垒”</strong> 的传统观念，挑战了“大模型需要巨额资本支撑”的说法。</p>
<p>通过算法优化，Kimi 展现了计算效率的突破，使得较低预算的团队也能开发和部署强大的推理模型。</p>
<p>这种效率革命使得高端 AI 模型的门槛降低，行业竞争格局发生了根本性变化。</p>
<br/>
<br/>

<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>推理模型正在成为下一代 AI 应用的新基建。</p>
<p>K2‑Thinking 作为一个开源且具备实战能力的代表，显示出国产模型在“推理能力”维度也有突破。</p>
<p>现在能看到，<strong>越来越多新产品从“简单生成”转向“复杂行动＋思考＋工具协同”。</strong></p>
<p>期待国内人工智能的生态越做越好，越来越成熟 ！</p>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

<h2 id="延申阅读"><a href="#延申阅读" class="headerlink" title="延申阅读"></a>延申阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://moonshotai.github.io/Kimi-K2/thinking.html">Introducing Kimi K2 Thinking 技术博客（Moonshot AI）</a></li>
<li><a target="_blank" rel="noopener" href="https://www.shuttle.dev/blog/2025/11/17/kimi-k2-thinking-hands-on-review">Kimi K2 Thinking: Testing the Open-Source Reasoning Model on Real Code</a></li>
<li><a target="_blank" rel="noopener" href="https://c3.unu.edu/blog/the-agent-has-landed-why-kimi-k2-thinking-is-more-than-just-a-new-ai-model">Why Kimi K2 Thinking Is More Than Just a New AI Model</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.liluhui.cn">Luhui芦荟</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.liluhui.cn/2025/11/21/Understanding-Reasoning-Models-Exploring-Kimi-K2-Thinking-and-Its-Breakthrough/">https://blog.liluhui.cn/2025/11/21/Understanding-Reasoning-Models-Exploring-Kimi-K2-Thinking-and-Its-Breakthrough/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.liluhui.cn" target="_blank">Luhui's Personal Website</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="prev-post pull-left" href="/2025/11/28/Engineering-Insights-from-GPT-5-Unified-System-Design/" title="从 GPT-5 Unified 系统设计中学到的工程精髓"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">从 GPT-5 Unified 系统设计中学到的工程精髓</div></div></a><a class="next-post pull-right" href="/2025/11/19/Why-Fei-Fei-Li-Says-the-Future-of-AI-Progress-Depends-on-World-Models/" title="为什么李飞飞说：AI 真正的进步取决于世界模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">为什么李飞飞说：AI 真正的进步取决于世界模型</div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info is-center"><div class="avatar-img"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Luhui芦荟</div><div class="author-info-description">关于生活、学习、工作</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">117</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="/rss2.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a><a class="social-icon" href="https://github.com/LDingLDing" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liluhuizj@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E5%80%BC%E5%BE%97%E6%88%91%E4%BB%AC%E5%85%B3%E6%B3%A8"><span class="toc-number">1.</span> <span class="toc-text">引言：推理模型，为什么值得我们关注</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BC%A0%E7%BB%9F-LLM-%E7%9A%84%E5%85%B3%E9%94%AE%E5%8C%BA%E5%88%AB"><span class="toc-number">2.</span> <span class="toc-text">什么是推理模型？与传统 LLM 的关键区别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%93%BE%E5%BC%8F%E6%8E%A8%E7%90%86%EF%BC%88Chain-of-Thought%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">1. 链式推理（Chain-of-Thought）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%EF%BC%88Tool-Calling%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">2. 工具调用（Tool Calling）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%87%AA%E6%88%91%E5%8F%8D%E6%80%9D%EF%BC%88Self-Reflection%EF%BC%89"><span class="toc-number">2.3.</span> <span class="toc-text">3. 自我反思（Self-Reflection）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E9%95%BF%E7%A8%8B%E6%8E%A8%E7%90%86%EF%BC%88Long-Horizon-Reasoning%EF%BC%89"><span class="toc-number">2.4.</span> <span class="toc-text">4. 长程推理（Long-Horizon Reasoning）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K2%E2%80%91Thinking-%E7%9A%84%E5%88%9B%E6%96%B0%E7%AA%81%E7%A0%B4"><span class="toc-number">3.</span> <span class="toc-text">K2‑Thinking 的创新突破</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%95%BF%E6%97%B6%E9%97%B4%E8%87%AA%E4%B8%BB%E6%8E%A8%E7%90%86%EF%BC%88Long-Horizon-Agency%EF%BC%89"><span class="toc-number">3.1.</span> <span class="toc-text">1. 长时间自主推理（Long-Horizon Agency）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B5%8B%E8%AF%95%E6%97%B6%E6%89%A9%E5%B1%95%EF%BC%88Test-Time-Scaling%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">2. 测试时扩展（Test-Time Scaling）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%AB%98%E6%95%88%E7%9A%84-MoE%EF%BC%88Mixture-of-Experts%EF%BC%89%E6%9E%B6%E6%9E%84"><span class="toc-number">3.3.</span> <span class="toc-text">3. 高效的 MoE（Mixture-of-Experts）架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%8E%9F%E7%94%9F-INT4-%E9%87%8F%E5%8C%96%E5%8A%A0%E9%80%9F"><span class="toc-number">3.4.</span> <span class="toc-text">4. 原生 INT4 量化加速</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E4%BC%98%E5%BC%82%E7%9A%84%E5%A4%9A%E6%AD%A5%E9%AA%A4%E6%8E%A8%E7%90%86%E8%A1%A8%E7%8E%B0"><span class="toc-number">3.5.</span> <span class="toc-text">5. 优异的多步骤推理表现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E4%BD%8E%E6%88%90%E6%9C%AC%E8%AE%AD%E7%BB%83%E5%92%8C%E9%AB%98%E6%95%88%E8%AE%A1%E7%AE%97"><span class="toc-number">3.6.</span> <span class="toc-text">6. 低成本训练和高效计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E5%BC%80%E6%BA%90%E4%B8%8E%E5%95%86%E4%B8%9A%E6%A8%A1%E5%BC%8F%E5%88%9B%E6%96%B0"><span class="toc-number">3.7.</span> <span class="toc-text">7. 开源与商业模式创新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E6%89%93%E7%A0%B4%E2%80%9C%E8%AE%A1%E7%AE%97%E5%A3%81%E5%9E%92%E2%80%9D%EF%BC%9A%E7%AE%97%E6%B3%95%E4%B8%BA%E5%85%88%EF%BC%8C%E8%B5%84%E6%9C%AC%E4%B8%BA%E5%90%8E"><span class="toc-number">3.8.</span> <span class="toc-text">8. 打破“计算壁垒”：算法为先，资本为后</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="toc-number">4.</span> <span class="toc-text">写在最后</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%B6%E7%94%B3%E9%98%85%E8%AF%BB"><span class="toc-number">5.</span> <span class="toc-text">延申阅读</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/23/My-Favorite-AI-Tools-of-2025/" title="我这一年，如何用 AI 构建第二个大脑和第二套生产系统">我这一年，如何用 AI 构建第二个大脑和第二套生产系统</a><time datetime="2026-01-23T10:42:44.000Z" title="发表于 2026-01-23 18:42:44">2026-01-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/20/Catching-Unconscious-Goals-Between-Each-Inhale-and-Exhale/" title="在一呼一吸间，看见那些无意识的目标">在一呼一吸间，看见那些无意识的目标</a><time datetime="2026-01-20T09:08:39.000Z" title="发表于 2026-01-20 17:08:39">2026-01-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/18/How-to-Actually-Ship-Honest-Alignment-in-the-Age-of-Agents/" title="工程视角：Agent 时代，诚实对齐该如何落地？">工程视角：Agent 时代，诚实对齐该如何落地？</a><time datetime="2026-01-18T08:57:08.000Z" title="发表于 2026-01-18 16:57:08">2026-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/10/When-Models-Know-They-Are-Cheating-A-Technical-Dissection-of-Scheming-and-Reward-Hacking/" title="当模型知道自己在作弊：Scheming 与 Reward Hacking 的技术解剖">当模型知道自己在作弊：Scheming 与 Reward Hacking 的技术解剖</a><time datetime="2026-01-10T11:40:41.000Z" title="发表于 2026-01-10 19:40:41">2026-01-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/02/202512/" title="2025/12 Review"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2026/01/02/IMG_1271_20251225.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025/12 Review"/></a><div class="content"><a class="title" href="/2026/01/02/202512/" title="2025/12 Review">2025/12 Review</a><time datetime="2026-01-02T14:04:56.000Z" title="发表于 2026-01-02 22:04:56">2026-01-02</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2026 By Luhui芦荟</div><div class="footer_custom_text"><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn">浙ICP备19010836号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: '4987f0fb0a509fb9f0af',
      clientSecret: '7e264967a3ea557003aacdf795b9e57e36a56382',
      repo: 'ldinglding.github.io',
      owner: 'LDingLDing',
      admin: ['LDingLDing'],
      id: '07d3f49f588e8546239f907bc3d3dffb',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>