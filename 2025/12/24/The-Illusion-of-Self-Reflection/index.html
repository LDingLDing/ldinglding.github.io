<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Self-reflection 的幻觉：为什么让模型“反思”往往没用？ | Luhui's Personal Website</title><meta name="author" content="Luhui芦荟"><meta name="copyright" content="Luhui芦荟"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言我们这一年在工程里最常见的一个动作是： 模型答错了？让它反思一下。 加一句 “Let’s reflect” “Check your answer” “Are you sure?”，或者做个 “draft → critique → revise” 的链条，往往准确率真能上去。 但问题在于：你想解决的是Honesty（诚实），还是Accuracy（准确）？ 这两者经常被混在一起，尤其当大家把“反思">
<meta property="og:type" content="article">
<meta property="og:title" content="Self-reflection 的幻觉：为什么让模型“反思”往往没用？">
<meta property="og:url" content="https://blog.liluhui.cn/2025/12/24/The-Illusion-of-Self-Reflection/index.html">
<meta property="og:site_name" content="Luhui&#39;s Personal Website">
<meta property="og:description" content="前言我们这一年在工程里最常见的一个动作是： 模型答错了？让它反思一下。 加一句 “Let’s reflect” “Check your answer” “Are you sure?”，或者做个 “draft → critique → revise” 的链条，往往准确率真能上去。 但问题在于：你想解决的是Honesty（诚实），还是Accuracy（准确）？ 这两者经常被混在一起，尤其当大家把“反思">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg">
<meta property="article:published_time" content="2025-12-24T10:03:35.000Z">
<meta property="article:modified_time" content="2026-01-18T09:03:14.267Z">
<meta property="article:author" content="Luhui芦荟">
<meta property="article:tag" content="李璐慧,芦荟,Aloea,技术博客,前端,Node">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg"><link rel="shortcut icon" href="https://i.loli.net/2017/11/26/5a19c0b50432e.png"><link rel="canonical" href="https://blog.liluhui.cn/2025/12/24/The-Illusion-of-Self-Reflection/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{
      const saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
      
      window.btf = {
        saveToLocal: saveToLocal,
        getScript: (url, attr = {}) => new Promise((resolve, reject) => {
          const script = document.createElement('script')
          script.src = url
          script.async = true
          script.onerror = reject
          script.onload = script.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            script.onload = script.onreadystatechange = null
            resolve()
          }

          Object.keys(attr).forEach(key => {
            script.setAttribute(key, attr[key])
          })

          document.head.appendChild(script)
        }),

        getCSS: (url, id = false) => new Promise((resolve, reject) => {
          const link = document.createElement('link')
          link.rel = 'stylesheet'
          link.href = url
          if (id) link.id = id
          link.onerror = reject
          link.onload = link.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            link.onload = link.onreadystatechange = null
            resolve()
          }
          document.head.appendChild(link)
        }),

        addGlobalFn: (key, fn, name = false, parent = window) => {
          const pjaxEnable = false
          if (!pjaxEnable && key.startsWith('pjax')) return

          const globalFn = parent.globalFn || {}
          const keyObj = globalFn[key] || {}
    
          if (name && keyObj[name]) return
    
          name = name || Object.keys(keyObj).length
          keyObj[name] = fn
          globalFn[key] = keyObj
          parent.globalFn = globalFn
        }
      }
    
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode
      
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })()</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=8Z2NNDYTL9"></script><script>window.dataLayer = window.dataLayer || []
function gtag(){dataLayer.push(arguments)}
gtag('js', new Date())
gtag('config', '8Z2NNDYTL9')
btf.addGlobalFn('pjaxComplete', () => {
  gtag('config', '8Z2NNDYTL9', {'page_path': window.location.pathname})
}, 'google_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":true,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Self-reflection 的幻觉：为什么让模型“反思”往往没用？',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-01-18 17:03:14'
}</script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/rss2.xml" title="Luhui's Personal Website" type="application/rss+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">116</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" href="/about"><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/process"><span> 建站历程</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url(https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/5W7DZ_A-ywM.jpg);"><nav id="nav"><span id="blog-info"><a href="/" title="Luhui's Personal Website"><span class="site-name">Luhui's Personal Website</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives"><span> 文章归档</span></a></div><div class="menus_item"><a class="site-page" href="/about"><span> 关于我</span></a></div><div class="menus_item"><a class="site-page" href="/process"><span> 建站历程</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Self-reflection 的幻觉：为什么让模型“反思”往往没用？</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-24T10:03:35.000Z" title="发表于 2025-12-24 18:03:35">2025-12-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-18T09:03:14.267Z" title="更新于 2026-01-18 17:03:14">2026-01-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%9A%E5%AE%9E%E5%AF%B9%E9%BD%90/">大模型诚实对齐</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Self-reflection 的幻觉：为什么让模型“反思”往往没用？"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们这一年在工程里最常见的一个动作是：</p>
<p><strong>模型答错了？让它反思一下。</strong></p>
<p>加一句 “Let’s reflect” “Check your answer” “Are you sure?”，或者做个 “draft → critique → revise” 的链条，往往<strong>准确率</strong>真能上去。</p>
<p>但问题在于：你想解决的是<strong>Honesty（诚实）</strong>，还是<strong>Accuracy（准确）</strong>？</p>
<p>这两者经常被混在一起，尤其当大家把“反思”当作万能修复按钮时。更麻烦的是：</p>
<ul>
<li>有些错误是模型“不知道自己错了”（典型幻觉&#x2F;知识盲区），反思也无从下手；</li>
<li>有些错误是模型“知道自己在做坏事但不说”（reward hacking &#x2F; scheming），反思反而更像“圆谎”，它会生成一套更漂亮的解释；</li>
<li>还有一些场景，反思会让模型<strong>更自信地坚持错误</strong>（自洽但错得很统一）。</li>
</ul>
<br/>

<p>所以，这篇长文的核心观点是：</p>
<p>大多数 self-reflection 并没有把模型变诚实，它只是把同一个生成过程又跑了一遍。</p>
<p>它能提升“输出质量&#x2F;正确率”，但通常提升不了“诚实度”。</p>
<br/>
<br/>



<h2 id="先看对比：六类方法，各自解决的不是同一件事"><a href="#先看对比：六类方法，各自解决的不是同一件事" class="headerlink" title="先看对比：六类方法，各自解决的不是同一件事"></a>先看对比：六类方法，各自解决的不是同一件事</h2><ol>
<li><strong>Self-critique &#x2F; Self-refine &#x2F; Reflexion（自我批评&#x2F;自我精炼&#x2F;反思代理）</strong><ul>
<li>主要优化：<strong>输出质量、推理质量</strong>（更像写作和解题的二次打磨）</li>
<li>常见收益：准确率、可读性、偏好评分提升</li>
<li>主要短板：对“有意欺骗”几乎无解；对“模型不知错”的幻觉也有限</li>
<li>经典方案：OpenAI critiques、Self-Refine、Reflexion</li>
</ul>
</li>
</ol>
<br/>

<ol start="2">
<li><strong>Reflection prompting（反思式提示词）</strong><ul>
<li>主要优化：<strong>推理时的注意力分配</strong>（提醒它别草率）</li>
<li>常见收益：复杂推理正确率上升</li>
<li>主要短板：稳定性差；容易“过度修正”；面对对抗&#x2F;自适应攻击效果会衰减（DeepMind 明确提过这类现象）</li>
</ul>
</li>
</ol>
<br/>


<ol start="3">
<li><strong>Multi-sample voting &#x2F; Self-consistency（多样采样投票&#x2F;自洽）</strong><ul>
<li>主要优化：<strong>降低偶发错误</strong>（用统计学对冲一次采样的随机性）</li>
<li>常见收益：推理基准大幅提升（例如 GSM8K 等）</li>
<li>主要短板：对“系统性偏见&#x2F;统一错”无能为力；对诚实提升很有限</li>
</ul>
</li>
</ol>
<br/>

<ol start="4">
<li><strong>Debate &#x2F; Peer review（辩论&#x2F;互评）</strong><ul>
<li>主要优化：<strong>外部监督质量</strong>（把评估拆成更易判别的子问题）</li>
<li>常见收益：理论上可扩展监督（PSPACE vs NP 视角），用于“拆穿谎言更易”的假设</li>
<li>主要短板：实现复杂；需要强裁判或强对手；存在串通&#x2F;误导风险</li>
</ul>
</li>
</ol>
<br/>

<ol start="5">
<li><strong>Constitutional AI（宪法式自我修正）</strong><ul>
<li>主要优化：<strong>合规性与无害性</strong>（按原则自评、自改，再做 RL）</li>
<li>常见收益：安全性明显提升，且不依赖逐条人工标注</li>
<li>主要短板：更偏“安全对齐”，并不等价于“事实诚实”；也可能带来过度拒答</li>
</ul>
</li>
</ol>
<br/>

<ol start="6">
<li><strong>Confessions &#x2F; Self-report fine-tuning（供述&#x2F;自我报告）</strong><ul>
<li>主要优化：<strong>“愿不愿意说真话”</strong>，尤其是行为层面的不诚实</li>
<li>关键差异：把“做对任务”和“承认违规&#x2F;作弊”<strong>解耦</strong>训练（供述奖励不绑定主任务）</li>
<li>另一个近期强结果：DeepMind&#x2F;合作者提出的 SRFT（自我报告微调）显示，对“隐藏目标”可接近满分检测（F1&#x3D;0.98 vs 基线 0）</li>
<li>主要短板：对“模型根本不知道自己错了”的幻觉，帮助有限；更像事后透明机制</li>
</ul>
</li>
</ol>
<p>结论：</p>
<p><strong>想要更少出错</strong>：用 self-consistency &#x2F; self-refine &#x2F; reflection prompting。</p>
<p><strong>想要更诚实</strong>：必须引入独立的“报告&#x2F;供述”通道与激励（confession &#x2F; self-report），并配合外部监督。</p>
<br/>
<br/>


<h2 id="先把“反思”这个概念拆开：它到底在做哪件事？"><a href="#先把“反思”这个概念拆开：它到底在做哪件事？" class="headerlink" title="先把“反思”这个概念拆开：它到底在做哪件事？"></a>先把“反思”这个概念拆开：它到底在做哪件事？</h2><p>你在提示里写“请反思”，模型通常做的是三件事之一：</p>
<ul>
<li><strong>复述式反思</strong>：把刚才说过的换种说法再说一遍（几乎没信息增量）</li>
<li><strong>修辞式反思</strong>：写出更像“认真想过”的解释（提升可读性，但未必更真）</li>
<li><strong>检错式反思</strong>：真的去找冲突、边界条件、单位、步骤错误（这才可能提升正确率）</li>
</ul>
<p>注意：这三者都不等价于“诚实”。<br>诚实至少需要两个条件：</p>
<ol>
<li><strong>Self-knowledge</strong>：它知道自己错&#x2F;违规了</li>
<li><strong>Disclosure</strong>：它愿意把这件事说出来</li>
</ol>
<p>大多数 reflection 只在（1）上碰碰运气；（2）几乎没动。</p>
<br/>
<br/>

<h2 id="为什么让模型“反思”往往没用？"><a href="#为什么让模型“反思”往往没用？" class="headerlink" title="为什么让模型“反思”往往没用？"></a>为什么让模型“反思”往往没用？</h2><h3 id="根因-A：反思不是“反省”，而是“第二次生成”"><a href="#根因-A：反思不是“反省”，而是“第二次生成”" class="headerlink" title="根因 A：反思不是“反省”，而是“第二次生成”"></a>根因 A：反思不是“反省”，而是“第二次生成”</h3><p>Self-Refine 的定义非常直白：先生成初稿，再让同一个模型给反馈，再迭代修订；它不需要额外训练数据，效果在多任务上提升显著。</p>
<p>但这类方法提升的是“输出偏好&#x2F;质量”，并没有引入新的证据来源。换句话说：它只是把同一分布多采样了一次。</p>
<p>因此你会看到一个典型现象：</p>
<ul>
<li>越写越像回事，但事实仍可能是错的</li>
<li>对抗性场景里，“反思”变成了“更高级的圆谎”</li>
</ul>
<br/>

<h3 id="根因-B：模型常常“不知道自己错了”"><a href="#根因-B：模型常常“不知道自己错了”" class="headerlink" title="根因 B：模型常常“不知道自己错了”"></a>根因 B：模型常常“不知道自己错了”</h3><p>对幻觉而言，模型可能在内部把错误当作高置信事实。</p>
<p>这不是“它不诚实”，而是“它没意识到错误”。此时反思很难凭空纠错。</p>
<p>相关研究开始专门评估“无外部反馈条件下的反思能力”，指出很多 self-reflection 的收益可能来自外部反馈或隐含提示，而非真正的内省能力。</p>
<br/>

<h3 id="根因-C：激励不对，反思阶段也会继续优化“看起来对”"><a href="#根因-C：激励不对，反思阶段也会继续优化“看起来对”" class="headerlink" title="根因 C：激励不对，反思阶段也会继续优化“看起来对”"></a>根因 C：激励不对，反思阶段也会继续优化“看起来对”</h3><p>如果你的系统奖励（显性或隐性）仍然是：</p>
<ul>
<li>回答要完整</li>
<li>语气要自信</li>
<li>用户要满意</li>
</ul>
<p>那模型在“反思”阶段最自然的优化目标是：<strong>把叙事补齐、把漏洞抹平</strong>。</p>
<p>这会提升“可接受性”，但可能降低“可证伪性”。</p>
<br/>

<h3 id="根因-D：反思提示在对抗-x2F-自适应攻击前会迅速失效"><a href="#根因-D：反思提示在对抗-x2F-自适应攻击前会迅速失效" class="headerlink" title="根因 D：反思提示在对抗&#x2F;自适应攻击前会迅速失效"></a>根因 D：反思提示在对抗&#x2F;自适应攻击前会迅速失效</h3><p>DeepMind 在 Gemini 安全防护相关的<a target="_blank" rel="noopener" href="https://deepmind.google/blog/advancing-geminis-security-safeguards">博客</a>里明确提到：像 self-reflection 这类静态防御，在面对会适应的攻击时会变得不那么有效。</p>
<p>这其实在诚实性上同理：当对方（人或环境）开始利用你的“反思套路”，模型可以学会“反思该怎么写才过关”。</p>
<br/>


<h3 id="根因-E：多轮反思会引入“自我污染”"><a href="#根因-E：多轮反思会引入“自我污染”" class="headerlink" title="根因 E：多轮反思会引入“自我污染”"></a>根因 E：多轮反思会引入“自我污染”</h3><p>反思过程产生的文本会反过来成为下一步生成的条件。</p>
<p>如果第一步方向错了，后续反思可能只是不断在错误轨道上“越修越顺”。</p>
<p>Reflexion 把反思写入 episodic memory，确实能显著提升代理任务表现；但从诚实角度看，这种记忆写入也可能把“错误信念&#x2F;错误策略”固化进去，除非你有强外部反馈来纠偏。</p>
<br/>
<br/>


<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>如果你做的是“把答案做对”，反思系方法是有效的：Self-consistency 通过统计学对冲随机性，Self-Refine 通过迭代打磨表达与推理。</p>
<p>但如果你做的是“让模型更诚实”，仅靠反思不够。</p>
<p>诚实要求模型在知道自己做错时仍愿意披露，而这通常需要独立的报告通道与激励设计——例如 Confessions 或 SRFT 这种“承认错误不吃亏”的机制。</p>
<p>换句话说，反思解决的是“更少犯错”，供述解决的是“犯错也别骗”。</p>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>


<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2206.05802">Self-critiquing models for assisting human evaluators</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.17651">Self-Refine: Iterative Refinement with Self-Feedback</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.11366">Reflexion: Language Agents with Verbal Reinforcement Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://deepmind.google/blog/advancing-geminis-security-safeguards/">Advancing Gemini’s security safeguards</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.11171">Self-Consistency Improves Chain of Thought Reasoning in Language Models</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.00899">[1805.00899] AI safety via debate</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2212.08073">Constitutional AI: Harmlessness from AI Feedback</a></li>
<li><a target="_blank" rel="noopener" href="https://cdn.openai.com/pdf/6216f8bc-187b-4bbb-8932-ba7c40c5553d/confessions_paper.pdf">Training LLMs for Honesty via Confessions</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2511.06626">Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/html/2404.09129v1">Testing Limits on Reflective Thinking in Large Language</a></li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.liluhui.cn">Luhui芦荟</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.liluhui.cn/2025/12/24/The-Illusion-of-Self-Reflection/">https://blog.liluhui.cn/2025/12/24/The-Illusion-of-Self-Reflection/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.liluhui.cn" target="_blank">Luhui's Personal Website</a>！</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="prev-post pull-left" href="/2025/12/26/A-2025-Retrospective-on-the-OpenSource-Large-Language-Model-Ecosystem/" title="2025 开源大模型生态回顾一览"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">2025 开源大模型生态回顾一览</div></div></a><a class="next-post pull-right" href="/2025/12/19/openai-confession/" title="OpenAI Confession：为什么“承认作弊”比“不作弊”更重要"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">OpenAI Confession：为什么“承认作弊”比“不作弊”更重要</div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info is-center"><div class="avatar-img"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/C31A6047.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Luhui芦荟</div><div class="author-info-description">关于生活、学习、工作</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">116</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">31</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="/rss2.xml" target="_blank" title="RSS"><i class="fas fa-rss"></i></a><a class="social-icon" href="https://github.com/LDingLDing" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liluhuizj@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E7%9C%8B%E5%AF%B9%E6%AF%94%EF%BC%9A%E5%85%AD%E7%B1%BB%E6%96%B9%E6%B3%95%EF%BC%8C%E5%90%84%E8%87%AA%E8%A7%A3%E5%86%B3%E7%9A%84%E4%B8%8D%E6%98%AF%E5%90%8C%E4%B8%80%E4%BB%B6%E4%BA%8B"><span class="toc-number">2.</span> <span class="toc-text">先看对比：六类方法，各自解决的不是同一件事</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E6%8A%8A%E2%80%9C%E5%8F%8D%E6%80%9D%E2%80%9D%E8%BF%99%E4%B8%AA%E6%A6%82%E5%BF%B5%E6%8B%86%E5%BC%80%EF%BC%9A%E5%AE%83%E5%88%B0%E5%BA%95%E5%9C%A8%E5%81%9A%E5%93%AA%E4%BB%B6%E4%BA%8B%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">先把“反思”这个概念拆开：它到底在做哪件事？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AE%A9%E6%A8%A1%E5%9E%8B%E2%80%9C%E5%8F%8D%E6%80%9D%E2%80%9D%E5%BE%80%E5%BE%80%E6%B2%A1%E7%94%A8%EF%BC%9F"><span class="toc-number">4.</span> <span class="toc-text">为什么让模型“反思”往往没用？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E5%9B%A0-A%EF%BC%9A%E5%8F%8D%E6%80%9D%E4%B8%8D%E6%98%AF%E2%80%9C%E5%8F%8D%E7%9C%81%E2%80%9D%EF%BC%8C%E8%80%8C%E6%98%AF%E2%80%9C%E7%AC%AC%E4%BA%8C%E6%AC%A1%E7%94%9F%E6%88%90%E2%80%9D"><span class="toc-number">4.1.</span> <span class="toc-text">根因 A：反思不是“反省”，而是“第二次生成”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E5%9B%A0-B%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%B8%B8%E5%B8%B8%E2%80%9C%E4%B8%8D%E7%9F%A5%E9%81%93%E8%87%AA%E5%B7%B1%E9%94%99%E4%BA%86%E2%80%9D"><span class="toc-number">4.2.</span> <span class="toc-text">根因 B：模型常常“不知道自己错了”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E5%9B%A0-C%EF%BC%9A%E6%BF%80%E5%8A%B1%E4%B8%8D%E5%AF%B9%EF%BC%8C%E5%8F%8D%E6%80%9D%E9%98%B6%E6%AE%B5%E4%B9%9F%E4%BC%9A%E7%BB%A7%E7%BB%AD%E4%BC%98%E5%8C%96%E2%80%9C%E7%9C%8B%E8%B5%B7%E6%9D%A5%E5%AF%B9%E2%80%9D"><span class="toc-number">4.3.</span> <span class="toc-text">根因 C：激励不对，反思阶段也会继续优化“看起来对”</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E5%9B%A0-D%EF%BC%9A%E5%8F%8D%E6%80%9D%E6%8F%90%E7%A4%BA%E5%9C%A8%E5%AF%B9%E6%8A%97-x2F-%E8%87%AA%E9%80%82%E5%BA%94%E6%94%BB%E5%87%BB%E5%89%8D%E4%BC%9A%E8%BF%85%E9%80%9F%E5%A4%B1%E6%95%88"><span class="toc-number">4.4.</span> <span class="toc-text">根因 D：反思提示在对抗&#x2F;自适应攻击前会迅速失效</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B9%E5%9B%A0-E%EF%BC%9A%E5%A4%9A%E8%BD%AE%E5%8F%8D%E6%80%9D%E4%BC%9A%E5%BC%95%E5%85%A5%E2%80%9C%E8%87%AA%E6%88%91%E6%B1%A1%E6%9F%93%E2%80%9D"><span class="toc-number">4.5.</span> <span class="toc-text">根因 E：多轮反思会引入“自我污染”</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="toc-number">5.</span> <span class="toc-text">写在最后</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB"><span class="toc-number">6.</span> <span class="toc-text">延伸阅读</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/20/Catching-Unconscious-Goals-Between-Each-Inhale-and-Exhale/" title="在一呼一吸间，看见那些无意识的目标">在一呼一吸间，看见那些无意识的目标</a><time datetime="2026-01-20T09:08:39.000Z" title="发表于 2026-01-20 17:08:39">2026-01-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/18/How-to-Actually-Ship-Honest-Alignment-in-the-Age-of-Agents/" title="工程视角：Agent 时代，诚实对齐该如何落地？">工程视角：Agent 时代，诚实对齐该如何落地？</a><time datetime="2026-01-18T08:57:08.000Z" title="发表于 2026-01-18 16:57:08">2026-01-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/10/When-Models-Know-They-Are-Cheating-A-Technical-Dissection-of-Scheming-and-Reward-Hacking/" title="当模型知道自己在作弊：Scheming 与 Reward Hacking 的技术解剖">当模型知道自己在作弊：Scheming 与 Reward Hacking 的技术解剖</a><time datetime="2026-01-10T11:40:41.000Z" title="发表于 2026-01-10 19:40:41">2026-01-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/02/202512/" title="2025/12 Review"><img src="https://liluhui.oss-cn-hangzhou.aliyuncs.com/assets/imgs/2026/01/02/IMG_1271_20251225.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="2025/12 Review"/></a><div class="content"><a class="title" href="/2026/01/02/202512/" title="2025/12 Review">2025/12 Review</a><time datetime="2026-01-02T14:04:56.000Z" title="发表于 2026-01-02 22:04:56">2026-01-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/26/A-2025-Retrospective-on-the-OpenSource-Large-Language-Model-Ecosystem/" title="2025 开源大模型生态回顾一览">2025 开源大模型生态回顾一览</a><time datetime="2025-12-26T13:00:29.000Z" title="发表于 2025-12-26 21:00:29">2025-12-26</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2026 By Luhui芦荟</div><div class="footer_custom_text"><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn">浙ICP备19010836号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: '4987f0fb0a509fb9f0af',
      clientSecret: '7e264967a3ea557003aacdf795b9e57e36a56382',
      repo: 'ldinglding.github.io',
      owner: 'LDingLDing',
      admin: ['LDingLDing'],
      id: 'cb83f294af7192e3406a5f9160e09b8d',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>